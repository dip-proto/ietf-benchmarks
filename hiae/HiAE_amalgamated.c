/*
 * HiAE Amalgamated Implementation
 * 
 * This file is automatically generated by scripts/amalgamate.py
 * It contains all HiAE source files merged into a single compilation unit.
 * 
 * To use this file, simply compile it with your project:
 *   cc -O3 -o myapp myapp.c HiAE_amalgamated.c
 * 
 * The amalgamated version preserves all runtime dispatch functionality
 * and automatically selects the optimal implementation for your CPU.
 */

#ifndef HIAE_AMALGAMATED_H
#define HIAE_AMALGAMATED_H

/* Standard C library includes */
#include <stddef.h>
#include <stdint.h>
#include <string.h>
#include <assert.h>

/* Platform-specific includes */
#ifdef __linux__
#    include <sys/auxv.h>
#endif
#ifdef __ANDROID_API__
#    include <cpu-features.h>
#endif
#ifdef __APPLE__
#    include <mach/machine.h>
#    include <sys/sysctl.h>
#    include <sys/types.h>
#endif
#if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_IX86))
#    include <intrin.h>
#endif

/* Architecture-specific intrinsics */
#if defined(__i386__) || defined(_M_IX86) || defined(__x86_64__) || defined(_M_AMD64)
#    include <immintrin.h>
#    include <wmmintrin.h>
#    ifdef __GNUC__
#        if __has_include(<vaesintrin.h>)
#            include <vaesintrin.h>
#        endif
#    endif
#endif

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @file HiAE.h
 * @brief HiAE (High-Throughput Authenticated Encryption) - A high-performance AEAD cipher
 *
 * HiAE is a cross-platform cryptographic library implementing an AES-based AEAD
 * (Authenticated Encryption with Associated Data) cipher with runtime CPU feature
 * detection. It automatically selects the optimal implementation:
 * - VAES+AVX512 for latest x86 processors
 * - AES-NI for x86-64 processors with hardware AES
 * - ARM Crypto Extensions for ARM64 processors
 * - Pure software universal fallback
 *
 * The library provides three API levels:
 * 1. High-Level All-at-Once: Simple functions for small to medium messages
 * 2. High-Level Streaming: Automatic buffering for large files/streams
 * 3. Low-Level Block-Oriented: Fine control with manual alignment requirements
 */






#if !defined(__clang__) && !defined(__GNUC__)
#    ifdef __attribute__
#        undef __attribute__
#    endif
#    define __attribute__(a)
#endif

/**
 * @defgroup constants Cryptographic Constants
 * @brief Core cryptographic parameter sizes for HiAE
 * @{
 */

/** @brief Key size in bytes (256 bits)
 *
 * HiAE uses 256-bit (32-byte) keys for all operations.
 * Keys should be generated using a cryptographically secure random number generator.
 */
#define HIAE_KEYBYTES 32

/** @brief Nonce/IV size in bytes (128 bits)
 *
 * HiAE uses 128-bit (16-byte) nonces (initialization vectors).
 * Each nonce must be unique for a given key to maintain security.
 * Reusing a nonce with the same key compromises the encryption.
 */
#define HIAE_NONCEBYTES 16

/** @brief Authentication tag size in bytes (128 bits)
 *
 * HiAE produces 128-bit (16-byte) authentication tags.
 * The tag provides integrity and authenticity verification for both
 * the ciphertext and any associated data.
 */
#define HIAE_MACBYTES 16

/** @} */

/**
 * @defgroup types Data Types
 * @brief Core data structures used by HiAE
 * @{
 */

/**
 * @brief Opaque state structure for low-level streaming operations
 *
 * This structure maintains the internal state for incremental encryption/decryption
 * operations. The contents are implementation-specific and should not be accessed
 * directly by applications.
 *
 * @note The state is 256 bytes to accommodate all implementation variants
 * @note Each state instance is independent and thread-safe when used by one thread
 * @warning Never modify the contents directly or copy states between operations
 */
typedef struct {
    uint8_t opaque[256];
} HiAE_state_t;

/** @} */

/**
 * @defgroup highlevel High-Level All-at-Once API
 * @brief Simple functions for encrypting/decrypting complete messages in memory
 *
 * These functions are the easiest to use and are suitable for messages that
 * fit comfortably in memory. They handle all the complexity internally.
 * @{
 */

/**
 * @brief Encrypt a message with authenticated encryption
 *
 * Encrypts a plaintext message and generates an authentication tag that
 * protects both the ciphertext and optional associated data.
 *
 * @param key       Encryption key (must be HIAE_KEYBYTES bytes)
 * @param nonce     Unique nonce/IV for this message (must be HIAE_NONCEBYTES bytes)
 * @param msg       Plaintext message to encrypt
 * @param ct        Output buffer for ciphertext (same size as msg)
 * @param msg_len   Length of the message in bytes
 * @param ad        Optional associated data to authenticate (can be NULL)
 * @param ad_len    Length of associated data (0 if ad is NULL)
 * @param tag       Output buffer for authentication tag (must be HIAE_MACBYTES bytes)
 *
 * @return 0 on success, non-zero on error
 *
 * @warning Never reuse a nonce with the same key
 * @note The ciphertext buffer must be at least msg_len bytes
 * @note Associated data is authenticated but not encrypted
 *
 * Example:
 * @code
 * uint8_t key[HIAE_KEYBYTES];
 * uint8_t nonce[HIAE_NONCEBYTES];
 * uint8_t plaintext[] = "Secret message";
 * uint8_t ciphertext[sizeof(plaintext)];
 * uint8_t tag[HIAE_MACBYTES];
 * uint8_t ad[] = "metadata";
 *
 * // Generate random key and nonce (use proper CSPRNG)
 * // ...
 *
 * int ret = HiAE_encrypt(key, nonce, plaintext, ciphertext,
 *                        sizeof(plaintext), ad, sizeof(ad), tag);
 * if (ret != 0) {
 *     // Handle error
 * }
 * @endcode
 */
int HiAE_encrypt(const uint8_t *key, const uint8_t *nonce, const uint8_t *msg, uint8_t *ct,
                 size_t msg_len, const uint8_t *ad, size_t ad_len, uint8_t *tag);

/**
 * @brief Decrypt a message with authenticated encryption
 *
 * Decrypts a ciphertext and verifies its authenticity using the provided tag.
 * If verification fails, the output buffer contents are undefined.
 *
 * @param key       Decryption key (must match encryption key)
 * @param nonce     Nonce/IV used during encryption
 * @param msg       Output buffer for decrypted plaintext
 * @param ct        Ciphertext to decrypt
 * @param ct_len    Length of the ciphertext in bytes
 * @param ad        Associated data used during encryption (can be NULL)
 * @param ad_len    Length of associated data (0 if ad is NULL)
 * @param tag       Authentication tag from encryption
 *
 * @return 0 on success (authentication passed), non-zero on failure
 *
 * @warning ALWAYS check the return value - non-zero means authentication failed
 * @warning On authentication failure, the output buffer contents are undefined
 * @note The plaintext buffer must be at least ct_len bytes
 *
 * Example:
 * @code
 * uint8_t decrypted[sizeof(ciphertext)];
 *
 * int ret = HiAE_decrypt(key, nonce, decrypted, ciphertext,
 *                        sizeof(ciphertext), ad, sizeof(ad), tag);
 * if (ret != 0) {
 *     // Authentication failed! Message was tampered with
 *     // Do not use decrypted data
 *     return -1;
 * }
 * // Safe to use decrypted data
 * @endcode
 */
int HiAE_decrypt(const uint8_t *key, const uint8_t *nonce, uint8_t *msg, const uint8_t *ct,
                 size_t ct_len, const uint8_t *ad, size_t ad_len, const uint8_t *tag);

/**
 * @brief Compute authentication tag without encryption (MAC-only mode)
 *
 * Generates an authentication tag for data without performing encryption.
 * Useful for authenticating data that doesn't need confidentiality.
 *
 * @param key       Authentication key (must be HIAE_KEYBYTES bytes)
 * @param nonce     Unique nonce for this operation
 * @param data      Data to authenticate
 * @param data_len  Length of data in bytes
 * @param tag       Output buffer for authentication tag
 *
 * @return 0 on success, non-zero on error
 *
 * @note This is equivalent to HiAE_encrypt with a zero-length message
 * @warning Still requires unique nonces like encryption operations
 *
 * Example:
 * @code
 * uint8_t tag[HIAE_MACBYTES];
 * uint8_t metadata[] = "file-metadata-v1.0";
 *
 * int ret = HiAE_mac(key, nonce, metadata, sizeof(metadata), tag);
 * @endcode
 */
int HiAE_mac(const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len,
             uint8_t *tag);

/** @} */

/**
 * @defgroup utility Utility Functions
 * @brief Helper functions for library management and diagnostics
 * @{
 */

/**
 * @brief Initialize the HiAE library
 *
 * Performs CPU feature detection and selects the optimal implementation.
 * This function is called automatically on first use, but can be called
 * explicitly for better control over initialization timing.
 *
 * @return 0 on success, non-zero on error
 *
 * @note Thread-safe and idempotent (safe to call multiple times)
 * @note Calling this early can avoid initialization overhead on first use
 */
int HiAE_init_library(void);

/**
 * @brief Get the name of the active implementation
 *
 * Returns a string describing which implementation was selected based
 * on CPU feature detection.
 *
 * @return Implementation name (e.g., "VAES+AVX512", "AES-NI", "ARM-Crypto", "Software")
 *
 * @note The returned string is static and should not be freed
 * @note Useful for debugging and performance analysis
 *
 * Example:
 * @code
 * printf("Using HiAE implementation: %s\n", HiAE_get_implementation_name());
 * @endcode
 */
const char *HiAE_get_implementation_name(void);

/**
 * @brief Force a specific implementation to be used
 *
 * Forces the library to use a specific implementation instead of automatically
 * detecting the best one. Useful for testing, debugging, or when specific
 * behavior is required.
 *
 * @param impl_name Implementation name to force ("Software", "AES-NI", "VAES+AVX512", "ARM NEON",
 * "ARM SHA3")
 *
 * @return 0 on success, -1 if implementation is not available or name is invalid
 *
 * @note Must be called before any other HiAE operations
 * @note Pass NULL to restore automatic detection
 * @note Not all implementations are available on all platforms
 *
 * Example:
 * @code
 * // Force software implementation for testing
 * if (HiAE_force_implementation("Software") != 0) {
 *     fprintf(stderr, "Failed to force software implementation\n");
 * }
 *
 * // Restore automatic detection
 * HiAE_force_implementation(NULL);
 * @endcode
 */
int HiAE_force_implementation(const char *impl_name);

/**
 * @brief Constant-time comparison of authentication tags
 *
 * Compares two authentication tags in constant time to prevent
 * timing side-channel attacks.
 *
 * @param expected_tag  The expected tag (HIAE_MACBYTES bytes)
 * @param actual_tag    The tag to verify (HIAE_MACBYTES bytes)
 *
 * @return 0 if tags match, non-zero if different
 *
 * @note Always compares exactly HIAE_MACBYTES bytes
 * @note Execution time is independent of tag contents
 *
 * Example:
 * @code
 * if (HiAE_verify_tag(expected_tag, computed_tag) != 0) {
 *     // Authentication failed
 * }
 * @endcode
 */
int HiAE_verify_tag(const uint8_t *expected_tag, const uint8_t *actual_tag);

/** @} */

/**
 * @defgroup streaming High-Level Streaming API
 * @brief Streaming functions with automatic buffering for large data
 *
 * This API provides streaming encryption/decryption with automatic internal
 * buffering. Unlike the low-level API, it handles partial blocks transparently
 * and accepts any chunk size.
 * @{
 */

/**
 * @brief Stream processing phases
 *
 * Tracks the current phase of streaming operation to ensure correct API usage.
 */
typedef enum {
    HIAE_STREAM_INIT  = 0, /**< Initial state after HiAE_stream_init() */
    HIAE_STREAM_AD    = 1, /**< Processing associated data */
    HIAE_STREAM_MSG   = 2, /**< Processing message data (encrypt/decrypt) */
    HIAE_STREAM_FINAL = 3 /**< Finalized, tag generated/verified */
} HiAE_stream_phase_t;

/**
 * @brief Stream operation mode
 *
 * Indicates whether the stream is used for encryption or decryption.
 */
typedef enum {
    HIAE_STREAM_MODE_NONE    = 0, /**< Not yet determined */
    HIAE_STREAM_MODE_ENCRYPT = 1, /**< Encryption mode */
    HIAE_STREAM_MODE_DECRYPT = 2 /**< Decryption mode */
} HiAE_stream_mode_t;

/**
 * @brief High-level streaming state
 *
 * Maintains state for streaming operations with automatic buffering.
 * This structure handles partial blocks internally, allowing arbitrary
 * chunk sizes without manual alignment.
 *
 * @note Do not access fields directly - use the streaming API functions
 */
typedef struct {
    HiAE_state_t        state; /**< Internal cryptographic state */
    uint8_t             buffer[16]; /**< Internal buffer for partial blocks */
    size_t              offset; /**< Current offset in buffer */
    size_t              ad_len; /**< Total associated data processed */
    size_t              msg_len; /**< Total message data processed */
    HiAE_stream_phase_t phase; /**< Current processing phase */
    HiAE_stream_mode_t  mode; /**< Encryption or decryption mode */
} HiAE_stream_state_t;

/** @} */

/**
 * @brief Initialize a streaming encryption/decryption operation
 *
 * Sets up the streaming state with the provided key and nonce.
 * After initialization, you can absorb associated data and then
 * encrypt or decrypt message data.
 *
 * @param stream  Stream state to initialize
 * @param key     Encryption/decryption key (HIAE_KEYBYTES bytes)
 * @param nonce   Unique nonce for this operation (HIAE_NONCEBYTES bytes)
 *
 * @note Must be called before any other streaming operations
 * @note The same state cannot be reused - create a new state for each operation
 *
 * Example:
 * @code
 * HiAE_stream_state_t stream;
 * HiAE_stream_init(&stream, key, nonce);
 * @endcode
 */
void HiAE_stream_init(HiAE_stream_state_t *stream, const uint8_t *key, const uint8_t *nonce);

/**
 * @brief Process associated data in streaming mode
 *
 * Absorbs associated data that will be authenticated but not encrypted.
 * Can be called multiple times with any chunk size. Must be called
 * before any encrypt/decrypt operations.
 *
 * @param stream  Stream state
 * @param ad      Associated data chunk
 * @param ad_len  Length of this chunk
 *
 * @note Call multiple times to process AD in chunks of any size
 * @note Must complete all AD before starting encryption/decryption
 *
 * Example:
 * @code
 * HiAE_stream_absorb(&stream, header1, 100);
 * HiAE_stream_absorb(&stream, header2, 57);
 * @endcode
 */
void HiAE_stream_absorb(HiAE_stream_state_t *stream, const uint8_t *ad, size_t ad_len);

/**
 * @brief Encrypt data in streaming mode
 *
 * Encrypts plaintext data incrementally. Handles partial blocks
 * automatically, accepting any chunk size.
 *
 * @param stream  Stream state
 * @param ct      Output buffer for ciphertext
 * @param pt      Input plaintext
 * @param len     Length of data to process
 *
 * @note Output buffer must be at least 'len' bytes
 * @note Can process data in chunks of any size
 * @note Cannot be mixed with decrypt operations on same stream
 *
 * Example:
 * @code
 * // Process file in arbitrary chunks
 * while ((bytes = fread(buffer, 1, sizeof(buffer), input)) > 0) {
 *     HiAE_stream_encrypt(&stream, output, buffer, bytes);
 *     fwrite(output, 1, bytes, output_file);
 * }
 * @endcode
 */
void HiAE_stream_encrypt(HiAE_stream_state_t *stream, uint8_t *ct, const uint8_t *pt, size_t len);

/**
 * @brief Decrypt data in streaming mode
 *
 * Decrypts ciphertext data incrementally. Handles partial blocks
 * automatically, accepting any chunk size.
 *
 * @param stream  Stream state
 * @param pt      Output buffer for plaintext
 * @param ct      Input ciphertext
 * @param len     Length of data to process
 *
 * @note Output buffer must be at least 'len' bytes
 * @note Can process data in chunks of any size
 * @note Cannot be mixed with encrypt operations on same stream
 * @note Does not verify authentication until HiAE_stream_verify()
 */
void HiAE_stream_decrypt(HiAE_stream_state_t *stream, uint8_t *pt, const uint8_t *ct, size_t len);

/**
 * @brief Finalize streaming encryption and get authentication tag
 *
 * Completes the encryption operation and generates the authentication tag.
 * Must be called after all data has been encrypted.
 *
 * @param stream  Stream state
 * @param tag     Output buffer for authentication tag (HIAE_MACBYTES bytes)
 *
 * @note Stream cannot be used after finalization
 * @note For decryption, use HiAE_stream_verify() instead
 *
 * Example:
 * @code
 * uint8_t tag[HIAE_MACBYTES];
 * HiAE_stream_finalize(&stream, tag);
 * // Save or transmit tag with ciphertext
 * @endcode
 */
void HiAE_stream_finalize(HiAE_stream_state_t *stream, uint8_t *tag);

/**
 * @brief Verify authentication tag after streaming decryption
 *
 * Completes the decryption operation and verifies the authentication tag.
 * Must be called after all data has been decrypted.
 *
 * @param stream        Stream state
 * @param expected_tag  The authentication tag to verify
 *
 * @return 0 if authentication succeeds, non-zero on failure
 *
 * @warning If this returns non-zero, the decrypted data is not authentic
 * @note Stream cannot be used after verification
 *
 * Example:
 * @code
 * if (HiAE_stream_verify(&stream, received_tag) != 0) {
 *     // Authentication failed - data was tampered with
 *     // Discard all decrypted data
 * }
 * @endcode
 */
int HiAE_stream_verify(HiAE_stream_state_t *stream, const uint8_t *expected_tag);

/** @} */

/**
 * @defgroup lowlevel Low-Level Streaming API
 * @brief Advanced functions for fine-grained control over streaming operations
 *
 * This API provides direct access to the underlying cipher operations.
 * It requires careful attention to block alignment: all operations except
 * the last must process multiples of 16 bytes.
 *
 * @warning Use the high-level streaming API unless you need fine control
 * @{
 */

/**
 * @brief Initialize low-level streaming state
 *
 * Prepares the state for incremental encryption/decryption operations.
 *
 * @param state   State structure to initialize
 * @param key     Encryption/decryption key (HIAE_KEYBYTES bytes)
 * @param nonce   Unique nonce for this operation (HIAE_NONCEBYTES bytes)
 *
 * @note State must not be reused - initialize fresh state for each operation
 */
void HiAE_init(HiAE_state_t *state, const uint8_t *key, const uint8_t *nonce);

/**
 * @brief Absorb associated data
 *
 * Processes associated data for authentication. Can be called multiple times.
 *
 * @param state   Current state
 * @param ad      Associated data chunk
 * @param len     Length of chunk
 *
 * @warning All calls except the last must have len as multiple of 16
 * @note Must complete all AD before any enc/dec operations
 *
 * Example:
 * @code
 * HiAE_absorb(&state, ad_chunk1, 64);   // Multiple of 16
 * HiAE_absorb(&state, ad_chunk2, 32);   // Multiple of 16
 * HiAE_absorb(&state, ad_chunk3, 7);    // Last chunk - any size
 * @endcode
 */
void HiAE_absorb(HiAE_state_t *state, const uint8_t *ad, size_t len);

/**
 * @brief Finalize and generate authentication tag
 *
 * Completes the operation and produces the authentication tag.
 *
 * @param state    Current state
 * @param ad_len   Total bytes of associated data processed
 * @param msg_len  Total bytes of message data processed
 * @param tag      Output buffer for tag (HIAE_MACBYTES bytes)
 *
 * @note The total lengths must match actual data processed
 * @note State cannot be used after finalization
 */
void HiAE_finalize(HiAE_state_t *state, uint64_t ad_len, uint64_t msg_len, uint8_t *tag);

/**
 * @brief Encrypt data incrementally
 *
 * Encrypts plaintext and updates the internal state.
 *
 * @param state  Current state
 * @param ci     Output ciphertext buffer
 * @param mi     Input plaintext
 * @param size   Number of bytes to process
 *
 * @warning All calls except the last must have size as multiple of 16
 * @note Output buffer must be at least 'size' bytes
 *
 * Example:
 * @code
 * HiAE_enc(&state, ct1, pt1, 256);  // Multiple of 16
 * HiAE_enc(&state, ct2, pt2, 64);   // Multiple of 16
 * HiAE_enc(&state, ct3, pt3, 13);   // Last chunk - any size
 * @endcode
 */
void HiAE_enc(HiAE_state_t *state, uint8_t *ci, const uint8_t *mi, size_t size);

/**
 * @brief Decrypt data incrementally
 *
 * Decrypts ciphertext and updates the internal state.
 *
 * @param state  Current state
 * @param mi     Output plaintext buffer
 * @param ci     Input ciphertext
 * @param size   Number of bytes to process
 *
 * @warning All calls except the last must have size as multiple of 16
 * @note Output buffer must be at least 'size' bytes
 * @note Does not verify authentication - check tag after finalize
 */
void HiAE_dec(HiAE_state_t *state, uint8_t *mi, const uint8_t *ci, size_t size);

/**
 * @brief Encrypt partial block without updating state
 *
 * Encrypts data without updating the internal state. Used for handling
 * partial blocks when more data will follow before finalization.
 *
 * @param state  Current state (not modified)
 * @param ci     Output ciphertext buffer
 * @param mi     Input plaintext
 * @param size   Number of bytes (must be < 16)
 *
 * @warning Only use for partial blocks < 16 bytes
 * @warning State is not updated - cannot be immediately followed by finalize
 * @warning Must eventually process more data to update state properly
 *
 * Example (handling non-aligned streaming):
 * @code
 * // Have 7 bytes but more data coming later
 * uint8_t buffer[16];
 * memcpy(buffer, partial_data, 7);
 * HiAE_enc_partial_noupdate(&state, ct_partial, buffer, 7);
 * // ... when more data arrives to complete block ...
 * memcpy(buffer + 7, more_data, 9);  // Now have full 16-byte block
 * HiAE_enc(&state, ct_full, buffer, 16);  // Updates state
 * @endcode
 */
void HiAE_enc_partial_noupdate(HiAE_state_t *state, uint8_t *ci, const uint8_t *mi, size_t size);

/**
 * @brief Decrypt partial block without updating state
 *
 * Decrypts data without updating the internal state. Used for handling
 * partial blocks when more data will follow before finalization.
 *
 * @param state  Current state (not modified)
 * @param mi     Output plaintext buffer
 * @param ci     Input ciphertext
 * @param size   Number of bytes (must be < 16)
 *
 * @warning Only use for partial blocks < 16 bytes
 * @warning State is not updated - cannot be immediately followed by finalize
 * @warning Must eventually process more data to update state properly
 */
void HiAE_dec_partial_noupdate(HiAE_state_t *state, uint8_t *mi, const uint8_t *ci, size_t size);

/** @} */




/* Internal definitions from HiAE_internal.h */



/* Implementation function table */
typedef struct {
    const char *name;
    void (*init)(HiAE_state_t *state, const uint8_t *key, const uint8_t *nonce);
    void (*absorb)(HiAE_state_t *state, const uint8_t *ad, size_t len);
    void (*finalize)(HiAE_state_t *state, uint64_t ad_len, uint64_t msg_len, uint8_t *tag);
    void (*enc)(HiAE_state_t *state, uint8_t *ci, const uint8_t *mi, size_t size);
    void (*dec)(HiAE_state_t *state, uint8_t *mi, const uint8_t *ci, size_t size);
    void (*enc_partial_noupdate)(HiAE_state_t *state, uint8_t *ci, const uint8_t *mi, size_t size);
    void (*dec_partial_noupdate)(HiAE_state_t *state, uint8_t *mi, const uint8_t *ci, size_t size);
    int (*encrypt)(const uint8_t *key, const uint8_t *nonce, const uint8_t *msg, uint8_t *ct,
                   size_t msg_len, const uint8_t *ad, size_t ad_len, uint8_t *tag);
    int (*decrypt)(const uint8_t *key, const uint8_t *nonce, uint8_t *msg, const uint8_t *ct,
                   size_t ct_len, const uint8_t *ad, size_t ad_len, const uint8_t *tag);
    int (*mac)(const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len,
               uint8_t *tag);
} HiAE_impl_t;

/* Cryptographic parameter sizes */
#define HIAE_KEYBYTES   32 /* 256-bit key */
#define HIAE_NONCEBYTES 16 /* 128-bit nonce */
#define HIAE_MACBYTES   16 /* 128-bit authentication tag */

/* Internal constants */
#define P_0 0
#define P_1 1
#define P_4 13
#define P_7 9
#define I_1 3
#define I_2 13

#define UNROLL_BLOCK_SIZE 256
#define BLOCK_SIZE        16
#define STATE             16

/* Implementation forcing macros - define at compile time to force specific implementation */
#ifdef HIAE_FORCE_SOFTWARE
#    define HIAE_FORCED_IMPL "Software"
#endif
#ifdef HIAE_FORCE_AESNI
#    define HIAE_FORCED_IMPL "AES-NI"
#endif
#ifdef HIAE_FORCE_VAES_AVX512
#    define HIAE_FORCED_IMPL "VAES+AVX512"
#endif
#ifdef HIAE_FORCE_ARM
#    define HIAE_FORCED_IMPL "ARM NEON"
#endif
#ifdef HIAE_FORCE_ARM_SHA3
#    define HIAE_FORCED_IMPL "ARM SHA3"
#endif

/* Internal constant arrays */
static const uint8_t C0[BLOCK_SIZE] = { 0x32, 0x43, 0xf6, 0xa8, 0x88, 0x5a, 0x30, 0x8d,
                                        0x31, 0x31, 0x98, 0xa2, 0xe0, 0x37, 0x07, 0x34 };
static const uint8_t C1[BLOCK_SIZE] = { 0x4a, 0x40, 0x93, 0x82, 0x22, 0x99, 0xf3, 0x1d,
                                        0x00, 0x82, 0xef, 0xa9, 0x8e, 0xc4, 0xe6, 0xc8 };

/* Internal helper functions */
static inline int
hiae_constant_time_compare(const uint8_t *a, const uint8_t *b, size_t len)
{
    volatile uint8_t result = 0;
    for (size_t i = 0; i < len; i++) {
        result |= a[i] ^ b[i];
    }
#if defined(__GNUC__) || defined(__clang__)
    __asm__("" : "+r"(result) :);
#endif
    return -(result != 0);
}



/* Software AES implementation from softaes.h */



#ifndef CRYPTO_ALIGN
#    if defined(__INTEL_COMPILER) || defined(_MSC_VER)
#        define CRYPTO_ALIGN(x) __declspec(align(x))
#    else
#        define CRYPTO_ALIGN(x) __attribute__((aligned(x)))
#    endif
#endif

#define LOAD32_LE(SRC) load32_le(SRC)
static inline uint32_t
load32_le(const uint8_t src[4])
{
#if defined(__BYTE_ORDER__) && __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
    uint32_t w;
    memcpy(&w, src, sizeof w);
    return w;
#else
    uint32_t w = (uint32_t) src[0];
    w |= (uint32_t) src[1] << 8;
    w |= (uint32_t) src[2] << 16;
    w |= (uint32_t) src[3] << 24;
    return w;
#endif
}

#define STORE32_LE(DST, W) store32_le((DST), (W))
static inline void
store32_le(uint8_t dst[4], uint32_t w)
{
#if defined(__BYTE_ORDER__) && __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
    memcpy(dst, &w, sizeof w);
#else
    dst[0] = (uint8_t) w;
    w >>= 8;
    dst[1] = (uint8_t) w;
    w >>= 8;
    dst[2] = (uint8_t) w;
    w >>= 8;
    dst[3] = (uint8_t) w;
#endif
}

#define ROTL32(X, B) rotl32((X), (B))
static inline uint32_t
rotl32(const uint32_t x, const int b)
{
    return (x << b) | (x >> (32 - b));
}

typedef struct SoftAesBlock {
    uint32_t w0;
    uint32_t w1;
    uint32_t w2;
    uint32_t w3;
} SoftAesBlock;

static inline SoftAesBlock
softaes_block_zero(void)
{
    const SoftAesBlock out = { 0, 0, 0, 0 };
    return out;
}

static inline SoftAesBlock
softaes_block_load(const uint8_t in[16])
{
    const SoftAesBlock out = { LOAD32_LE(in + 0), LOAD32_LE(in + 4), LOAD32_LE(in + 8),
                               LOAD32_LE(in + 12) };
    return out;
}

static inline SoftAesBlock
softaes_block_load64x2(const uint64_t a, const uint64_t b)
{
    const SoftAesBlock out = { (uint32_t) b, (uint32_t) (b >> 32), (uint32_t) a,
                               (uint32_t) (a >> 32) };
    return out;
}

static inline void
softaes_block_store(uint8_t out[16], const SoftAesBlock in)
{
    STORE32_LE(out + 0, in.w0);
    STORE32_LE(out + 4, in.w1);
    STORE32_LE(out + 8, in.w2);
    STORE32_LE(out + 12, in.w3);
}

static inline SoftAesBlock
softaes_block_xor(const SoftAesBlock a, const SoftAesBlock b)
{
    const SoftAesBlock out = { a.w0 ^ b.w0, a.w1 ^ b.w1, a.w2 ^ b.w2, a.w3 ^ b.w3 };
    return out;
}

static inline SoftAesBlock
softaes_block_and(const SoftAesBlock a, const SoftAesBlock b)
{
    const SoftAesBlock out = { a.w0 & b.w0, a.w1 & b.w1, a.w2 & b.w2, a.w3 & b.w3 };
    return out;
}

#if defined(__wasm__) && !defined(FAVOR_PERFORMANCE)
#    define FAVOR_PERFORMANCE
#endif

#ifndef SOFTAES_STRIDE
#    define SOFTAES_STRIDE 16
#endif

#ifdef FAVOR_PERFORMANCE
static const uint32_t _aes_lut[1024] = {
    0xa56363c6, 0x847c7cf8, 0x997777ee, 0x8d7b7bf6, 0x0df2f2ff, 0xbd6b6bd6, 0xb16f6fde, 0x54c5c591,
    0x50303060, 0x03010102, 0xa96767ce, 0x7d2b2b56, 0x19fefee7, 0x62d7d7b5, 0xe6abab4d, 0x9a7676ec,
    0x45caca8f, 0x9d82821f, 0x40c9c989, 0x877d7dfa, 0x15fafaef, 0xeb5959b2, 0xc947478e, 0x0bf0f0fb,
    0xecadad41, 0x67d4d4b3, 0xfda2a25f, 0xeaafaf45, 0xbf9c9c23, 0xf7a4a453, 0x967272e4, 0x5bc0c09b,
    0xc2b7b775, 0x1cfdfde1, 0xae93933d, 0x6a26264c, 0x5a36366c, 0x413f3f7e, 0x02f7f7f5, 0x4fcccc83,
    0x5c343468, 0xf4a5a551, 0x34e5e5d1, 0x08f1f1f9, 0x937171e2, 0x73d8d8ab, 0x53313162, 0x3f15152a,
    0x0c040408, 0x52c7c795, 0x65232346, 0x5ec3c39d, 0x28181830, 0xa1969637, 0x0f05050a, 0xb59a9a2f,
    0x0907070e, 0x36121224, 0x9b80801b, 0x3de2e2df, 0x26ebebcd, 0x6927274e, 0xcdb2b27f, 0x9f7575ea,
    0x1b090912, 0x9e83831d, 0x742c2c58, 0x2e1a1a34, 0x2d1b1b36, 0xb26e6edc, 0xee5a5ab4, 0xfba0a05b,
    0xf65252a4, 0x4d3b3b76, 0x61d6d6b7, 0xceb3b37d, 0x7b292952, 0x3ee3e3dd, 0x712f2f5e, 0x97848413,
    0xf55353a6, 0x68d1d1b9, 0x00000000, 0x2cededc1, 0x60202040, 0x1ffcfce3, 0xc8b1b179, 0xed5b5bb6,
    0xbe6a6ad4, 0x46cbcb8d, 0xd9bebe67, 0x4b393972, 0xde4a4a94, 0xd44c4c98, 0xe85858b0, 0x4acfcf85,
    0x6bd0d0bb, 0x2aefefc5, 0xe5aaaa4f, 0x16fbfbed, 0xc5434386, 0xd74d4d9a, 0x55333366, 0x94858511,
    0xcf45458a, 0x10f9f9e9, 0x06020204, 0x817f7ffe, 0xf05050a0, 0x443c3c78, 0xba9f9f25, 0xe3a8a84b,
    0xf35151a2, 0xfea3a35d, 0xc0404080, 0x8a8f8f05, 0xad92923f, 0xbc9d9d21, 0x48383870, 0x04f5f5f1,
    0xdfbcbc63, 0xc1b6b677, 0x75dadaaf, 0x63212142, 0x30101020, 0x1affffe5, 0x0ef3f3fd, 0x6dd2d2bf,
    0x4ccdcd81, 0x140c0c18, 0x35131326, 0x2fececc3, 0xe15f5fbe, 0xa2979735, 0xcc444488, 0x3917172e,
    0x57c4c493, 0xf2a7a755, 0x827e7efc, 0x473d3d7a, 0xac6464c8, 0xe75d5dba, 0x2b191932, 0x957373e6,
    0xa06060c0, 0x98818119, 0xd14f4f9e, 0x7fdcdca3, 0x66222244, 0x7e2a2a54, 0xab90903b, 0x8388880b,
    0xca46468c, 0x29eeeec7, 0xd3b8b86b, 0x3c141428, 0x79dedea7, 0xe25e5ebc, 0x1d0b0b16, 0x76dbdbad,
    0x3be0e0db, 0x56323264, 0x4e3a3a74, 0x1e0a0a14, 0xdb494992, 0x0a06060c, 0x6c242448, 0xe45c5cb8,
    0x5dc2c29f, 0x6ed3d3bd, 0xefacac43, 0xa66262c4, 0xa8919139, 0xa4959531, 0x37e4e4d3, 0x8b7979f2,
    0x32e7e7d5, 0x43c8c88b, 0x5937376e, 0xb76d6dda, 0x8c8d8d01, 0x64d5d5b1, 0xd24e4e9c, 0xe0a9a949,
    0xb46c6cd8, 0xfa5656ac, 0x07f4f4f3, 0x25eaeacf, 0xaf6565ca, 0x8e7a7af4, 0xe9aeae47, 0x18080810,
    0xd5baba6f, 0x887878f0, 0x6f25254a, 0x722e2e5c, 0x241c1c38, 0xf1a6a657, 0xc7b4b473, 0x51c6c697,
    0x23e8e8cb, 0x7cdddda1, 0x9c7474e8, 0x211f1f3e, 0xdd4b4b96, 0xdcbdbd61, 0x868b8b0d, 0x858a8a0f,
    0x907070e0, 0x423e3e7c, 0xc4b5b571, 0xaa6666cc, 0xd8484890, 0x05030306, 0x01f6f6f7, 0x120e0e1c,
    0xa36161c2, 0x5f35356a, 0xf95757ae, 0xd0b9b969, 0x91868617, 0x58c1c199, 0x271d1d3a, 0xb99e9e27,
    0x38e1e1d9, 0x13f8f8eb, 0xb398982b, 0x33111122, 0xbb6969d2, 0x70d9d9a9, 0x898e8e07, 0xa7949433,
    0xb69b9b2d, 0x221e1e3c, 0x92878715, 0x20e9e9c9, 0x49cece87, 0xff5555aa, 0x78282850, 0x7adfdfa5,
    0x8f8c8c03, 0xf8a1a159, 0x80898909, 0x170d0d1a, 0xdabfbf65, 0x31e6e6d7, 0xc6424284, 0xb86868d0,
    0xc3414182, 0xb0999929, 0x772d2d5a, 0x110f0f1e, 0xcbb0b07b, 0xfc5454a8, 0xd6bbbb6d, 0x3a16162c,
    0x6363c6a5, 0x7c7cf884, 0x7777ee99, 0x7b7bf68d, 0xf2f2ff0d, 0x6b6bd6bd, 0x6f6fdeb1, 0xc5c59154,
    0x30306050, 0x01010203, 0x6767cea9, 0x2b2b567d, 0xfefee719, 0xd7d7b562, 0xabab4de6, 0x7676ec9a,
    0xcaca8f45, 0x82821f9d, 0xc9c98940, 0x7d7dfa87, 0xfafaef15, 0x5959b2eb, 0x47478ec9, 0xf0f0fb0b,
    0xadad41ec, 0xd4d4b367, 0xa2a25ffd, 0xafaf45ea, 0x9c9c23bf, 0xa4a453f7, 0x7272e496, 0xc0c09b5b,
    0xb7b775c2, 0xfdfde11c, 0x93933dae, 0x26264c6a, 0x36366c5a, 0x3f3f7e41, 0xf7f7f502, 0xcccc834f,
    0x3434685c, 0xa5a551f4, 0xe5e5d134, 0xf1f1f908, 0x7171e293, 0xd8d8ab73, 0x31316253, 0x15152a3f,
    0x0404080c, 0xc7c79552, 0x23234665, 0xc3c39d5e, 0x18183028, 0x969637a1, 0x05050a0f, 0x9a9a2fb5,
    0x07070e09, 0x12122436, 0x80801b9b, 0xe2e2df3d, 0xebebcd26, 0x27274e69, 0xb2b27fcd, 0x7575ea9f,
    0x0909121b, 0x83831d9e, 0x2c2c5874, 0x1a1a342e, 0x1b1b362d, 0x6e6edcb2, 0x5a5ab4ee, 0xa0a05bfb,
    0x5252a4f6, 0x3b3b764d, 0xd6d6b761, 0xb3b37dce, 0x2929527b, 0xe3e3dd3e, 0x2f2f5e71, 0x84841397,
    0x5353a6f5, 0xd1d1b968, 0x00000000, 0xededc12c, 0x20204060, 0xfcfce31f, 0xb1b179c8, 0x5b5bb6ed,
    0x6a6ad4be, 0xcbcb8d46, 0xbebe67d9, 0x3939724b, 0x4a4a94de, 0x4c4c98d4, 0x5858b0e8, 0xcfcf854a,
    0xd0d0bb6b, 0xefefc52a, 0xaaaa4fe5, 0xfbfbed16, 0x434386c5, 0x4d4d9ad7, 0x33336655, 0x85851194,
    0x45458acf, 0xf9f9e910, 0x02020406, 0x7f7ffe81, 0x5050a0f0, 0x3c3c7844, 0x9f9f25ba, 0xa8a84be3,
    0x5151a2f3, 0xa3a35dfe, 0x404080c0, 0x8f8f058a, 0x92923fad, 0x9d9d21bc, 0x38387048, 0xf5f5f104,
    0xbcbc63df, 0xb6b677c1, 0xdadaaf75, 0x21214263, 0x10102030, 0xffffe51a, 0xf3f3fd0e, 0xd2d2bf6d,
    0xcdcd814c, 0x0c0c1814, 0x13132635, 0xececc32f, 0x5f5fbee1, 0x979735a2, 0x444488cc, 0x17172e39,
    0xc4c49357, 0xa7a755f2, 0x7e7efc82, 0x3d3d7a47, 0x6464c8ac, 0x5d5dbae7, 0x1919322b, 0x7373e695,
    0x6060c0a0, 0x81811998, 0x4f4f9ed1, 0xdcdca37f, 0x22224466, 0x2a2a547e, 0x90903bab, 0x88880b83,
    0x46468cca, 0xeeeec729, 0xb8b86bd3, 0x1414283c, 0xdedea779, 0x5e5ebce2, 0x0b0b161d, 0xdbdbad76,
    0xe0e0db3b, 0x32326456, 0x3a3a744e, 0x0a0a141e, 0x494992db, 0x06060c0a, 0x2424486c, 0x5c5cb8e4,
    0xc2c29f5d, 0xd3d3bd6e, 0xacac43ef, 0x6262c4a6, 0x919139a8, 0x959531a4, 0xe4e4d337, 0x7979f28b,
    0xe7e7d532, 0xc8c88b43, 0x37376e59, 0x6d6ddab7, 0x8d8d018c, 0xd5d5b164, 0x4e4e9cd2, 0xa9a949e0,
    0x6c6cd8b4, 0x5656acfa, 0xf4f4f307, 0xeaeacf25, 0x6565caaf, 0x7a7af48e, 0xaeae47e9, 0x08081018,
    0xbaba6fd5, 0x7878f088, 0x25254a6f, 0x2e2e5c72, 0x1c1c3824, 0xa6a657f1, 0xb4b473c7, 0xc6c69751,
    0xe8e8cb23, 0xdddda17c, 0x7474e89c, 0x1f1f3e21, 0x4b4b96dd, 0xbdbd61dc, 0x8b8b0d86, 0x8a8a0f85,
    0x7070e090, 0x3e3e7c42, 0xb5b571c4, 0x6666ccaa, 0x484890d8, 0x03030605, 0xf6f6f701, 0x0e0e1c12,
    0x6161c2a3, 0x35356a5f, 0x5757aef9, 0xb9b969d0, 0x86861791, 0xc1c19958, 0x1d1d3a27, 0x9e9e27b9,
    0xe1e1d938, 0xf8f8eb13, 0x98982bb3, 0x11112233, 0x6969d2bb, 0xd9d9a970, 0x8e8e0789, 0x949433a7,
    0x9b9b2db6, 0x1e1e3c22, 0x87871592, 0xe9e9c920, 0xcece8749, 0x5555aaff, 0x28285078, 0xdfdfa57a,
    0x8c8c038f, 0xa1a159f8, 0x89890980, 0x0d0d1a17, 0xbfbf65da, 0xe6e6d731, 0x424284c6, 0x6868d0b8,
    0x414182c3, 0x999929b0, 0x2d2d5a77, 0x0f0f1e11, 0xb0b07bcb, 0x5454a8fc, 0xbbbb6dd6, 0x16162c3a,
    0x63c6a563, 0x7cf8847c, 0x77ee9977, 0x7bf68d7b, 0xf2ff0df2, 0x6bd6bd6b, 0x6fdeb16f, 0xc59154c5,
    0x30605030, 0x01020301, 0x67cea967, 0x2b567d2b, 0xfee719fe, 0xd7b562d7, 0xab4de6ab, 0x76ec9a76,
    0xca8f45ca, 0x821f9d82, 0xc98940c9, 0x7dfa877d, 0xfaef15fa, 0x59b2eb59, 0x478ec947, 0xf0fb0bf0,
    0xad41ecad, 0xd4b367d4, 0xa25ffda2, 0xaf45eaaf, 0x9c23bf9c, 0xa453f7a4, 0x72e49672, 0xc09b5bc0,
    0xb775c2b7, 0xfde11cfd, 0x933dae93, 0x264c6a26, 0x366c5a36, 0x3f7e413f, 0xf7f502f7, 0xcc834fcc,
    0x34685c34, 0xa551f4a5, 0xe5d134e5, 0xf1f908f1, 0x71e29371, 0xd8ab73d8, 0x31625331, 0x152a3f15,
    0x04080c04, 0xc79552c7, 0x23466523, 0xc39d5ec3, 0x18302818, 0x9637a196, 0x050a0f05, 0x9a2fb59a,
    0x070e0907, 0x12243612, 0x801b9b80, 0xe2df3de2, 0xebcd26eb, 0x274e6927, 0xb27fcdb2, 0x75ea9f75,
    0x09121b09, 0x831d9e83, 0x2c58742c, 0x1a342e1a, 0x1b362d1b, 0x6edcb26e, 0x5ab4ee5a, 0xa05bfba0,
    0x52a4f652, 0x3b764d3b, 0xd6b761d6, 0xb37dceb3, 0x29527b29, 0xe3dd3ee3, 0x2f5e712f, 0x84139784,
    0x53a6f553, 0xd1b968d1, 0x00000000, 0xedc12ced, 0x20406020, 0xfce31ffc, 0xb179c8b1, 0x5bb6ed5b,
    0x6ad4be6a, 0xcb8d46cb, 0xbe67d9be, 0x39724b39, 0x4a94de4a, 0x4c98d44c, 0x58b0e858, 0xcf854acf,
    0xd0bb6bd0, 0xefc52aef, 0xaa4fe5aa, 0xfbed16fb, 0x4386c543, 0x4d9ad74d, 0x33665533, 0x85119485,
    0x458acf45, 0xf9e910f9, 0x02040602, 0x7ffe817f, 0x50a0f050, 0x3c78443c, 0x9f25ba9f, 0xa84be3a8,
    0x51a2f351, 0xa35dfea3, 0x4080c040, 0x8f058a8f, 0x923fad92, 0x9d21bc9d, 0x38704838, 0xf5f104f5,
    0xbc63dfbc, 0xb677c1b6, 0xdaaf75da, 0x21426321, 0x10203010, 0xffe51aff, 0xf3fd0ef3, 0xd2bf6dd2,
    0xcd814ccd, 0x0c18140c, 0x13263513, 0xecc32fec, 0x5fbee15f, 0x9735a297, 0x4488cc44, 0x172e3917,
    0xc49357c4, 0xa755f2a7, 0x7efc827e, 0x3d7a473d, 0x64c8ac64, 0x5dbae75d, 0x19322b19, 0x73e69573,
    0x60c0a060, 0x81199881, 0x4f9ed14f, 0xdca37fdc, 0x22446622, 0x2a547e2a, 0x903bab90, 0x880b8388,
    0x468cca46, 0xeec729ee, 0xb86bd3b8, 0x14283c14, 0xdea779de, 0x5ebce25e, 0x0b161d0b, 0xdbad76db,
    0xe0db3be0, 0x32645632, 0x3a744e3a, 0x0a141e0a, 0x4992db49, 0x060c0a06, 0x24486c24, 0x5cb8e45c,
    0xc29f5dc2, 0xd3bd6ed3, 0xac43efac, 0x62c4a662, 0x9139a891, 0x9531a495, 0xe4d337e4, 0x79f28b79,
    0xe7d532e7, 0xc88b43c8, 0x376e5937, 0x6ddab76d, 0x8d018c8d, 0xd5b164d5, 0x4e9cd24e, 0xa949e0a9,
    0x6cd8b46c, 0x56acfa56, 0xf4f307f4, 0xeacf25ea, 0x65caaf65, 0x7af48e7a, 0xae47e9ae, 0x08101808,
    0xba6fd5ba, 0x78f08878, 0x254a6f25, 0x2e5c722e, 0x1c38241c, 0xa657f1a6, 0xb473c7b4, 0xc69751c6,
    0xe8cb23e8, 0xdda17cdd, 0x74e89c74, 0x1f3e211f, 0x4b96dd4b, 0xbd61dcbd, 0x8b0d868b, 0x8a0f858a,
    0x70e09070, 0x3e7c423e, 0xb571c4b5, 0x66ccaa66, 0x4890d848, 0x03060503, 0xf6f701f6, 0x0e1c120e,
    0x61c2a361, 0x356a5f35, 0x57aef957, 0xb969d0b9, 0x86179186, 0xc19958c1, 0x1d3a271d, 0x9e27b99e,
    0xe1d938e1, 0xf8eb13f8, 0x982bb398, 0x11223311, 0x69d2bb69, 0xd9a970d9, 0x8e07898e, 0x9433a794,
    0x9b2db69b, 0x1e3c221e, 0x87159287, 0xe9c920e9, 0xce8749ce, 0x55aaff55, 0x28507828, 0xdfa57adf,
    0x8c038f8c, 0xa159f8a1, 0x89098089, 0x0d1a170d, 0xbf65dabf, 0xe6d731e6, 0x4284c642, 0x68d0b868,
    0x4182c341, 0x9929b099, 0x2d5a772d, 0x0f1e110f, 0xb07bcbb0, 0x54a8fc54, 0xbb6dd6bb, 0x162c3a16,
    0xc6a56363, 0xf8847c7c, 0xee997777, 0xf68d7b7b, 0xff0df2f2, 0xd6bd6b6b, 0xdeb16f6f, 0x9154c5c5,
    0x60503030, 0x02030101, 0xcea96767, 0x567d2b2b, 0xe719fefe, 0xb562d7d7, 0x4de6abab, 0xec9a7676,
    0x8f45caca, 0x1f9d8282, 0x8940c9c9, 0xfa877d7d, 0xef15fafa, 0xb2eb5959, 0x8ec94747, 0xfb0bf0f0,
    0x41ecadad, 0xb367d4d4, 0x5ffda2a2, 0x45eaafaf, 0x23bf9c9c, 0x53f7a4a4, 0xe4967272, 0x9b5bc0c0,
    0x75c2b7b7, 0xe11cfdfd, 0x3dae9393, 0x4c6a2626, 0x6c5a3636, 0x7e413f3f, 0xf502f7f7, 0x834fcccc,
    0x685c3434, 0x51f4a5a5, 0xd134e5e5, 0xf908f1f1, 0xe2937171, 0xab73d8d8, 0x62533131, 0x2a3f1515,
    0x080c0404, 0x9552c7c7, 0x46652323, 0x9d5ec3c3, 0x30281818, 0x37a19696, 0x0a0f0505, 0x2fb59a9a,
    0x0e090707, 0x24361212, 0x1b9b8080, 0xdf3de2e2, 0xcd26ebeb, 0x4e692727, 0x7fcdb2b2, 0xea9f7575,
    0x121b0909, 0x1d9e8383, 0x58742c2c, 0x342e1a1a, 0x362d1b1b, 0xdcb26e6e, 0xb4ee5a5a, 0x5bfba0a0,
    0xa4f65252, 0x764d3b3b, 0xb761d6d6, 0x7dceb3b3, 0x527b2929, 0xdd3ee3e3, 0x5e712f2f, 0x13978484,
    0xa6f55353, 0xb968d1d1, 0x00000000, 0xc12ceded, 0x40602020, 0xe31ffcfc, 0x79c8b1b1, 0xb6ed5b5b,
    0xd4be6a6a, 0x8d46cbcb, 0x67d9bebe, 0x724b3939, 0x94de4a4a, 0x98d44c4c, 0xb0e85858, 0x854acfcf,
    0xbb6bd0d0, 0xc52aefef, 0x4fe5aaaa, 0xed16fbfb, 0x86c54343, 0x9ad74d4d, 0x66553333, 0x11948585,
    0x8acf4545, 0xe910f9f9, 0x04060202, 0xfe817f7f, 0xa0f05050, 0x78443c3c, 0x25ba9f9f, 0x4be3a8a8,
    0xa2f35151, 0x5dfea3a3, 0x80c04040, 0x058a8f8f, 0x3fad9292, 0x21bc9d9d, 0x70483838, 0xf104f5f5,
    0x63dfbcbc, 0x77c1b6b6, 0xaf75dada, 0x42632121, 0x20301010, 0xe51affff, 0xfd0ef3f3, 0xbf6dd2d2,
    0x814ccdcd, 0x18140c0c, 0x26351313, 0xc32fecec, 0xbee15f5f, 0x35a29797, 0x88cc4444, 0x2e391717,
    0x9357c4c4, 0x55f2a7a7, 0xfc827e7e, 0x7a473d3d, 0xc8ac6464, 0xbae75d5d, 0x322b1919, 0xe6957373,
    0xc0a06060, 0x19988181, 0x9ed14f4f, 0xa37fdcdc, 0x44662222, 0x547e2a2a, 0x3bab9090, 0x0b838888,
    0x8cca4646, 0xc729eeee, 0x6bd3b8b8, 0x283c1414, 0xa779dede, 0xbce25e5e, 0x161d0b0b, 0xad76dbdb,
    0xdb3be0e0, 0x64563232, 0x744e3a3a, 0x141e0a0a, 0x92db4949, 0x0c0a0606, 0x486c2424, 0xb8e45c5c,
    0x9f5dc2c2, 0xbd6ed3d3, 0x43efacac, 0xc4a66262, 0x39a89191, 0x31a49595, 0xd337e4e4, 0xf28b7979,
    0xd532e7e7, 0x8b43c8c8, 0x6e593737, 0xdab76d6d, 0x018c8d8d, 0xb164d5d5, 0x9cd24e4e, 0x49e0a9a9,
    0xd8b46c6c, 0xacfa5656, 0xf307f4f4, 0xcf25eaea, 0xcaaf6565, 0xf48e7a7a, 0x47e9aeae, 0x10180808,
    0x6fd5baba, 0xf0887878, 0x4a6f2525, 0x5c722e2e, 0x38241c1c, 0x57f1a6a6, 0x73c7b4b4, 0x9751c6c6,
    0xcb23e8e8, 0xa17cdddd, 0xe89c7474, 0x3e211f1f, 0x96dd4b4b, 0x61dcbdbd, 0x0d868b8b, 0x0f858a8a,
    0xe0907070, 0x7c423e3e, 0x71c4b5b5, 0xccaa6666, 0x90d84848, 0x06050303, 0xf701f6f6, 0x1c120e0e,
    0xc2a36161, 0x6a5f3535, 0xaef95757, 0x69d0b9b9, 0x17918686, 0x9958c1c1, 0x3a271d1d, 0x27b99e9e,
    0xd938e1e1, 0xeb13f8f8, 0x2bb39898, 0x22331111, 0xd2bb6969, 0xa970d9d9, 0x07898e8e, 0x33a79494,
    0x2db69b9b, 0x3c221e1e, 0x15928787, 0xc920e9e9, 0x8749cece, 0xaaff5555, 0x50782828, 0xa57adfdf,
    0x038f8c8c, 0x59f8a1a1, 0x09808989, 0x1a170d0d, 0x65dabfbf, 0xd731e6e6, 0x84c64242, 0xd0b86868,
    0x82c34141, 0x29b09999, 0x5a772d2d, 0x1e110f0f, 0x7bcbb0b0, 0xa8fc5454, 0x6dd6bbbb, 0x2c3a1616
};

static const uint32_t* const LUT0 = _aes_lut + 0 * 256;
static const uint32_t* const LUT1 = _aes_lut + 1 * 256;
static const uint32_t* const LUT2 = _aes_lut + 2 * 256;
static const uint32_t* const LUT3 = _aes_lut + 3 * 256;

static SoftAesBlock
_encrypt(const uint8_t ix0[4], const uint8_t ix1[4], const uint8_t ix2[4], const uint8_t ix3[4])
{
    SoftAesBlock out;

    out.w0 = LUT0[ix0[0]];
    out.w1 = LUT0[ix0[1]];
    out.w2 = LUT0[ix0[2]];
    out.w3 = LUT0[ix0[3]];

    out.w0 ^= LUT1[ix1[0]];
    out.w1 ^= LUT1[ix1[1]];
    out.w2 ^= LUT1[ix1[2]];
    out.w3 ^= LUT1[ix1[3]];

    out.w0 ^= LUT2[ix2[0]];
    out.w1 ^= LUT2[ix2[1]];
    out.w2 ^= LUT2[ix2[2]];
    out.w3 ^= LUT2[ix2[3]];

    out.w0 ^= LUT3[ix3[0]];
    out.w1 ^= LUT3[ix3[1]];
    out.w2 ^= LUT3[ix3[2]];
    out.w3 ^= LUT3[ix3[3]];

    return out;
}

#else

uint32_t _aes_lut[256] __attribute__((visibility("hidden"))) = {
    0xa56363c6, 0x847c7cf8, 0x997777ee, 0x8d7b7bf6, 0x0df2f2ff, 0xbd6b6bd6, 0xb16f6fde, 0x54c5c591,
    0x50303060, 0x03010102, 0xa96767ce, 0x7d2b2b56, 0x19fefee7, 0x62d7d7b5, 0xe6abab4d, 0x9a7676ec,
    0x45caca8f, 0x9d82821f, 0x40c9c989, 0x877d7dfa, 0x15fafaef, 0xeb5959b2, 0xc947478e, 0x0bf0f0fb,
    0xecadad41, 0x67d4d4b3, 0xfda2a25f, 0xeaafaf45, 0xbf9c9c23, 0xf7a4a453, 0x967272e4, 0x5bc0c09b,
    0xc2b7b775, 0x1cfdfde1, 0xae93933d, 0x6a26264c, 0x5a36366c, 0x413f3f7e, 0x02f7f7f5, 0x4fcccc83,
    0x5c343468, 0xf4a5a551, 0x34e5e5d1, 0x08f1f1f9, 0x937171e2, 0x73d8d8ab, 0x53313162, 0x3f15152a,
    0x0c040408, 0x52c7c795, 0x65232346, 0x5ec3c39d, 0x28181830, 0xa1969637, 0x0f05050a, 0xb59a9a2f,
    0x0907070e, 0x36121224, 0x9b80801b, 0x3de2e2df, 0x26ebebcd, 0x6927274e, 0xcdb2b27f, 0x9f7575ea,
    0x1b090912, 0x9e83831d, 0x742c2c58, 0x2e1a1a34, 0x2d1b1b36, 0xb26e6edc, 0xee5a5ab4, 0xfba0a05b,
    0xf65252a4, 0x4d3b3b76, 0x61d6d6b7, 0xceb3b37d, 0x7b292952, 0x3ee3e3dd, 0x712f2f5e, 0x97848413,
    0xf55353a6, 0x68d1d1b9, 0x00000000, 0x2cededc1, 0x60202040, 0x1ffcfce3, 0xc8b1b179, 0xed5b5bb6,
    0xbe6a6ad4, 0x46cbcb8d, 0xd9bebe67, 0x4b393972, 0xde4a4a94, 0xd44c4c98, 0xe85858b0, 0x4acfcf85,
    0x6bd0d0bb, 0x2aefefc5, 0xe5aaaa4f, 0x16fbfbed, 0xc5434386, 0xd74d4d9a, 0x55333366, 0x94858511,
    0xcf45458a, 0x10f9f9e9, 0x06020204, 0x817f7ffe, 0xf05050a0, 0x443c3c78, 0xba9f9f25, 0xe3a8a84b,
    0xf35151a2, 0xfea3a35d, 0xc0404080, 0x8a8f8f05, 0xad92923f, 0xbc9d9d21, 0x48383870, 0x04f5f5f1,
    0xdfbcbc63, 0xc1b6b677, 0x75dadaaf, 0x63212142, 0x30101020, 0x1affffe5, 0x0ef3f3fd, 0x6dd2d2bf,
    0x4ccdcd81, 0x140c0c18, 0x35131326, 0x2fececc3, 0xe15f5fbe, 0xa2979735, 0xcc444488, 0x3917172e,
    0x57c4c493, 0xf2a7a755, 0x827e7efc, 0x473d3d7a, 0xac6464c8, 0xe75d5dba, 0x2b191932, 0x957373e6,
    0xa06060c0, 0x98818119, 0xd14f4f9e, 0x7fdcdca3, 0x66222244, 0x7e2a2a54, 0xab90903b, 0x8388880b,
    0xca46468c, 0x29eeeec7, 0xd3b8b86b, 0x3c141428, 0x79dedea7, 0xe25e5ebc, 0x1d0b0b16, 0x76dbdbad,
    0x3be0e0db, 0x56323264, 0x4e3a3a74, 0x1e0a0a14, 0xdb494992, 0x0a06060c, 0x6c242448, 0xe45c5cb8,
    0x5dc2c29f, 0x6ed3d3bd, 0xefacac43, 0xa66262c4, 0xa8919139, 0xa4959531, 0x37e4e4d3, 0x8b7979f2,
    0x32e7e7d5, 0x43c8c88b, 0x5937376e, 0xb76d6dda, 0x8c8d8d01, 0x64d5d5b1, 0xd24e4e9c, 0xe0a9a949,
    0xb46c6cd8, 0xfa5656ac, 0x07f4f4f3, 0x25eaeacf, 0xaf6565ca, 0x8e7a7af4, 0xe9aeae47, 0x18080810,
    0xd5baba6f, 0x887878f0, 0x6f25254a, 0x722e2e5c, 0x241c1c38, 0xf1a6a657, 0xc7b4b473, 0x51c6c697,
    0x23e8e8cb, 0x7cdddda1, 0x9c7474e8, 0x211f1f3e, 0xdd4b4b96, 0xdcbdbd61, 0x868b8b0d, 0x858a8a0f,
    0x907070e0, 0x423e3e7c, 0xc4b5b571, 0xaa6666cc, 0xd8484890, 0x05030306, 0x01f6f6f7, 0x120e0e1c,
    0xa36161c2, 0x5f35356a, 0xf95757ae, 0xd0b9b969, 0x91868617, 0x58c1c199, 0x271d1d3a, 0xb99e9e27,
    0x38e1e1d9, 0x13f8f8eb, 0xb398982b, 0x33111122, 0xbb6969d2, 0x70d9d9a9, 0x898e8e07, 0xa7949433,
    0xb69b9b2d, 0x221e1e3c, 0x92878715, 0x20e9e9c9, 0x49cece87, 0xff5555aa, 0x78282850, 0x7adfdfa5,
    0x8f8c8c03, 0xf8a1a159, 0x80898909, 0x170d0d1a, 0xdabfbf65, 0x31e6e6d7, 0xc6424284, 0xb86868d0,
    0xc3414182, 0xb0999929, 0x772d2d5a, 0x110f0f1e, 0xcbb0b07b, 0xfc5454a8, 0xd6bbbb6d, 0x3a16162c
};

static const uint32_t* const LUT = _aes_lut;

static SoftAesBlock
_encrypt(const uint8_t ix0[4], const uint8_t ix1[4], const uint8_t ix2[4], const uint8_t ix3[4])
{
    CRYPTO_ALIGN(64) uint32_t     t[4][4][256 / SOFTAES_STRIDE];
    CRYPTO_ALIGN(64) uint8_t      of[4][4];
    CRYPTO_ALIGN(64) SoftAesBlock out;
    size_t                        i;
    size_t                        j;

    for (j = 0; j < 4; j++) {
        of[j][0] = ix0[j] % SOFTAES_STRIDE;
        of[j][1] = ix1[j] % SOFTAES_STRIDE;
        of[j][2] = ix2[j] % SOFTAES_STRIDE;
        of[j][3] = ix3[j] % SOFTAES_STRIDE;
    }
    for (i = 0; i < 256 / SOFTAES_STRIDE; i++) {
        for (j = 0; j < 4; j++) {
            t[j][0][i] = LUT[(i * SOFTAES_STRIDE) | of[j][0]];
            t[j][1][i] = LUT[(i * SOFTAES_STRIDE) | of[j][1]];
            t[j][2][i] = LUT[(i * SOFTAES_STRIDE) | of[j][2]];
            t[j][3][i] = LUT[(i * SOFTAES_STRIDE) | of[j][3]];
        }
    }

#    if defined(__GNUC__) || defined(__clang__)
    __asm__ __volatile__("" : : "r"(t) : "memory");
#    endif

    out.w0 = t[0][0][ix0[0] / SOFTAES_STRIDE];
    out.w0 ^= ROTL32(t[0][1][ix1[0] / SOFTAES_STRIDE], 8);
    out.w0 ^= ROTL32(t[0][2][ix2[0] / SOFTAES_STRIDE], 16);
    out.w0 ^= ROTL32(t[0][3][ix3[0] / SOFTAES_STRIDE], 24);

    out.w1 = t[1][0][ix0[1] / SOFTAES_STRIDE];
    out.w1 ^= ROTL32(t[1][1][ix1[1] / SOFTAES_STRIDE], 8);
    out.w1 ^= ROTL32(t[1][2][ix2[1] / SOFTAES_STRIDE], 16);
    out.w1 ^= ROTL32(t[1][3][ix3[1] / SOFTAES_STRIDE], 24);

    out.w2 = t[2][0][ix0[2] / SOFTAES_STRIDE];
    out.w2 ^= ROTL32(t[2][1][ix1[2] / SOFTAES_STRIDE], 8);
    out.w2 ^= ROTL32(t[2][2][ix2[2] / SOFTAES_STRIDE], 16);
    out.w2 ^= ROTL32(t[2][3][ix3[2] / SOFTAES_STRIDE], 24);

    out.w3 = t[3][0][ix0[3] / SOFTAES_STRIDE];
    out.w3 ^= ROTL32(t[3][1][ix1[3] / SOFTAES_STRIDE], 8);
    out.w3 ^= ROTL32(t[3][2][ix2[3] / SOFTAES_STRIDE], 16);
    out.w3 ^= ROTL32(t[3][3][ix3[3] / SOFTAES_STRIDE], 24);

    return out;
}
#endif

static inline SoftAesBlock
softaes_block_aesl(const SoftAesBlock block)
{
    uint8_t        ix0[4], ix1[4], ix2[4], ix3[4];
    const uint32_t s0 = block.w0;
    const uint32_t s1 = block.w1;
    const uint32_t s2 = block.w2;
    const uint32_t s3 = block.w3;

    ix0[0] = (uint8_t) s0;
    ix0[1] = (uint8_t) s1;
    ix0[2] = (uint8_t) s2;
    ix0[3] = (uint8_t) s3;

    ix1[0] = (uint8_t) (s1 >> 8);
    ix1[1] = (uint8_t) (s2 >> 8);
    ix1[2] = (uint8_t) (s3 >> 8);
    ix1[3] = (uint8_t) (s0 >> 8);

    ix2[0] = (uint8_t) (s2 >> 16);
    ix2[1] = (uint8_t) (s3 >> 16);
    ix2[2] = (uint8_t) (s0 >> 16);
    ix2[3] = (uint8_t) (s1 >> 16);

    ix3[0] = (uint8_t) (s3 >> 24);
    ix3[1] = (uint8_t) (s0 >> 24);
    ix3[2] = (uint8_t) (s1 >> 24);
    ix3[3] = (uint8_t) (s2 >> 24);

    return _encrypt(ix0, ix1, ix2, ix3);
}

static inline SoftAesBlock
softaes_block_xaesl(SoftAesBlock block, const SoftAesBlock prk)
{
    block.w0 ^= prk.w0;
    block.w1 ^= prk.w1;
    block.w2 ^= prk.w2;
    block.w3 ^= prk.w3;

    return softaes_block_aesl(block);
}

static inline SoftAesBlock
softaes_block_encrypt(const SoftAesBlock block, const SoftAesBlock rk)
{

    SoftAesBlock out = softaes_block_aesl(block);
    out.w0 ^= rk.w0;
    out.w1 ^= rk.w1;
    out.w2 ^= rk.w2;
    out.w3 ^= rk.w3;

    return out;
}



/* =====================================================
 * HiAE_software.c - hiae_software implementation
 * =====================================================
 */

// Only compile software implementation if hardware AES+VAES+AVX512 is not available
#if !((defined(__AES__) && defined(__VAES__) && defined(__AVX512F__)) || \
      defined(__ARM_FEATURE_CRYPTO))

#    define FAVOR_PERFORMANCE

typedef SoftAesBlock hiae_software_DATA128b;
#    define hiae_software_SIMD_LOAD(x)     softaes_block_load(x)
#    define hiae_software_SIMD_STORE(x, y) softaes_block_store(x, y)
#    define hiae_software_SIMD_XOR(x, y)   softaes_block_xor(x, y)
#    define hiae_software_SIMD_AND(x, y)   softaes_block_and(x, y)
#    define hiae_software_SIMD_ZERO_128()  softaes_block_zero()
#    define hiae_software_AESL(x)          softaes_block_aesl(x)
#    define hiae_software_XAESL(x, y)      softaes_block_xaesl(x, y)

static inline void
hiae_software_update_state_offset(hiae_software_DATA128b *state, hiae_software_DATA128b *tmp, hiae_software_DATA128b M, int offset)
{
    tmp[offset] = hiae_software_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    tmp[offset] = hiae_software_SIMD_XOR(tmp[offset], M);
    state[(0 + offset) % STATE]   = hiae_software_SIMD_XOR(tmp[offset], hiae_software_AESL(state[(P_4 + offset) % STATE]));
    state[(I_1 + offset) % STATE] = hiae_software_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_software_SIMD_XOR(state[(I_2 + offset) % STATE], M);
}

static inline hiae_software_DATA128b
hiae_software_keystream_block(hiae_software_DATA128b *state, hiae_software_DATA128b M, int offset)
{
    hiae_software_DATA128b tmp = hiae_software_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    M            = hiae_software_SIMD_XOR(hiae_software_SIMD_XOR(tmp, M), state[(P_7 + offset) % STATE]);
    return M;
}

static inline hiae_software_DATA128b
hiae_software_enc_offset(hiae_software_DATA128b *state, hiae_software_DATA128b M, int offset)
{
    hiae_software_DATA128b C = hiae_software_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    C          = hiae_software_SIMD_XOR(C, M);
    state[(0 + offset) % STATE]   = hiae_software_SIMD_XOR(C, hiae_software_AESL(state[(P_4 + offset) % STATE]));
    C                             = hiae_software_SIMD_XOR(C, state[(P_7 + offset) % STATE]);
    state[(I_1 + offset) % STATE] = hiae_software_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_software_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return C;
}

static inline hiae_software_DATA128b
hiae_software_dec_offset(hiae_software_DATA128b *state, hiae_software_DATA128b *tmp, hiae_software_DATA128b C, int offset)
{
    tmp[offset] = hiae_software_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    hiae_software_DATA128b M  = hiae_software_SIMD_XOR(state[(P_7 + offset) % STATE], C);
    state[(0 + offset) % STATE]   = hiae_software_SIMD_XOR(M, hiae_software_AESL(state[(P_4 + offset) % STATE]));
    M                             = hiae_software_SIMD_XOR(M, tmp[offset]);
    state[(I_1 + offset) % STATE] = hiae_software_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_software_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return M;
}

#    define hiae_software_LOAD_1BLOCK_offset_enc(M, offset)  (M) = hiae_software_SIMD_LOAD(mi + i + 0 + BLOCK_SIZE * offset);
#    define hiae_software_LOAD_1BLOCK_offset_dec(C, offset)  (C) = hiae_software_SIMD_LOAD(ci + i + 0 + BLOCK_SIZE * offset);
#    define hiae_software_LOAD_1BLOCK_offset_ad(M, offset)   (M) = hiae_software_SIMD_LOAD(ad + i + 0 + BLOCK_SIZE * offset);
#    define hiae_software_STORE_1BLOCK_offset_enc(C, offset) hiae_software_SIMD_STORE(ci + i + 0 + BLOCK_SIZE * offset, (C));
#    define hiae_software_STORE_1BLOCK_offset_dec(M, offset) hiae_software_SIMD_STORE(mi + i + 0 + BLOCK_SIZE * offset, (M));

static inline void
hiae_software_state_shift(hiae_software_DATA128b *state, hiae_software_DATA128b *tmp)
{
    tmp[0]    = state[0];
    state[0]  = state[1];
    state[1]  = state[2];
    state[2]  = state[3];
    state[3]  = state[4];
    state[4]  = state[5];
    state[5]  = state[6];
    state[6]  = state[7];
    state[7]  = state[8];
    state[8]  = state[9];
    state[9]  = state[10];
    state[10] = state[11];
    state[11] = state[12];
    state[12] = state[13];
    state[13] = state[14];
    state[14] = state[15];
    state[15] = tmp[0];
}

static inline void
hiae_software_init_update(hiae_software_DATA128b *state, hiae_software_DATA128b *tmp, hiae_software_DATA128b c0)
{
    hiae_software_update_state_offset(state, tmp, c0, 0);
    hiae_software_update_state_offset(state, tmp, c0, 1);
    hiae_software_update_state_offset(state, tmp, c0, 2);
    hiae_software_update_state_offset(state, tmp, c0, 3);
    hiae_software_update_state_offset(state, tmp, c0, 4);
    hiae_software_update_state_offset(state, tmp, c0, 5);
    hiae_software_update_state_offset(state, tmp, c0, 6);
    hiae_software_update_state_offset(state, tmp, c0, 7);
    hiae_software_update_state_offset(state, tmp, c0, 8);
    hiae_software_update_state_offset(state, tmp, c0, 9);
    hiae_software_update_state_offset(state, tmp, c0, 10);
    hiae_software_update_state_offset(state, tmp, c0, 11);
    hiae_software_update_state_offset(state, tmp, c0, 12);
    hiae_software_update_state_offset(state, tmp, c0, 13);
    hiae_software_update_state_offset(state, tmp, c0, 14);
    hiae_software_update_state_offset(state, tmp, c0, 15);
}

static inline void
hiae_software_ad_update(hiae_software_DATA128b *state, hiae_software_DATA128b *tmp, const uint8_t *ad, size_t i)
{
    hiae_software_DATA128b M[16];
    hiae_software_LOAD_1BLOCK_offset_ad(M[0], 0);
    hiae_software_LOAD_1BLOCK_offset_ad(M[1], 1);
    hiae_software_LOAD_1BLOCK_offset_ad(M[2], 2);
    hiae_software_LOAD_1BLOCK_offset_ad(M[3], 3);
    hiae_software_LOAD_1BLOCK_offset_ad(M[4], 4);
    hiae_software_LOAD_1BLOCK_offset_ad(M[5], 5);
    hiae_software_LOAD_1BLOCK_offset_ad(M[6], 6);
    hiae_software_LOAD_1BLOCK_offset_ad(M[7], 7);
    hiae_software_LOAD_1BLOCK_offset_ad(M[8], 8);
    hiae_software_LOAD_1BLOCK_offset_ad(M[9], 9);
    hiae_software_LOAD_1BLOCK_offset_ad(M[10], 10);
    hiae_software_LOAD_1BLOCK_offset_ad(M[11], 11);
    hiae_software_LOAD_1BLOCK_offset_ad(M[12], 12);
    hiae_software_LOAD_1BLOCK_offset_ad(M[13], 13);
    hiae_software_LOAD_1BLOCK_offset_ad(M[14], 14);
    hiae_software_LOAD_1BLOCK_offset_ad(M[15], 15);
    hiae_software_update_state_offset(state, tmp, M[0], 0);
    hiae_software_update_state_offset(state, tmp, M[1], 1);
    hiae_software_update_state_offset(state, tmp, M[2], 2);
    hiae_software_update_state_offset(state, tmp, M[3], 3);
    hiae_software_update_state_offset(state, tmp, M[4], 4);
    hiae_software_update_state_offset(state, tmp, M[5], 5);
    hiae_software_update_state_offset(state, tmp, M[6], 6);
    hiae_software_update_state_offset(state, tmp, M[7], 7);
    hiae_software_update_state_offset(state, tmp, M[8], 8);
    hiae_software_update_state_offset(state, tmp, M[9], 9);
    hiae_software_update_state_offset(state, tmp, M[10], 10);
    hiae_software_update_state_offset(state, tmp, M[11], 11);
    hiae_software_update_state_offset(state, tmp, M[12], 12);
    hiae_software_update_state_offset(state, tmp, M[13], 13);
    hiae_software_update_state_offset(state, tmp, M[14], 14);
    hiae_software_update_state_offset(state, tmp, M[15], 15);
}

static inline void
hiae_software_encrypt_chunk(hiae_software_DATA128b *state, const uint8_t *mi, uint8_t *ci, size_t i)
{
    hiae_software_DATA128b M[16], C[16];
    hiae_software_LOAD_1BLOCK_offset_enc(M[0], 0);
    hiae_software_LOAD_1BLOCK_offset_enc(M[1], 1);
    hiae_software_LOAD_1BLOCK_offset_enc(M[2], 2);
    hiae_software_LOAD_1BLOCK_offset_enc(M[3], 3);
    hiae_software_LOAD_1BLOCK_offset_enc(M[4], 4);
    hiae_software_LOAD_1BLOCK_offset_enc(M[5], 5);
    hiae_software_LOAD_1BLOCK_offset_enc(M[6], 6);
    hiae_software_LOAD_1BLOCK_offset_enc(M[7], 7);
    hiae_software_LOAD_1BLOCK_offset_enc(M[8], 8);
    hiae_software_LOAD_1BLOCK_offset_enc(M[9], 9);
    hiae_software_LOAD_1BLOCK_offset_enc(M[10], 10);
    hiae_software_LOAD_1BLOCK_offset_enc(M[11], 11);
    hiae_software_LOAD_1BLOCK_offset_enc(M[12], 12);
    hiae_software_LOAD_1BLOCK_offset_enc(M[13], 13);
    hiae_software_LOAD_1BLOCK_offset_enc(M[14], 14);
    hiae_software_LOAD_1BLOCK_offset_enc(M[15], 15);
    C[0]  = hiae_software_enc_offset(state, M[0], 0);
    C[1]  = hiae_software_enc_offset(state, M[1], 1);
    C[2]  = hiae_software_enc_offset(state, M[2], 2);
    C[3]  = hiae_software_enc_offset(state, M[3], 3);
    C[4]  = hiae_software_enc_offset(state, M[4], 4);
    C[5]  = hiae_software_enc_offset(state, M[5], 5);
    C[6]  = hiae_software_enc_offset(state, M[6], 6);
    C[7]  = hiae_software_enc_offset(state, M[7], 7);
    C[8]  = hiae_software_enc_offset(state, M[8], 8);
    C[9]  = hiae_software_enc_offset(state, M[9], 9);
    C[10] = hiae_software_enc_offset(state, M[10], 10);
    C[11] = hiae_software_enc_offset(state, M[11], 11);
    C[12] = hiae_software_enc_offset(state, M[12], 12);
    C[13] = hiae_software_enc_offset(state, M[13], 13);
    C[14] = hiae_software_enc_offset(state, M[14], 14);
    C[15] = hiae_software_enc_offset(state, M[15], 15);
    hiae_software_STORE_1BLOCK_offset_enc(C[0], 0);
    hiae_software_STORE_1BLOCK_offset_enc(C[1], 1);
    hiae_software_STORE_1BLOCK_offset_enc(C[2], 2);
    hiae_software_STORE_1BLOCK_offset_enc(C[3], 3);
    hiae_software_STORE_1BLOCK_offset_enc(C[4], 4);
    hiae_software_STORE_1BLOCK_offset_enc(C[5], 5);
    hiae_software_STORE_1BLOCK_offset_enc(C[6], 6);
    hiae_software_STORE_1BLOCK_offset_enc(C[7], 7);
    hiae_software_STORE_1BLOCK_offset_enc(C[8], 8);
    hiae_software_STORE_1BLOCK_offset_enc(C[9], 9);
    hiae_software_STORE_1BLOCK_offset_enc(C[10], 10);
    hiae_software_STORE_1BLOCK_offset_enc(C[11], 11);
    hiae_software_STORE_1BLOCK_offset_enc(C[12], 12);
    hiae_software_STORE_1BLOCK_offset_enc(C[13], 13);
    hiae_software_STORE_1BLOCK_offset_enc(C[14], 14);
    hiae_software_STORE_1BLOCK_offset_enc(C[15], 15);
}

static inline void
hiae_software_decrypt_chunk(hiae_software_DATA128b *state, hiae_software_DATA128b *tmp, const uint8_t *ci, uint8_t *mi, size_t i)
{
    hiae_software_DATA128b M[16], C[16];
    hiae_software_LOAD_1BLOCK_offset_dec(C[0], 0);
    hiae_software_LOAD_1BLOCK_offset_dec(C[1], 1);
    hiae_software_LOAD_1BLOCK_offset_dec(C[2], 2);
    hiae_software_LOAD_1BLOCK_offset_dec(C[3], 3);
    hiae_software_LOAD_1BLOCK_offset_dec(C[4], 4);
    hiae_software_LOAD_1BLOCK_offset_dec(C[5], 5);
    hiae_software_LOAD_1BLOCK_offset_dec(C[6], 6);
    hiae_software_LOAD_1BLOCK_offset_dec(C[7], 7);
    hiae_software_LOAD_1BLOCK_offset_dec(C[8], 8);
    hiae_software_LOAD_1BLOCK_offset_dec(C[9], 9);
    hiae_software_LOAD_1BLOCK_offset_dec(C[10], 10);
    hiae_software_LOAD_1BLOCK_offset_dec(C[11], 11);
    hiae_software_LOAD_1BLOCK_offset_dec(C[12], 12);
    hiae_software_LOAD_1BLOCK_offset_dec(C[13], 13);
    hiae_software_LOAD_1BLOCK_offset_dec(C[14], 14);
    hiae_software_LOAD_1BLOCK_offset_dec(C[15], 15);
    M[0]  = hiae_software_dec_offset(state, tmp, C[0], 0);
    M[1]  = hiae_software_dec_offset(state, tmp, C[1], 1);
    M[2]  = hiae_software_dec_offset(state, tmp, C[2], 2);
    M[3]  = hiae_software_dec_offset(state, tmp, C[3], 3);
    M[4]  = hiae_software_dec_offset(state, tmp, C[4], 4);
    M[5]  = hiae_software_dec_offset(state, tmp, C[5], 5);
    M[6]  = hiae_software_dec_offset(state, tmp, C[6], 6);
    M[7]  = hiae_software_dec_offset(state, tmp, C[7], 7);
    M[8]  = hiae_software_dec_offset(state, tmp, C[8], 8);
    M[9]  = hiae_software_dec_offset(state, tmp, C[9], 9);
    M[10] = hiae_software_dec_offset(state, tmp, C[10], 10);
    M[11] = hiae_software_dec_offset(state, tmp, C[11], 11);
    M[12] = hiae_software_dec_offset(state, tmp, C[12], 12);
    M[13] = hiae_software_dec_offset(state, tmp, C[13], 13);
    M[14] = hiae_software_dec_offset(state, tmp, C[14], 14);
    M[15] = hiae_software_dec_offset(state, tmp, C[15], 15);
    hiae_software_STORE_1BLOCK_offset_dec(M[0], 0);
    hiae_software_STORE_1BLOCK_offset_dec(M[1], 1);
    hiae_software_STORE_1BLOCK_offset_dec(M[2], 2);
    hiae_software_STORE_1BLOCK_offset_dec(M[3], 3);
    hiae_software_STORE_1BLOCK_offset_dec(M[4], 4);
    hiae_software_STORE_1BLOCK_offset_dec(M[5], 5);
    hiae_software_STORE_1BLOCK_offset_dec(M[6], 6);
    hiae_software_STORE_1BLOCK_offset_dec(M[7], 7);
    hiae_software_STORE_1BLOCK_offset_dec(M[8], 8);
    hiae_software_STORE_1BLOCK_offset_dec(M[9], 9);
    hiae_software_STORE_1BLOCK_offset_dec(M[10], 10);
    hiae_software_STORE_1BLOCK_offset_dec(M[11], 11);
    hiae_software_STORE_1BLOCK_offset_dec(M[12], 12);
    hiae_software_STORE_1BLOCK_offset_dec(M[13], 13);
    hiae_software_STORE_1BLOCK_offset_dec(M[14], 14);
    hiae_software_STORE_1BLOCK_offset_dec(M[15], 15);
}

static void
HiAE_init_software(HiAE_state_t *state_opaque, const uint8_t *key, const uint8_t *nonce)
{
    hiae_software_DATA128b state[STATE];
    memset(&state, 0, sizeof state);
    hiae_software_DATA128b c0 = hiae_software_SIMD_LOAD(C0);
    hiae_software_DATA128b c1 = hiae_software_SIMD_LOAD(C1);
    hiae_software_DATA128b k0 = hiae_software_SIMD_LOAD(key);
    hiae_software_DATA128b k1 = hiae_software_SIMD_LOAD(key + 16);
    hiae_software_DATA128b N  = hiae_software_SIMD_LOAD(nonce);

    hiae_software_DATA128b ze = hiae_software_SIMD_ZERO_128();
    state[0]    = c0;
    state[1]    = k1;
    state[2]    = N;
    state[3]    = c0;
    state[4]    = ze;
    state[5]    = hiae_software_SIMD_XOR(N, k0);
    state[6]    = ze;
    state[7]    = c1;
    state[8]    = hiae_software_SIMD_XOR(N, k1);
    state[9]    = ze;
    state[10]   = k1;
    state[11]   = c0;
    state[12]   = c1;
    state[13]   = k1;
    state[14]   = ze;
    state[15]   = hiae_software_SIMD_XOR(c0, c1);

    /* 32 consecutive updates with C0 */
    hiae_software_DATA128b tmp[STATE];
    hiae_software_init_update(state, tmp, c0);
    hiae_software_init_update(state, tmp, c0);

    state[9]  = hiae_software_SIMD_XOR(state[9], k0);
    state[13] = hiae_software_SIMD_XOR(state[13], k1);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_absorb_software(HiAE_state_t *state_opaque, const uint8_t *ad, size_t len)
{
    hiae_software_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t   i      = 0;
    size_t   rest   = len % UNROLL_BLOCK_SIZE;
    size_t   prefix = len - rest;
    hiae_software_DATA128b tmp[STATE], M[16];
    if (len == 0)
        return;

    for (; i < prefix; i += UNROLL_BLOCK_SIZE) {
        hiae_software_ad_update(state, tmp, ad, i);
    }

    size_t pad = len % BLOCK_SIZE;
    len -= pad;
    for (; i < len; i += BLOCK_SIZE) {
        M[0] = hiae_software_SIMD_LOAD(ad + i);
        hiae_software_update_state_offset(state, tmp, M[0], 0);
        hiae_software_state_shift(state, tmp);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memset(buf, 0x00, sizeof(buf));
        memcpy(buf, ad + len, pad);
        M[0] = hiae_software_SIMD_LOAD(buf);
        hiae_software_update_state_offset(state, tmp, M[0], 0);
        hiae_software_state_shift(state, tmp);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

/* Convert byte lengths to bit lengths */
static void
HiAE_finalize_software(HiAE_state_t *state_opaque, uint64_t ad_len, uint64_t msg_len, uint8_t *tag)
{
    hiae_software_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    uint64_t lens[2];
    lens[0] = ad_len * 8;
    lens[1] = msg_len * 8;
    hiae_software_DATA128b temp, tmp[STATE];
    temp = hiae_software_SIMD_LOAD((uint8_t *) lens);
    hiae_software_init_update(state, tmp, temp);
    hiae_software_init_update(state, tmp, temp);
    temp = state[0];
    for (size_t i = 1; i < STATE; ++i) {
        temp = hiae_software_SIMD_XOR(temp, state[i]);
    }
    hiae_software_SIMD_STORE(tag, temp);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_software(HiAE_state_t *state_opaque, uint8_t *ci, const uint8_t *mi, size_t size)
{
    hiae_software_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_software_DATA128b M[STATE], C[STATE], tmp[STATE];

    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        hiae_software_encrypt_chunk(state, mi, ci, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;
    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        M[0] = hiae_software_SIMD_LOAD(mi + i + prefix);
        C[0] = hiae_software_enc_offset(state, M[0], 0);
        hiae_software_state_shift(state, tmp);
        hiae_software_SIMD_STORE(ci + i + prefix, C[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memcpy(buf, mi + rest + prefix, pad);
        memset(buf + pad, 0, BLOCK_SIZE - pad);
        M[0] = hiae_software_SIMD_LOAD(buf);
        C[0] = hiae_software_enc_offset(state, M[0], 0);
        hiae_software_state_shift(state, tmp);
        hiae_software_SIMD_STORE(buf, C[0]);
        memcpy(ci + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_dec_software(HiAE_state_t *state_opaque, uint8_t *mi, const uint8_t *ci, size_t size)
{
    hiae_software_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_software_DATA128b M[STATE], C[STATE], tmp[STATE];

    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        hiae_software_decrypt_chunk(state, tmp, ci, mi, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;

    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        C[0] = hiae_software_SIMD_LOAD(ci + i + prefix);
        M[0] = hiae_software_dec_offset(state, tmp, C[0], 0);
        hiae_software_state_shift(state, tmp);
        hiae_software_SIMD_STORE(mi + i + prefix, M[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        uint8_t mask[BLOCK_SIZE];
        memcpy(buf, ci + rest + prefix, pad);
        memset(mask, 0xff, pad);
        memset(mask + pad, 0x00, BLOCK_SIZE - pad);
        C[0] = hiae_software_SIMD_LOAD(buf);
        M[0] = hiae_software_SIMD_LOAD(mask);
        C[0] = hiae_software_keystream_block(state, C[0], 0);
        C[0] = hiae_software_SIMD_AND(C[0], M[0]);
        hiae_software_update_state_offset(state, tmp, C[0], 0);
        hiae_software_state_shift(state, tmp);
        hiae_software_SIMD_STORE(buf, C[0]);
        memcpy(mi + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_partial_noupdate_software(HiAE_state_t  *state_opaque,
                                   uint8_t       *ci,
                                   const uint8_t *mi,
                                   size_t         size)
{
    if (size == 0)
        return;

    hiae_software_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_software_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];

    memcpy(buf, mi, size);
    memset(buf + size, 0, BLOCK_SIZE - size);
    M[0] = hiae_software_SIMD_LOAD(buf);
    C[0] = hiae_software_enc_offset(state, M[0], 0);
    hiae_software_SIMD_STORE(buf, C[0]);
    memcpy(ci, buf, size);
}

static void
HiAE_dec_partial_noupdate_software(HiAE_state_t  *state_opaque,
                                   uint8_t       *mi,
                                   const uint8_t *ci,
                                   size_t         size)
{
    if (size == 0)
        return;

    hiae_software_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_software_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];
    uint8_t  mask[BLOCK_SIZE];

    memcpy(buf, ci, size);
    memset(mask, 0xff, size);
    memset(mask + size, 0x00, BLOCK_SIZE - size);
    C[0] = hiae_software_SIMD_LOAD(buf);
    M[0] = hiae_software_SIMD_LOAD(mask);
    C[0] = hiae_software_keystream_block(state, C[0], 0);
    C[0] = hiae_software_SIMD_AND(C[0], M[0]);
    hiae_software_SIMD_STORE(buf, C[0]);
    memcpy(mi, buf, size);
}

static int
HiAE_encrypt_software(const uint8_t *key,
                      const uint8_t *nonce,
                      const uint8_t *msg,
                      uint8_t       *ct,
                      size_t         msg_len,
                      const uint8_t *ad,
                      size_t         ad_len,
                      uint8_t       *tag)
{
    HiAE_state_t state;
    HiAE_init_software(&state, key, nonce);
    HiAE_absorb_software(&state, ad, ad_len);
    HiAE_enc_software(&state, ct, msg, msg_len);
    HiAE_finalize_software(&state, ad_len, msg_len, tag);

    return 0;
}

static int
HiAE_decrypt_software(const uint8_t *key,
                      const uint8_t *nonce,
                      uint8_t       *msg,
                      const uint8_t *ct,
                      size_t         ct_len,
                      const uint8_t *ad,
                      size_t         ad_len,
                      const uint8_t *tag)
{
    HiAE_state_t state;
    uint8_t      computed_tag[HIAE_MACBYTES];
    HiAE_init_software(&state, key, nonce);
    HiAE_absorb_software(&state, ad, ad_len);
    HiAE_dec_software(&state, msg, ct, ct_len);
    HiAE_finalize_software(&state, ad_len, ct_len, computed_tag);

    return hiae_constant_time_compare(computed_tag, tag, HIAE_MACBYTES);
}

static int
HiAE_mac_software(
    const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len, uint8_t *tag)
{
    HiAE_state_t state;
    HiAE_init_software(&state, key, nonce);
    HiAE_absorb_software(&state, data, data_len);
    HiAE_finalize_software(&state, data_len, 0, tag);

    return 0;
}

const HiAE_impl_t hiae_software_impl = { .name                 = "Software",
                                         .init                 = HiAE_init_software,
                                         .absorb               = HiAE_absorb_software,
                                         .finalize             = HiAE_finalize_software,
                                         .enc                  = HiAE_enc_software,
                                         .dec                  = HiAE_dec_software,
                                         .enc_partial_noupdate = HiAE_enc_partial_noupdate_software,
                                         .dec_partial_noupdate = HiAE_dec_partial_noupdate_software,
                                         .encrypt              = HiAE_encrypt_software,
                                         .decrypt              = HiAE_decrypt_software,
                                         .mac                  = HiAE_mac_software };

#endif // !defined(__AES__) && !defined(__ARM_FEATURE_CRYPTO)

/* End of HiAE_software.c */

/* =====================================================
 * HiAE_aesni.c - hiae_aesni implementation
 * =====================================================
 */

#if defined(__i386__) || defined(_M_IX86) || defined(__x86_64__) || defined(_M_AMD64)

#    ifdef __clang__
#        pragma clang attribute push(__attribute__((target("aes,avx"))), apply_to = function)
#    elif defined(__GNUC__)
#        pragma GCC target("aes,avx")
#    endif

#    include <immintrin.h>
#    include <wmmintrin.h>

#    define hiae_aesni_PREFETCH_READ(addr, locality)  _mm_prefetch((const char *) (addr), _MM_HINT_T0)
#    define hiae_aesni_PREFETCH_WRITE(addr, locality) _mm_prefetch((const char *) (addr), _MM_HINT_T0)
/* Prefetch distance in bytes - optimized for x86 streaming workloads */
#    define hiae_aesni_PREFETCH_DISTANCE 512

typedef __m128i hiae_aesni_DATA128b;

#    define hiae_aesni_SIMD_LOAD(x)     _mm_loadu_si128((const __m128i *) (x))
#    define hiae_aesni_SIMD_STORE(x, y) _mm_storeu_si128((__m128i *) (x), y)
#    define hiae_aesni_SIMD_XOR(x, y)   _mm_xor_si128(x, y)
#    define hiae_aesni_SIMD_AND(x, y)   _mm_and_si128(x, y)
#    define hiae_aesni_SIMD_ZERO_128()  _mm_setzero_si128()
#    define hiae_aesni_AESENC(x, y)     _mm_aesenc_si128(x, y)

static inline void
hiae_aesni_update_state_offset(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b *tmp, hiae_aesni_DATA128b M, int offset)
{
    tmp[offset] = hiae_aesni_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    tmp[offset] = hiae_aesni_AESENC(tmp[offset], M);
    state[(0 + offset) % STATE]   = hiae_aesni_AESENC(state[(P_4 + offset) % STATE], tmp[offset]);
    state[(I_1 + offset) % STATE] = hiae_aesni_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_aesni_SIMD_XOR(state[(I_2 + offset) % STATE], M);
}

static inline hiae_aesni_DATA128b
hiae_aesni_keystream_block(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b *tmp, hiae_aesni_DATA128b M, int offset)
{
    tmp[offset] = hiae_aesni_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    M           = hiae_aesni_AESENC(tmp[offset], M);
    M           = hiae_aesni_SIMD_XOR(M, state[(P_7 + offset) % STATE]);
    return M;
}

static inline hiae_aesni_DATA128b
hiae_aesni_enc_offset(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b M, int offset)
{
    hiae_aesni_DATA128b C = hiae_aesni_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    C          = hiae_aesni_AESENC(C, M);
    state[(0 + offset) % STATE]   = hiae_aesni_AESENC(state[(P_4 + offset) % STATE], C);
    C                             = hiae_aesni_SIMD_XOR(C, state[(P_7 + offset) % STATE]);
    state[(I_1 + offset) % STATE] = hiae_aesni_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_aesni_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return C;
}

static inline hiae_aesni_DATA128b
hiae_aesni_dec_offset(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b *tmp, hiae_aesni_DATA128b C, int offset)
{
    tmp[offset] = hiae_aesni_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    hiae_aesni_DATA128b M  = hiae_aesni_SIMD_XOR(state[(P_7 + offset) % STATE], C);
    state[(0 + offset) % STATE]   = hiae_aesni_AESENC(state[(P_4 + offset) % STATE], M);
    M                             = hiae_aesni_AESENC(tmp[offset], M);
    state[(I_1 + offset) % STATE] = hiae_aesni_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_aesni_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return M;
}

#    define hiae_aesni_LOAD_1BLOCK_offset_enc(M, offset)  (M) = hiae_aesni_SIMD_LOAD(mi + i + 0 + BLOCK_SIZE * offset);
#    define hiae_aesni_LOAD_1BLOCK_offset_dec(C, offset)  (C) = hiae_aesni_SIMD_LOAD(ci + i + 0 + BLOCK_SIZE * offset);
#    define hiae_aesni_LOAD_1BLOCK_offset_ad(M, offset)   (M) = hiae_aesni_SIMD_LOAD(ad + i + 0 + BLOCK_SIZE * offset);
#    define hiae_aesni_STORE_1BLOCK_offset_enc(C, offset) hiae_aesni_SIMD_STORE(ci + i + 0 + BLOCK_SIZE * offset, (C));
#    define hiae_aesni_STORE_1BLOCK_offset_dec(M, offset) hiae_aesni_SIMD_STORE(mi + i + 0 + BLOCK_SIZE * offset, (M));

static inline void
hiae_aesni_state_shift(hiae_aesni_DATA128b *state)
{
    hiae_aesni_DATA128b temp = state[0];
    state[0]      = state[1];
    state[1]      = state[2];
    state[2]      = state[3];
    state[3]      = state[4];
    state[4]      = state[5];
    state[5]      = state[6];
    state[6]      = state[7];
    state[7]      = state[8];
    state[8]      = state[9];
    state[9]      = state[10];
    state[10]     = state[11];
    state[11]     = state[12];
    state[12]     = state[13];
    state[13]     = state[14];
    state[14]     = state[15];
    state[15]     = temp;
}

static inline void
hiae_aesni_init_update(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b *tmp, hiae_aesni_DATA128b c0)
{
    hiae_aesni_update_state_offset(state, tmp, c0, 0);
    hiae_aesni_update_state_offset(state, tmp, c0, 1);
    hiae_aesni_update_state_offset(state, tmp, c0, 2);
    hiae_aesni_update_state_offset(state, tmp, c0, 3);
    hiae_aesni_update_state_offset(state, tmp, c0, 4);
    hiae_aesni_update_state_offset(state, tmp, c0, 5);
    hiae_aesni_update_state_offset(state, tmp, c0, 6);
    hiae_aesni_update_state_offset(state, tmp, c0, 7);
    hiae_aesni_update_state_offset(state, tmp, c0, 8);
    hiae_aesni_update_state_offset(state, tmp, c0, 9);
    hiae_aesni_update_state_offset(state, tmp, c0, 10);
    hiae_aesni_update_state_offset(state, tmp, c0, 11);
    hiae_aesni_update_state_offset(state, tmp, c0, 12);
    hiae_aesni_update_state_offset(state, tmp, c0, 13);
    hiae_aesni_update_state_offset(state, tmp, c0, 14);
    hiae_aesni_update_state_offset(state, tmp, c0, 15);
}

static inline void
hiae_aesni_ad_update(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b *tmp, hiae_aesni_DATA128b *M, const uint8_t *ad, size_t i)
{
    hiae_aesni_PREFETCH_READ(ad + i + UNROLL_BLOCK_SIZE, 0);
    hiae_aesni_PREFETCH_READ(ad + i + UNROLL_BLOCK_SIZE + 128, 0);

    // Process in groups of 4 blocks to reduce register pressure
    // This allows GCC to better manage register allocation

    // Group 1: blocks 0-3
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[0], 0);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[1], 1);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[2], 2);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[3], 3);
    hiae_aesni_update_state_offset(state, tmp, M[0], 0);
    hiae_aesni_update_state_offset(state, tmp, M[1], 1);
    hiae_aesni_update_state_offset(state, tmp, M[2], 2);
    hiae_aesni_update_state_offset(state, tmp, M[3], 3);

    // Group 2: blocks 4-7
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[4], 4);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[5], 5);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[6], 6);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[7], 7);
    hiae_aesni_update_state_offset(state, tmp, M[4], 4);
    hiae_aesni_update_state_offset(state, tmp, M[5], 5);
    hiae_aesni_update_state_offset(state, tmp, M[6], 6);
    hiae_aesni_update_state_offset(state, tmp, M[7], 7);

    // Group 3: blocks 8-11
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[8], 8);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[9], 9);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[10], 10);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[11], 11);
    hiae_aesni_update_state_offset(state, tmp, M[8], 8);
    hiae_aesni_update_state_offset(state, tmp, M[9], 9);
    hiae_aesni_update_state_offset(state, tmp, M[10], 10);
    hiae_aesni_update_state_offset(state, tmp, M[11], 11);

    // Group 4: blocks 12-15
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[12], 12);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[13], 13);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[14], 14);
    hiae_aesni_LOAD_1BLOCK_offset_ad(M[15], 15);
    hiae_aesni_update_state_offset(state, tmp, M[12], 12);
    hiae_aesni_update_state_offset(state, tmp, M[13], 13);
    hiae_aesni_update_state_offset(state, tmp, M[14], 14);
    hiae_aesni_update_state_offset(state, tmp, M[15], 15);
}

static inline void
hiae_aesni_encrypt_chunk(hiae_aesni_DATA128b *state, hiae_aesni_DATA128b *M, hiae_aesni_DATA128b *C, const uint8_t *mi, uint8_t *ci, size_t i)
{
    hiae_aesni_PREFETCH_READ(mi + i + hiae_aesni_PREFETCH_DISTANCE, 0);
    hiae_aesni_PREFETCH_WRITE(ci + i + hiae_aesni_PREFETCH_DISTANCE, 0);

    // Process blocks in groups of 4 to reduce register pressure
    // This prevents GCC from trying to keep all 16 M[] and C[] values in registers

    // Group 1: blocks 0-3
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[0], 0);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[1], 1);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[2], 2);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[3], 3);
    C[0] = hiae_aesni_enc_offset(state, M[0], 0);
    C[1] = hiae_aesni_enc_offset(state, M[1], 1);
    C[2] = hiae_aesni_enc_offset(state, M[2], 2);
    C[3] = hiae_aesni_enc_offset(state, M[3], 3);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[0], 0);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[1], 1);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[2], 2);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[3], 3);

    // Group 2: blocks 4-7
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[4], 4);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[5], 5);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[6], 6);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[7], 7);
    C[4] = hiae_aesni_enc_offset(state, M[4], 4);
    C[5] = hiae_aesni_enc_offset(state, M[5], 5);
    C[6] = hiae_aesni_enc_offset(state, M[6], 6);
    C[7] = hiae_aesni_enc_offset(state, M[7], 7);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[4], 4);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[5], 5);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[6], 6);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[7], 7);

    // Group 3: blocks 8-11
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[8], 8);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[9], 9);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[10], 10);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[11], 11);
    C[8]  = hiae_aesni_enc_offset(state, M[8], 8);
    C[9]  = hiae_aesni_enc_offset(state, M[9], 9);
    C[10] = hiae_aesni_enc_offset(state, M[10], 10);
    C[11] = hiae_aesni_enc_offset(state, M[11], 11);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[8], 8);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[9], 9);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[10], 10);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[11], 11);

    // Group 4: blocks 12-15
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[12], 12);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[13], 13);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[14], 14);
    hiae_aesni_LOAD_1BLOCK_offset_enc(M[15], 15);
    C[12] = hiae_aesni_enc_offset(state, M[12], 12);
    C[13] = hiae_aesni_enc_offset(state, M[13], 13);
    C[14] = hiae_aesni_enc_offset(state, M[14], 14);
    C[15] = hiae_aesni_enc_offset(state, M[15], 15);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[12], 12);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[13], 13);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[14], 14);
    hiae_aesni_STORE_1BLOCK_offset_enc(C[15], 15);
}

static inline void
hiae_aesni_decrypt_chunk(hiae_aesni_DATA128b      *state,
              hiae_aesni_DATA128b      *tmp,
              hiae_aesni_DATA128b      *M,
              hiae_aesni_DATA128b      *C,
              const uint8_t *ci,
              uint8_t       *mi,
              size_t         i)
{
    hiae_aesni_PREFETCH_READ(ci + i + hiae_aesni_PREFETCH_DISTANCE, 0);
    hiae_aesni_PREFETCH_WRITE(mi + i + hiae_aesni_PREFETCH_DISTANCE, 0);

    // Group 1: blocks 0-3
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[0], 0);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[1], 1);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[2], 2);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[3], 3);
    M[0] = hiae_aesni_dec_offset(state, tmp, C[0], 0);
    M[1] = hiae_aesni_dec_offset(state, tmp, C[1], 1);
    M[2] = hiae_aesni_dec_offset(state, tmp, C[2], 2);
    M[3] = hiae_aesni_dec_offset(state, tmp, C[3], 3);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[0], 0);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[1], 1);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[2], 2);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[3], 3);

    // Group 2: blocks 4-7
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[4], 4);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[5], 5);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[6], 6);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[7], 7);
    M[4] = hiae_aesni_dec_offset(state, tmp, C[4], 4);
    M[5] = hiae_aesni_dec_offset(state, tmp, C[5], 5);
    M[6] = hiae_aesni_dec_offset(state, tmp, C[6], 6);
    M[7] = hiae_aesni_dec_offset(state, tmp, C[7], 7);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[4], 4);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[5], 5);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[6], 6);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[7], 7);

    // Group 3: blocks 8-11
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[8], 8);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[9], 9);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[10], 10);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[11], 11);
    M[8]  = hiae_aesni_dec_offset(state, tmp, C[8], 8);
    M[9]  = hiae_aesni_dec_offset(state, tmp, C[9], 9);
    M[10] = hiae_aesni_dec_offset(state, tmp, C[10], 10);
    M[11] = hiae_aesni_dec_offset(state, tmp, C[11], 11);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[8], 8);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[9], 9);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[10], 10);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[11], 11);

    // Group 4: blocks 12-15
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[12], 12);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[13], 13);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[14], 14);
    hiae_aesni_LOAD_1BLOCK_offset_dec(C[15], 15);
    M[12] = hiae_aesni_dec_offset(state, tmp, C[12], 12);
    M[13] = hiae_aesni_dec_offset(state, tmp, C[13], 13);
    M[14] = hiae_aesni_dec_offset(state, tmp, C[14], 14);
    M[15] = hiae_aesni_dec_offset(state, tmp, C[15], 15);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[12], 12);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[13], 13);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[14], 14);
    hiae_aesni_STORE_1BLOCK_offset_dec(M[15], 15);
}

static void
HiAE_init_aesni(HiAE_state_t *state_opaque, const uint8_t *key, const uint8_t *nonce)
{
    hiae_aesni_DATA128b state[STATE];
    memset(&state, 0, sizeof state);
    hiae_aesni_DATA128b c0 = hiae_aesni_SIMD_LOAD(C0);
    hiae_aesni_DATA128b c1 = hiae_aesni_SIMD_LOAD(C1);
    hiae_aesni_DATA128b k0 = hiae_aesni_SIMD_LOAD(key);
    hiae_aesni_DATA128b k1 = hiae_aesni_SIMD_LOAD(key + 16);
    hiae_aesni_DATA128b N  = hiae_aesni_SIMD_LOAD(nonce);

    hiae_aesni_DATA128b ze = hiae_aesni_SIMD_ZERO_128();
    state[0]    = c0;
    state[1]    = k1;
    state[2]    = N;
    state[3]    = c0;
    state[4]    = ze;
    state[5]    = hiae_aesni_SIMD_XOR(N, k0);
    state[6]    = ze;
    state[7]    = c1;
    state[8]    = hiae_aesni_SIMD_XOR(N, k1);
    state[9]    = ze;
    state[10]   = k1;
    state[11]   = c0;
    state[12]   = c1;
    state[13]   = k1;
    state[14]   = ze;
    state[15]   = hiae_aesni_SIMD_XOR(c0, c1);

    hiae_aesni_DATA128b tmp[STATE];
    hiae_aesni_init_update(state, tmp, c0);
    hiae_aesni_init_update(state, tmp, c0);

    state[9]  = hiae_aesni_SIMD_XOR(state[9], k0);
    state[13] = hiae_aesni_SIMD_XOR(state[13], k1);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_absorb_aesni(HiAE_state_t *state_opaque, const uint8_t *ad, size_t len)
{
    hiae_aesni_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t   i      = 0;
    size_t   rest   = len % UNROLL_BLOCK_SIZE;
    size_t   prefix = len - rest;
    hiae_aesni_DATA128b tmp[STATE], M[16];
    if (len == 0)
        return;

    for (; i < prefix; i += UNROLL_BLOCK_SIZE) {
        hiae_aesni_ad_update(state, tmp, M, ad, i);
    }

    size_t pad = len % BLOCK_SIZE;
    len -= pad;
    for (; i < len; i += BLOCK_SIZE) {
        M[0] = hiae_aesni_SIMD_LOAD(ad + i);
        hiae_aesni_update_state_offset(state, tmp, M[0], 0);
        hiae_aesni_state_shift(state);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memset(buf, 0x00, sizeof(buf));
        memcpy(buf, ad + len, pad);
        M[0] = hiae_aesni_SIMD_LOAD(buf);
        hiae_aesni_update_state_offset(state, tmp, M[0], 0);
        hiae_aesni_state_shift(state);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_finalize_aesni(HiAE_state_t *state_opaque, uint64_t ad_len, uint64_t msg_len, uint8_t *tag)
{
    hiae_aesni_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    uint64_t lens[2];
    lens[0] = ad_len * 8;
    lens[1] = msg_len * 8;
    hiae_aesni_DATA128b temp, tmp[STATE];
    temp = hiae_aesni_SIMD_LOAD((uint8_t *) lens);
    hiae_aesni_init_update(state, tmp, temp);
    hiae_aesni_init_update(state, tmp, temp);
    temp = state[0];
    for (size_t i = 1; i < STATE; ++i) {
        temp = hiae_aesni_SIMD_XOR(temp, state[i]);
    }
    hiae_aesni_SIMD_STORE(tag, temp);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_aesni(HiAE_state_t *state_opaque, uint8_t *ci, const uint8_t *mi, size_t size)
{
    hiae_aesni_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_aesni_DATA128b M[STATE], C[STATE];

    // Main processing loop with prefetching
    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        // Unconditional prefetch for next iteration
        hiae_aesni_PREFETCH_READ(mi + i + UNROLL_BLOCK_SIZE, 0);
        hiae_aesni_PREFETCH_WRITE(ci + i + UNROLL_BLOCK_SIZE, 0);

        hiae_aesni_encrypt_chunk(state, M, C, mi, ci, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;
    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        M[0] = hiae_aesni_SIMD_LOAD(mi + i + prefix);
        C[0] = hiae_aesni_enc_offset(state, M[0], 0);
        hiae_aesni_state_shift(state);
        hiae_aesni_SIMD_STORE(ci + i + prefix, C[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memcpy(buf, mi + rest + prefix, pad);
        memset(buf + pad, 0, BLOCK_SIZE - pad);
        M[0] = hiae_aesni_SIMD_LOAD(buf);
        C[0] = hiae_aesni_enc_offset(state, M[0], 0);
        hiae_aesni_state_shift(state);
        hiae_aesni_SIMD_STORE(buf, C[0]);
        memcpy(ci + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_dec_aesni(HiAE_state_t *state_opaque, uint8_t *mi, const uint8_t *ci, size_t size)
{
    hiae_aesni_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_aesni_DATA128b M[STATE], C[STATE], tmp[STATE];

    // Main processing loop with prefetching
    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        // Unconditional prefetch for next iteration
        hiae_aesni_PREFETCH_READ(ci + i + UNROLL_BLOCK_SIZE, 0);
        hiae_aesni_PREFETCH_WRITE(mi + i + UNROLL_BLOCK_SIZE, 0);

        hiae_aesni_decrypt_chunk(state, tmp, M, C, ci, mi, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;

    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        C[0] = hiae_aesni_SIMD_LOAD(ci + i + prefix);
        M[0] = hiae_aesni_dec_offset(state, tmp, C[0], 0);
        hiae_aesni_state_shift(state);
        hiae_aesni_SIMD_STORE(mi + i + prefix, M[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        uint8_t mask[BLOCK_SIZE];
        memcpy(buf, ci + rest + prefix, pad);
        memset(mask, 0xff, pad);
        memset(mask + pad, 0x00, BLOCK_SIZE - pad);
        C[0] = hiae_aesni_SIMD_LOAD(buf);
        M[0] = hiae_aesni_SIMD_LOAD(mask);
        C[0] = hiae_aesni_keystream_block(state, tmp, C[0], 0);
        C[0] = hiae_aesni_SIMD_AND(C[0], M[0]);
        hiae_aesni_update_state_offset(state, tmp, C[0], 0);
        hiae_aesni_state_shift(state);
        hiae_aesni_SIMD_STORE(buf, C[0]);
        memcpy(mi + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_partial_noupdate_aesni(HiAE_state_t  *state_opaque,
                                uint8_t       *ci,
                                const uint8_t *mi,
                                size_t         size)
{
    if (size == 0)
        return;

    hiae_aesni_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_aesni_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];

    memcpy(buf, mi, size);
    memset(buf + size, 0, BLOCK_SIZE - size);
    M[0] = hiae_aesni_SIMD_LOAD(buf);
    C[0] = hiae_aesni_enc_offset(state, M[0], 0);
    hiae_aesni_SIMD_STORE(buf, C[0]);
    memcpy(ci, buf, size);
}

static void
HiAE_dec_partial_noupdate_aesni(HiAE_state_t  *state_opaque,
                                uint8_t       *mi,
                                const uint8_t *ci,
                                size_t         size)
{
    if (size == 0)
        return;

    hiae_aesni_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_aesni_DATA128b M[1], C[1], tmp[STATE];
    uint8_t  buf[BLOCK_SIZE];
    uint8_t  mask[BLOCK_SIZE];

    memcpy(buf, ci, size);
    memset(mask, 0xff, size);
    memset(mask + size, 0x00, BLOCK_SIZE - size);
    C[0] = hiae_aesni_SIMD_LOAD(buf);
    M[0] = hiae_aesni_SIMD_LOAD(mask);
    C[0] = hiae_aesni_keystream_block(state, tmp, C[0], 0);
    C[0] = hiae_aesni_SIMD_AND(C[0], M[0]);
    hiae_aesni_SIMD_STORE(buf, C[0]);
    memcpy(mi, buf, size);
}

static int
HiAE_encrypt_aesni(const uint8_t *key,
                   const uint8_t *nonce,
                   const uint8_t *msg,
                   uint8_t       *ct,
                   size_t         msg_len,
                   const uint8_t *ad,
                   size_t         ad_len,
                   uint8_t       *tag)
{
    HiAE_state_t state;
    HiAE_init_aesni(&state, key, nonce);
    HiAE_absorb_aesni(&state, ad, ad_len);
    HiAE_enc_aesni(&state, ct, msg, msg_len);
    HiAE_finalize_aesni(&state, ad_len, msg_len, tag);

    return 0;
}

static int
HiAE_decrypt_aesni(const uint8_t *key,
                   const uint8_t *nonce,
                   uint8_t       *msg,
                   const uint8_t *ct,
                   size_t         ct_len,
                   const uint8_t *ad,
                   size_t         ad_len,
                   const uint8_t *tag)
{
    HiAE_state_t state;
    uint8_t      computed_tag[HIAE_MACBYTES];
    HiAE_init_aesni(&state, key, nonce);
    HiAE_absorb_aesni(&state, ad, ad_len);
    HiAE_dec_aesni(&state, msg, ct, ct_len);
    HiAE_finalize_aesni(&state, ad_len, ct_len, computed_tag);

    return hiae_constant_time_compare(computed_tag, tag, HIAE_MACBYTES);
}

static int
HiAE_mac_aesni(
    const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len, uint8_t *tag)
{
    HiAE_state_t state;
    HiAE_init_aesni(&state, key, nonce);
    HiAE_absorb_aesni(&state, data, data_len);
    HiAE_finalize_aesni(&state, data_len, 0, tag);

    return 0;
}

const HiAE_impl_t hiae_aesni_impl = { .name                 = "AES-NI",
                                      .init                 = HiAE_init_aesni,
                                      .absorb               = HiAE_absorb_aesni,
                                      .finalize             = HiAE_finalize_aesni,
                                      .enc                  = HiAE_enc_aesni,
                                      .dec                  = HiAE_dec_aesni,
                                      .enc_partial_noupdate = HiAE_enc_partial_noupdate_aesni,
                                      .dec_partial_noupdate = HiAE_dec_partial_noupdate_aesni,
                                      .encrypt              = HiAE_encrypt_aesni,
                                      .decrypt              = HiAE_decrypt_aesni,
                                      .mac                  = HiAE_mac_aesni };

#    ifdef __clang__
#        pragma clang attribute pop
#    endif

#else
// AES-NI not available, provide stub implementation
const HiAE_impl_t hiae_aesni_impl = { .name                 = NULL,
                                      .init                 = NULL,
                                      .absorb               = NULL,
                                      .finalize             = NULL,
                                      .enc                  = NULL,
                                      .dec                  = NULL,
                                      .enc_partial_noupdate = NULL,
                                      .dec_partial_noupdate = NULL,
                                      .encrypt              = NULL,
                                      .decrypt              = NULL,
                                      .mac                  = NULL };
#endif

/* End of HiAE_aesni.c */

/* =====================================================
 * HiAE_vaes_avx512.c - hiae_vaes_avx512 implementation
 * =====================================================
 */

#if (defined(__i386__) || defined(_M_IX86) || defined(__x86_64__) || defined(_M_AMD64)) && \
    !defined(_MSC_VER)

#    ifdef __clang__
#        if __clang_major__ >= 18
#            pragma clang attribute push(__attribute__((target("aes,vaes,avx512f,evex512"))), \
                                         apply_to = function)
#        else
#            pragma clang attribute push(__attribute__((target("aes,vaes,avx512f"))), \
                                         apply_to = function)
#        endif
#    elif defined(__GNUC__)
#        pragma GCC target("aes,vaes,avx512f")
#    endif

#    include <immintrin.h>
#    include <wmmintrin.h>
#    include <xmmintrin.h>

typedef __m128i hiae_vaes_avx512_DATA128b;

/* x86-64 AES-NI specific SIMD operations */
#    define hiae_vaes_avx512_SIMD_LOAD(x)     _mm_loadu_si128((const __m128i *) (x))
#    define hiae_vaes_avx512_SIMD_STORE(x, y) _mm_storeu_si128((__m128i *) (x), y)
#    define hiae_vaes_avx512_SIMD_XOR(x, y)   _mm_xor_si128(x, y)
#    define hiae_vaes_avx512_SIMD_AND(x, y)   _mm_and_si128(x, y)
#    define hiae_vaes_avx512_SIMD_ZERO_128()  _mm_setzero_si128()
#    define hiae_vaes_avx512_AESENC(x, y)     _mm_aesenc_si128(x, y)

/* x86-specific state update functions */
static inline void
hiae_vaes_avx512_update_state_offset(hiae_vaes_avx512_DATA128b *state, hiae_vaes_avx512_DATA128b *tmp, hiae_vaes_avx512_DATA128b M, int offset)
{
    tmp[offset] = hiae_vaes_avx512_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    tmp[offset] = hiae_vaes_avx512_AESENC(tmp[offset], M);
    state[(0 + offset) % STATE]   = hiae_vaes_avx512_AESENC(state[(P_4 + offset) % STATE], tmp[offset]);
    state[(I_1 + offset) % STATE] = hiae_vaes_avx512_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_vaes_avx512_SIMD_XOR(state[(I_2 + offset) % STATE], M);
}

static inline hiae_vaes_avx512_DATA128b
hiae_vaes_avx512_keystream_block(hiae_vaes_avx512_DATA128b *state, hiae_vaes_avx512_DATA128b *tmp, hiae_vaes_avx512_DATA128b M, int offset)
{
    tmp[offset] = hiae_vaes_avx512_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    M           = hiae_vaes_avx512_AESENC(tmp[offset], M);
    M           = hiae_vaes_avx512_SIMD_XOR(M, state[(P_7 + offset) % STATE]);
    return M;
}

static inline hiae_vaes_avx512_DATA128b
hiae_vaes_avx512_enc_offset(hiae_vaes_avx512_DATA128b *state, hiae_vaes_avx512_DATA128b M, int offset)
{
    hiae_vaes_avx512_DATA128b C = hiae_vaes_avx512_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    C          = hiae_vaes_avx512_AESENC(C, M);
    state[(0 + offset) % STATE]   = hiae_vaes_avx512_AESENC(state[(P_4 + offset) % STATE], C);
    C                             = hiae_vaes_avx512_SIMD_XOR(C, state[(P_7 + offset) % STATE]);
    state[(I_1 + offset) % STATE] = hiae_vaes_avx512_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_vaes_avx512_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return C;
}

static inline hiae_vaes_avx512_DATA128b
hiae_vaes_avx512_dec_offset(hiae_vaes_avx512_DATA128b *state, hiae_vaes_avx512_DATA128b *tmp, hiae_vaes_avx512_DATA128b C, int offset)
{
    tmp[offset] = hiae_vaes_avx512_SIMD_XOR(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    hiae_vaes_avx512_DATA128b M  = hiae_vaes_avx512_SIMD_XOR(state[(P_7 + offset) % STATE], C);
    state[(0 + offset) % STATE]   = hiae_vaes_avx512_AESENC(state[(P_4 + offset) % STATE], M);
    M                             = hiae_vaes_avx512_AESENC(tmp[offset], M);
    state[(I_1 + offset) % STATE] = hiae_vaes_avx512_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_vaes_avx512_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return M;
}

#    define hiae_vaes_avx512_LOAD_1BLOCK_offset_enc(M, offset)  (M) = hiae_vaes_avx512_SIMD_LOAD(mi + i + 0 + BLOCK_SIZE * offset);
#    define hiae_vaes_avx512_LOAD_1BLOCK_offset_dec(C, offset)  (C) = hiae_vaes_avx512_SIMD_LOAD(ci + i + 0 + BLOCK_SIZE * offset);
#    define hiae_vaes_avx512_LOAD_1BLOCK_offset_ad(M, offset)   (M) = hiae_vaes_avx512_SIMD_LOAD(ad + i + 0 + BLOCK_SIZE * offset);
#    define hiae_vaes_avx512_STORE_1BLOCK_offset_enc(C, offset) hiae_vaes_avx512_SIMD_STORE(ci + i + 0 + BLOCK_SIZE * offset, (C));
#    define hiae_vaes_avx512_STORE_1BLOCK_offset_dec(M, offset) hiae_vaes_avx512_SIMD_STORE(mi + i + 0 + BLOCK_SIZE * offset, (M));

static inline void
hiae_vaes_avx512_state_shift(hiae_vaes_avx512_DATA128b *state)
{
    hiae_vaes_avx512_DATA128b temp = state[0];
    state[0]      = state[1];
    state[1]      = state[2];
    state[2]      = state[3];
    state[3]      = state[4];
    state[4]      = state[5];
    state[5]      = state[6];
    state[6]      = state[7];
    state[7]      = state[8];
    state[8]      = state[9];
    state[9]      = state[10];
    state[10]     = state[11];
    state[11]     = state[12];
    state[12]     = state[13];
    state[13]     = state[14];
    state[14]     = state[15];
    state[15]     = temp;
}

static inline void
hiae_vaes_avx512_init_update(hiae_vaes_avx512_DATA128b *state, hiae_vaes_avx512_DATA128b *tmp, hiae_vaes_avx512_DATA128b c0)
{
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 0);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 1);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 2);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 3);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 4);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 5);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 6);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 7);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 8);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 9);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 10);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 11);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 12);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 13);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 14);
    hiae_vaes_avx512_update_state_offset(state, tmp, c0, 15);
}

static void
HiAE_init_vaes(HiAE_state_t *state_opaque, const uint8_t *key, const uint8_t *nonce)
{
    hiae_vaes_avx512_DATA128b state[STATE];
    memset(&state, 0, sizeof state);
    hiae_vaes_avx512_DATA128b c0 = hiae_vaes_avx512_SIMD_LOAD(C0);
    hiae_vaes_avx512_DATA128b c1 = hiae_vaes_avx512_SIMD_LOAD(C1);
    hiae_vaes_avx512_DATA128b k0 = hiae_vaes_avx512_SIMD_LOAD(key);
    hiae_vaes_avx512_DATA128b k1 = hiae_vaes_avx512_SIMD_LOAD(key + 16);
    hiae_vaes_avx512_DATA128b N  = hiae_vaes_avx512_SIMD_LOAD(nonce);

    hiae_vaes_avx512_DATA128b ze = hiae_vaes_avx512_SIMD_ZERO_128();
    state[0]    = c0;
    state[1]    = k1;
    state[2]    = N;
    state[3]    = c0;
    state[4]    = ze;
    state[5]    = hiae_vaes_avx512_SIMD_XOR(N, k0);
    state[6]    = ze;
    state[7]    = c1;
    state[8]    = hiae_vaes_avx512_SIMD_XOR(N, k1);
    state[9]    = ze;
    state[10]   = k1;
    state[11]   = c0;
    state[12]   = c1;
    state[13]   = k1;
    state[14]   = ze;
    state[15]   = hiae_vaes_avx512_SIMD_XOR(c0, c1);

    hiae_vaes_avx512_DATA128b tmp[STATE];
    hiae_vaes_avx512_init_update(state, tmp, c0);
    hiae_vaes_avx512_init_update(state, tmp, c0);

    state[9]  = hiae_vaes_avx512_SIMD_XOR(state[9], k0);
    state[13] = hiae_vaes_avx512_SIMD_XOR(state[13], k1);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_absorb_vaes(HiAE_state_t *state_opaque, const uint8_t *ad, size_t len)
{
    hiae_vaes_avx512_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t   i      = 0;
    size_t   rest   = len % UNROLL_BLOCK_SIZE;
    size_t   prefix = len - rest;
    hiae_vaes_avx512_DATA128b tmp[STATE], M[16];
    if (len == 0)
        return;

    // VAES optimized assembly code for AD processing
    __asm__ volatile(
        // Load state into xmm0-xmm15
        "vmovdqa64 (%0), %%xmm0;" // state[0]
        "vmovdqa64 16(%0), %%xmm1;" // state[1]
        "vmovdqa64 32(%0), %%xmm2;" // state[2]
        "vmovdqa64 48(%0), %%xmm3;" // state[3]
        "vmovdqa64 64(%0), %%xmm4;" // state[4]
        "vmovdqa64 80(%0), %%xmm5;" // state[5]
        "vmovdqa64 96(%0), %%xmm6;" // state[6]
        "vmovdqa64 112(%0), %%xmm7;" // state[7]
        "vmovdqa64 128(%0), %%xmm8;" // state[8]
        "vmovdqa64 144(%0), %%xmm9;" // state[9]
        "vmovdqa64 160(%0), %%xmm10;" // state[10]
        "vmovdqa64 176(%0), %%xmm11;" // state[11]
        "vmovdqa64 192(%0), %%xmm12;" // state[12]
        "vmovdqa64 208(%0), %%xmm13;" // state[13]
        "vmovdqa64 224(%0), %%xmm14;" // state[14]
        "vmovdqa64 240(%0), %%xmm15;" // state[15]

        "movq $0, %%rax;" // Initialize counter i = 0
        "1:;" // Loop start
        "cmpq %2, %%rax;" // Compare i and prefix
        "jge 2f;" // If i >= prefix, jump to loop end

        // Prefetch next iteration data (512 bytes ahead)
        "prefetcht0 512(%1, %%rax);" // Prefetch next chunk for reading
        "prefetcht0 576(%1, %%rax);" // Prefetch more data (cache line boundary)

        // round 1
        "vmovdqu64 0(%1, %%rax), %%xmm16;" // Load M[0] into xmm16
        "vpxorq %%xmm0, %%xmm1, %%xmm24;" // C[0] = hiae_vaes_avx512_SIMD_XOR(S[0], S[1])
        "vaesenc %%xmm16, %%xmm24, %%xmm24;" // C[0] = hiae_vaes_avx512_AESENC(C[0], M[0])
        "vaesenc %%xmm24, %%xmm13, %%xmm0;" // S[16] = hiae_vaes_avx512_AESENC(S[13], C[0])
        "vpxorq %%xmm3, %%xmm16, %%xmm3;" // S[3] = hiae_vaes_avx512_SIMD_XOR(S[3], M[0])
        "vpxorq %%xmm13, %%xmm16, %%xmm13;" // S[13] = hiae_vaes_avx512_SIMD_XOR(S[13], M[0])

        // round 2
        "vmovdqu64 16(%1, %%rax), %%xmm17;" // Load M[1] into xmm17
        "vpxorq %%xmm1, %%xmm2, %%xmm25;" // C[1] = hiae_vaes_avx512_SIMD_XOR(S[1], S[2])
        "vaesenc %%xmm17, %%xmm25, %%xmm25;" // C[1] = hiae_vaes_avx512_AESENC(C[1], M[1])
        "vaesenc %%xmm25, %%xmm14, %%xmm1;" // S[17] = hiae_vaes_avx512_AESENC(S[14], C[1])
        "vpxorq %%xmm4, %%xmm17, %%xmm4;" // S[4] = hiae_vaes_avx512_SIMD_XOR(S[4], M[1])
        "vpxorq %%xmm14, %%xmm17, %%xmm14;" // S[14] = hiae_vaes_avx512_SIMD_XOR(S[14], M[1])

        // round 3
        "vmovdqu64 32(%1, %%rax), %%xmm18;" // Load M[2] into xmm18
        "vpxorq %%xmm2, %%xmm3, %%xmm26;" // C[2] = hiae_vaes_avx512_SIMD_XOR(S[2], S[3])
        "vaesenc %%xmm18, %%xmm26, %%xmm26;" // C[2] = hiae_vaes_avx512_AESENC(C[2], M[2])
        "vaesenc %%xmm26, %%xmm15, %%xmm2;" // S[18] = hiae_vaes_avx512_AESENC(S[15], C[2])
        "vpxorq %%xmm5, %%xmm18, %%xmm5;" // S[5] = hiae_vaes_avx512_SIMD_XOR(S[5], M[2])
        "vpxorq %%xmm15, %%xmm18, %%xmm15;" // S[15] = hiae_vaes_avx512_SIMD_XOR(S[15], M[2])

        // round 4
        "vmovdqu64 48(%1, %%rax), %%xmm19;" // Load M[3] into xmm19
        "vpxorq %%xmm3, %%xmm4, %%xmm27;" // C[3] = hiae_vaes_avx512_SIMD_XOR(S[3], S[4])
        "vaesenc %%xmm19, %%xmm27, %%xmm27;" // C[3] = hiae_vaes_avx512_AESENC(C[3], M[3])
        "vaesenc %%xmm27, %%xmm0, %%xmm3;" // S[19] = hiae_vaes_avx512_AESENC(S[0], C[3])
        "vpxorq %%xmm6, %%xmm19, %%xmm6;" // S[6] = hiae_vaes_avx512_SIMD_XOR(S[6], M[3])
        "vpxorq %%xmm0, %%xmm19, %%xmm0;" // S[0] = hiae_vaes_avx512_SIMD_XOR(S[0], M[3])

        // round 5
        "vmovdqu64 64(%1, %%rax), %%xmm20;" // Load M[4] into xmm20
        "vpxorq %%xmm4, %%xmm5, %%xmm28;" // C[4] = hiae_vaes_avx512_SIMD_XOR(S[4], S[5])
        "vaesenc %%xmm20, %%xmm28, %%xmm28;" // C[4] = hiae_vaes_avx512_AESENC(C[4], M[4])
        "vaesenc %%xmm28, %%xmm1, %%xmm4;" // S[20] = hiae_vaes_avx512_AESENC(S[1], C[4])
        "vpxorq %%xmm7, %%xmm20, %%xmm7;" // S[7] = hiae_vaes_avx512_SIMD_XOR(S[7], M[4])
        "vpxorq %%xmm1, %%xmm20, %%xmm1;" // S[1] = hiae_vaes_avx512_SIMD_XOR(S[1], M[4])

        // round 6
        "vmovdqu64 80(%1, %%rax), %%xmm21;" // Load M[5] into xmm21
        "vpxorq %%xmm5, %%xmm6, %%xmm29;" // C[5] = hiae_vaes_avx512_SIMD_XOR(S[5], S[6])
        "vaesenc %%xmm21, %%xmm29, %%xmm29;" // C[5] = hiae_vaes_avx512_AESENC(C[5], M[5])
        "vaesenc %%xmm29, %%xmm2, %%xmm5;" // S[21] = hiae_vaes_avx512_AESENC(S[2], C[5])
        "vpxorq %%xmm8, %%xmm21, %%xmm8;" // S[8] = hiae_vaes_avx512_SIMD_XOR(S[8], M[5])
        "vpxorq %%xmm2, %%xmm21, %%xmm2;" // S[2] = hiae_vaes_avx512_SIMD_XOR(S[2], M[5])

        // round 7
        "vmovdqu64 96(%1, %%rax), %%xmm22;" // Load M[6] into xmm22
        "vpxorq %%xmm6, %%xmm7, %%xmm30;" // C[6] = hiae_vaes_avx512_SIMD_XOR(S[6], S[7])
        "vaesenc %%xmm22, %%xmm30, %%xmm30;" // C[6] = hiae_vaes_avx512_AESENC(C[6], M[6])
        "vaesenc %%xmm30, %%xmm3, %%xmm6;" // S[22] = hiae_vaes_avx512_AESENC(S[3], C[6])
        "vpxorq %%xmm9, %%xmm22, %%xmm9;" // S[9] = hiae_vaes_avx512_SIMD_XOR(S[9], M[6])
        "vpxorq %%xmm3, %%xmm22, %%xmm3;" // S[3] = hiae_vaes_avx512_SIMD_XOR(S[3], M[6])

        // round 8
        "vmovdqu64 112(%1, %%rax), %%xmm23;" // Load M[7] into xmm23
        "vpxorq %%xmm7, %%xmm8, %%xmm31;" // C[7] = hiae_vaes_avx512_SIMD_XOR(S[7], S[8])
        "vaesenc %%xmm23, %%xmm31, %%xmm31;" // C[7] = hiae_vaes_avx512_AESENC(C[7], M[7])
        "vaesenc %%xmm31, %%xmm4, %%xmm7;" // S[23] = hiae_vaes_avx512_AESENC(S[4], C[7])
        "vpxorq %%xmm10, %%xmm23, %%xmm10;" // S[10] = hiae_vaes_avx512_SIMD_XOR(S[10], M[7])
        "vpxorq %%xmm4, %%xmm23, %%xmm4;" // S[4] = hiae_vaes_avx512_SIMD_XOR(S[4], M[7])

        // round 9
        "vmovdqa64 128(%1, %%rax), %%xmm16;" // Load M[8] into xmm16
        "vpxorq %%xmm8, %%xmm9, %%xmm24;" // C[8] = hiae_vaes_avx512_SIMD_XOR(S[8], S[9])
        "vaesenc %%xmm16, %%xmm24, %%xmm24;" // C[8] = hiae_vaes_avx512_AESENC(M[8], C[8])
        "vaesenc %%xmm24, %%xmm5, %%xmm8;" // S[24] = hiae_vaes_avx512_AESENC(C[8], S[5])
        "vpxorq %%xmm11, %%xmm16, %%xmm11;" // S[11] = hiae_vaes_avx512_SIMD_XOR(S[11], M[8])
        "vpxorq %%xmm5, %%xmm16, %%xmm5;" // S[5] = hiae_vaes_avx512_SIMD_XOR(S[5], M[8])

        // round 10
        "vmovdqa64 144(%1, %%rax), %%xmm17;" // Load M[9] into xmm17
        "vpxorq %%xmm9, %%xmm10, %%xmm25;" // C[9] = hiae_vaes_avx512_SIMD_XOR(S[9], S[10])
        "vaesenc %%xmm17, %%xmm25, %%xmm25;" // C[9] = hiae_vaes_avx512_AESENC(M[9], C[9])
        "vaesenc %%xmm25, %%xmm6, %%xmm9;" // S[25] = hiae_vaes_avx512_AESENC(C[9], S[6])
        "vpxorq %%xmm12, %%xmm17, %%xmm12;" // S[12] = hiae_vaes_avx512_SIMD_XOR(S[12], M[9])
        "vpxorq %%xmm6, %%xmm17, %%xmm6;" // S[6] = hiae_vaes_avx512_SIMD_XOR(S[6], M[9])

        // round 11
        "vmovdqa64 160(%1, %%rax), %%xmm18;" // Load M[10] into xmm18
        "vpxorq %%xmm10, %%xmm11, %%xmm26;" // C[10] = hiae_vaes_avx512_SIMD_XOR(S[10], S[11])
        "vaesenc %%xmm18, %%xmm26, %%xmm26;" // C[10] = hiae_vaes_avx512_AESENC(M[10], C[10])
        "vaesenc %%xmm26, %%xmm7, %%xmm10;" // S[26] = hiae_vaes_avx512_AESENC(C[10], S[7])
        "vpxorq %%xmm13, %%xmm18, %%xmm13;" // S[13] = hiae_vaes_avx512_SIMD_XOR(S[13], M[10])
        "vpxorq %%xmm7, %%xmm18, %%xmm7;" // S[7] = hiae_vaes_avx512_SIMD_XOR(S[7], M[10])

        // round 12
        "vmovdqa64 176(%1, %%rax), %%xmm19;" // Load M[11] into xmm19
        "vpxorq %%xmm11, %%xmm12, %%xmm27;" // C[11] = hiae_vaes_avx512_SIMD_XOR(S[11], S[12])
        "vaesenc %%xmm19, %%xmm27, %%xmm27;" // C[11] = hiae_vaes_avx512_AESENC(M[11], C[11])
        "vaesenc %%xmm27, %%xmm8, %%xmm11;" // S[27] = hiae_vaes_avx512_AESENC(C[11], S[8])
        "vpxorq %%xmm14, %%xmm19, %%xmm14;" // S[14] = hiae_vaes_avx512_SIMD_XOR(S[14], M[11])
        "vpxorq %%xmm8, %%xmm19, %%xmm8;" // S[8] = hiae_vaes_avx512_SIMD_XOR(S[8], M[11])

        // round 13
        "vmovdqa64 192(%1, %%rax), %%xmm20;" // Load M[12] into xmm20
        "vpxorq %%xmm12, %%xmm13, %%xmm28;" // C[12] = hiae_vaes_avx512_SIMD_XOR(S[12], S[13])
        "vaesenc %%xmm20, %%xmm28, %%xmm28;" // C[12] = hiae_vaes_avx512_AESENC(M[12], C[12])
        "vaesenc %%xmm28, %%xmm9, %%xmm12;" // S[28] = hiae_vaes_avx512_AESENC(C[12], S[9])
        "vpxorq %%xmm15, %%xmm20, %%xmm15;" // S[15] = hiae_vaes_avx512_SIMD_XOR(S[15], M[12])
        "vpxorq %%xmm9, %%xmm20, %%xmm9;" // S[9] = hiae_vaes_avx512_SIMD_XOR(S[9], M[12])

        // round 14
        "vmovdqa64 208(%1, %%rax), %%xmm21;" // Load M[13] into xmm21
        "vpxorq %%xmm13, %%xmm14, %%xmm29;" // C[13] = hiae_vaes_avx512_SIMD_XOR(S[13], S[14])
        "vaesenc %%xmm21, %%xmm29, %%xmm29;" // C[13] = hiae_vaes_avx512_AESENC(M[13], C[13])
        "vaesenc %%xmm29, %%xmm10, %%xmm13;" // S[29] = hiae_vaes_avx512_AESENC(C[13], S[10])
        "vpxorq %%xmm0, %%xmm21, %%xmm0;" // S[0] = hiae_vaes_avx512_SIMD_XOR(S[0], M[13])
        "vpxorq %%xmm10, %%xmm21, %%xmm10;" // S[10] = hiae_vaes_avx512_SIMD_XOR(S[10], M[13])

        // round 15
        "vmovdqa64 224(%1, %%rax), %%xmm22;" // Load M[14] into xmm22
        "vpxorq %%xmm14, %%xmm15, %%xmm30;" // C[14] = hiae_vaes_avx512_SIMD_XOR(S[14], S[15])
        "vaesenc %%xmm22, %%xmm30, %%xmm30;" // C[14] = hiae_vaes_avx512_AESENC(M[14], C[14])
        "vaesenc %%xmm30, %%xmm11, %%xmm14;" // S[30] = hiae_vaes_avx512_AESENC(C[14], S[11])
        "vpxorq %%xmm1, %%xmm22, %%xmm1;" // S[1] = hiae_vaes_avx512_SIMD_XOR(S[1], M[14])
        "vpxorq %%xmm11, %%xmm22, %%xmm11;" // S[11] = hiae_vaes_avx512_SIMD_XOR(S[11], M[14])

        // round 16
        "vmovdqa64 240(%1, %%rax), %%xmm23;" // Load M[15] into xmm23
        "vpxorq %%xmm15, %%xmm0, %%xmm31;" // C[15] = hiae_vaes_avx512_SIMD_XOR(S[15], S[0])
        "vaesenc %%xmm23, %%xmm31, %%xmm31;" // C[15] = hiae_vaes_avx512_AESENC(M[15], C[15])
        "vaesenc %%xmm31, %%xmm12, %%xmm15;" // S[31] = hiae_vaes_avx512_AESENC(C[15], S[12])
        "vpxorq %%xmm2, %%xmm23, %%xmm2;" // S[2] = hiae_vaes_avx512_SIMD_XOR(S[2], M[15])
        "vpxorq %%xmm12, %%xmm23, %%xmm12;" // S[12] = hiae_vaes_avx512_SIMD_XOR(S[12], M[15])

        "addq $256, %%rax;" // i += 256
        "jmp 1b;" // Loop back

        "2:;" // Loop end

        // Write back state
        "vmovdqa64 %%xmm0, (%0);"
        "vmovdqa64 %%xmm1, 16(%0);"
        "vmovdqa64 %%xmm2, 32(%0);"
        "vmovdqa64 %%xmm3, 48(%0);"
        "vmovdqa64 %%xmm4, 64(%0);"
        "vmovdqa64 %%xmm5, 80(%0);"
        "vmovdqa64 %%xmm6, 96(%0);"
        "vmovdqa64 %%xmm7, 112(%0);"
        "vmovdqa64 %%xmm8, 128(%0);"
        "vmovdqa64 %%xmm9, 144(%0);"
        "vmovdqa64 %%xmm10, 160(%0);"
        "vmovdqa64 %%xmm11, 176(%0);"
        "vmovdqa64 %%xmm12, 192(%0);"
        "vmovdqa64 %%xmm13, 208(%0);"
        "vmovdqa64 %%xmm14, 224(%0);"
        "vmovdqa64 %%xmm15, 240(%0);"

        :
        : "r"(state), "r"(ad), "r"(prefix) // input dst, src, prefix, state
        : "%rax", "%xmm0", "%xmm1", "%xmm2", "%xmm3", "%xmm4", "%xmm5", "%xmm6", "%xmm7", "%xmm8",
          "%xmm9", "%xmm10", "%xmm11", "%xmm12", "%xmm13", "%xmm14", "%xmm15", "%xmm16", "%xmm17",
          "%xmm18", "%xmm19", "%xmm20", "%xmm21", "%xmm22", "%xmm23", "%xmm24", "%xmm25", "%xmm26",
          "%xmm27", "%xmm28", "%xmm29", "%xmm30", "%xmm31", "memory");
    i = prefix;

    size_t pad = len % BLOCK_SIZE;
    len -= pad;
    for (; i < len; i += BLOCK_SIZE) {
        M[0] = hiae_vaes_avx512_SIMD_LOAD(ad + i);
        hiae_vaes_avx512_update_state_offset(state, tmp, M[0], 0);
        hiae_vaes_avx512_state_shift(state);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memset(buf, 0x00, sizeof(buf));
        memcpy(buf, ad + len, pad);
        M[0] = hiae_vaes_avx512_SIMD_LOAD(buf);
        hiae_vaes_avx512_update_state_offset(state, tmp, M[0], 0);
        hiae_vaes_avx512_state_shift(state);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_finalize_vaes(HiAE_state_t *state_opaque, uint64_t ad_len, uint64_t msg_len, uint8_t *tag)
{
    hiae_vaes_avx512_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    uint64_t lens[2];
    lens[0] = ad_len * 8;
    lens[1] = msg_len * 8;
    hiae_vaes_avx512_DATA128b temp, tmp[STATE];
    temp = hiae_vaes_avx512_SIMD_LOAD((uint8_t *) lens);
    hiae_vaes_avx512_init_update(state, tmp, temp);
    hiae_vaes_avx512_init_update(state, tmp, temp);
    temp = state[0];
    for (size_t i = 1; i < STATE; ++i) {
        temp = hiae_vaes_avx512_SIMD_XOR(temp, state[i]);
    }
    hiae_vaes_avx512_SIMD_STORE(tag, temp);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_vaes(HiAE_state_t *state_opaque, uint8_t *ci, const uint8_t *mi, size_t size)
{
    hiae_vaes_avx512_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_vaes_avx512_DATA128b M[STATE], C[STATE];

    // VAES optimized assembly code for encryption
    __asm__ volatile(
        // Load state into xmm0-xmm15
        "vmovdqa64 (%3), %%xmm0;" // state[0]
        "vmovdqa64 16(%3), %%xmm1;" // state[1]
        "vmovdqa64 32(%3), %%xmm2;" // state[2]
        "vmovdqa64 48(%3), %%xmm3;" // state[3]
        "vmovdqa64 64(%3), %%xmm4;" // state[4]
        "vmovdqa64 80(%3), %%xmm5;" // state[5]
        "vmovdqa64 96(%3), %%xmm6;" // state[6]
        "vmovdqa64 112(%3), %%xmm7;" // state[7]
        "vmovdqa64 128(%3), %%xmm8;" // state[8]
        "vmovdqa64 144(%3), %%xmm9;" // state[9]
        "vmovdqa64 160(%3), %%xmm10;" // state[10]
        "vmovdqa64 176(%3), %%xmm11;" // state[11]
        "vmovdqa64 192(%3), %%xmm12;" // state[12]
        "vmovdqa64 208(%3), %%xmm13;" // state[13]
        "vmovdqa64 224(%3), %%xmm14;" // state[14]
        "vmovdqa64 240(%3), %%xmm15;" // state[15]

        "movq $0, %%rax;" // Initialize counter i = 0
        "1:;" // Loop start
        "cmpq %2, %%rax;" // Compare i and prefix
        "jge 2f;" // If i >= prefix, jump to loop end

        // Prefetch next iteration data (512 bytes ahead)
        "prefetcht0 512(%1, %%rax);" // Prefetch next chunk for reading (plaintext)
        "prefetcht0 512(%0, %%rax);" // Prefetch next chunk for writing (ciphertext)
        "prefetcht0 576(%1, %%rax);" // Prefetch more data (cache line boundary)

        // round 1
        "vmovdqu64 0(%1, %%rax), %%xmm16;" // Load M[0] into xmm16
        "vpxorq %%xmm0, %%xmm1, %%xmm24;" // C[0] = hiae_vaes_avx512_SIMD_XOR(S[0], S[1])
        "vaesenc %%xmm16, %%xmm24, %%xmm24;" // C[0] = hiae_vaes_avx512_AESENC(C[0], M[0])
        "vaesenc %%xmm24, %%xmm13, %%xmm0;" // S[16] = hiae_vaes_avx512_AESENC(S[13], C[0])
        "vpxorq %%xmm24, %%xmm9, %%xmm24;" // C[0] = hiae_vaes_avx512_SIMD_XOR(C[0], S[9])
        "vpxorq %%xmm3, %%xmm16, %%xmm3;" // S[3] = hiae_vaes_avx512_SIMD_XOR(S[3], M[0])
        "vpxorq %%xmm13, %%xmm16, %%xmm13;" // S[13] = hiae_vaes_avx512_SIMD_XOR(S[13], M[0])
        "vmovdqu64 %%xmm24, 0(%0, %%rax);" // Write back C[0] to ci[i:i+16]

        // round 2
        "vmovdqu64 16(%1, %%rax), %%xmm17;" // Load M[1] into xmm17
        "vpxorq %%xmm1, %%xmm2, %%xmm25;" // C[1] = hiae_vaes_avx512_SIMD_XOR(S[1], S[2])
        "vaesenc %%xmm17, %%xmm25, %%xmm25;" // C[1] = hiae_vaes_avx512_AESENC(C[1], M[1])
        "vaesenc %%xmm25, %%xmm14, %%xmm1;" // S[17] = hiae_vaes_avx512_AESENC(S[14], C[1])
        "vpxorq %%xmm25, %%xmm10, %%xmm25;" // C[1] = hiae_vaes_avx512_SIMD_XOR(C[1], S[10])
        "vpxorq %%xmm4, %%xmm17, %%xmm4;" // S[4] = hiae_vaes_avx512_SIMD_XOR(S[4], M[1])
        "vpxorq %%xmm14, %%xmm17, %%xmm14;" // S[14] = hiae_vaes_avx512_SIMD_XOR(S[14], M[1])
        "vmovdqu64 %%xmm25, 16(%0, %%rax);" // Write back C[1] to ci[i+16:i+32]

        // round 3
        "vmovdqu64 32(%1, %%rax), %%xmm18;" // Load M[2] into xmm18
        "vpxorq %%xmm2, %%xmm3, %%xmm26;" // C[2] = hiae_vaes_avx512_SIMD_XOR(S[2], S[3])
        "vaesenc %%xmm18, %%xmm26, %%xmm26;" // C[2] = hiae_vaes_avx512_AESENC(C[2], M[2])
        "vaesenc %%xmm26, %%xmm15, %%xmm2;" // S[18] = hiae_vaes_avx512_AESENC(S[15], C[2])
        "vpxorq %%xmm26, %%xmm11, %%xmm26;" // C[2] = hiae_vaes_avx512_SIMD_XOR(C[2], S[11])
        "vpxorq %%xmm5, %%xmm18, %%xmm5;" // S[5] = hiae_vaes_avx512_SIMD_XOR(S[5], M[2])
        "vpxorq %%xmm15, %%xmm18, %%xmm15;" // S[15] = hiae_vaes_avx512_SIMD_XOR(S[15], M[2])
        "vmovdqu64 %%xmm26, 32(%0, %%rax);" // Write back C[2] to ci[i+32:i+48]

        // round 4
        "vmovdqu64 48(%1, %%rax), %%xmm19;" // Load M[3] into xmm19
        "vpxorq %%xmm3, %%xmm4, %%xmm27;" // C[3] = hiae_vaes_avx512_SIMD_XOR(S[3], S[4])
        "vaesenc %%xmm19, %%xmm27, %%xmm27;" // C[3] = hiae_vaes_avx512_AESENC(C[3], M[3])
        "vaesenc %%xmm27, %%xmm0, %%xmm3;" // S[19] = hiae_vaes_avx512_AESENC(S[0], C[3])
        "vpxorq %%xmm27, %%xmm12, %%xmm27;" // C[3] = hiae_vaes_avx512_SIMD_XOR(C[3], S[12])
        "vpxorq %%xmm6, %%xmm19, %%xmm6;" // S[6] = hiae_vaes_avx512_SIMD_XOR(S[6], M[3])
        "vpxorq %%xmm0, %%xmm19, %%xmm0;" // S[0] = hiae_vaes_avx512_SIMD_XOR(S[0], M[3])
        "vmovdqu64 %%xmm27, 48(%0, %%rax);" // Write back C[3] to ci[i+48:i+64]

        // round 5
        "vmovdqu64 64(%1, %%rax), %%xmm20;" // Load M[4] into xmm20
        "vpxorq %%xmm4, %%xmm5, %%xmm28;" // C[4] = hiae_vaes_avx512_SIMD_XOR(S[4], S[5])
        "vaesenc %%xmm20, %%xmm28, %%xmm28;" // C[4] = hiae_vaes_avx512_AESENC(C[4], M[4])
        "vaesenc %%xmm28, %%xmm1, %%xmm4;" // S[20] = hiae_vaes_avx512_AESENC(S[1], C[4])
        "vpxorq %%xmm28, %%xmm13, %%xmm28;" // C[4] = hiae_vaes_avx512_SIMD_XOR(C[4], S[13])
        "vpxorq %%xmm7, %%xmm20, %%xmm7;" // S[7] = hiae_vaes_avx512_SIMD_XOR(S[7], M[4])
        "vpxorq %%xmm1, %%xmm20, %%xmm1;" // S[1] = hiae_vaes_avx512_SIMD_XOR(S[1], M[4])
        "vmovdqu64 %%xmm28, 64(%0, %%rax);" // Write back C[4] to ci[i+64:i+80]

        // round 6
        "vmovdqu64 80(%1, %%rax), %%xmm21;" // Load M[5] into xmm21
        "vpxorq %%xmm5, %%xmm6, %%xmm29;" // C[5] = hiae_vaes_avx512_SIMD_XOR(S[5], S[6])
        "vaesenc %%xmm21, %%xmm29, %%xmm29;" // C[5] = hiae_vaes_avx512_AESENC(C[5], M[5])
        "vaesenc %%xmm29, %%xmm2, %%xmm5;" // S[21] = hiae_vaes_avx512_AESENC(S[2], C[5])
        "vpxorq %%xmm29, %%xmm14, %%xmm29;" // C[5] = hiae_vaes_avx512_SIMD_XOR(C[5], S[14])
        "vpxorq %%xmm8, %%xmm21, %%xmm8;" // S[8] = hiae_vaes_avx512_SIMD_XOR(S[8], M[5])
        "vpxorq %%xmm2, %%xmm21, %%xmm2;" // S[2] = hiae_vaes_avx512_SIMD_XOR(S[2], M[5])
        "vmovdqu64 %%xmm29, 80(%0, %%rax);" // Write back C[5] to ci[i+80:i+96]

        // round 7
        "vmovdqu64 96(%1, %%rax), %%xmm22;" // Load M[6] into xmm22
        "vpxorq %%xmm6, %%xmm7, %%xmm30;" // C[6] = hiae_vaes_avx512_SIMD_XOR(S[6], S[7])
        "vaesenc %%xmm22, %%xmm30, %%xmm30;" // C[6] = hiae_vaes_avx512_AESENC(C[6], M[6])
        "vaesenc %%xmm30, %%xmm3, %%xmm6;" // S[22] = hiae_vaes_avx512_AESENC(S[3], C[6])
        "vpxorq %%xmm30, %%xmm15, %%xmm30;" // C[6] = hiae_vaes_avx512_SIMD_XOR(C[6], S[15])
        "vpxorq %%xmm9, %%xmm22, %%xmm9;" // S[9] = hiae_vaes_avx512_SIMD_XOR(S[9], M[6])
        "vpxorq %%xmm3, %%xmm22, %%xmm3;" // S[3] = hiae_vaes_avx512_SIMD_XOR(S[3], M[6])
        "vmovdqu64 %%xmm30, 96(%0, %%rax);" // Write back C[6] to ci[i+96:i+112]

        // round 8
        "vmovdqu64 112(%1, %%rax), %%xmm23;" // Load M[7] into xmm23
        "vpxorq %%xmm7, %%xmm8, %%xmm31;" // C[7] = hiae_vaes_avx512_SIMD_XOR(S[7], S[8])
        "vaesenc %%xmm23, %%xmm31, %%xmm31;" // C[7] = hiae_vaes_avx512_AESENC(C[7], M[7])
        "vaesenc %%xmm31, %%xmm4, %%xmm7;" // S[23] = hiae_vaes_avx512_AESENC(S[4], C[7])
        "vpxorq %%xmm31, %%xmm0, %%xmm31;" // C[7] = hiae_vaes_avx512_SIMD_XOR(C[7], S[0])
        "vpxorq %%xmm10, %%xmm23, %%xmm10;" // S[10] = hiae_vaes_avx512_SIMD_XOR(S[10], M[7])
        "vpxorq %%xmm4, %%xmm23, %%xmm4;" // S[4] = hiae_vaes_avx512_SIMD_XOR(S[4], M[7])
        "vmovdqu64 %%xmm31, 112(%0, %%rax);" // Write back C[7] to ci[i+112:i+128]

        // round 9
        "vmovdqa64 128(%1, %%rax), %%xmm16;" // Load M[8] into xmm16
        "vpxorq %%xmm8, %%xmm9, %%xmm24;" // C[8] = hiae_vaes_avx512_SIMD_XOR(S[8], S[9])
        "vaesenc %%xmm16, %%xmm24, %%xmm24;" // C[8] = hiae_vaes_avx512_AESENC(M[8], C[8])
        "vaesenc %%xmm24, %%xmm5, %%xmm8;" // S[24] = hiae_vaes_avx512_AESENC(C[8], S[5])
        "vpxorq %%xmm24, %%xmm1, %%xmm24;" // C[8] = hiae_vaes_avx512_SIMD_XOR(C[8], S[1])
        "vpxorq %%xmm11, %%xmm16, %%xmm11;" // S[11] = hiae_vaes_avx512_SIMD_XOR(S[11], M[8])
        "vpxorq %%xmm5, %%xmm16, %%xmm5;" // S[5] = hiae_vaes_avx512_SIMD_XOR(S[5], M[8])
        "vmovdqa64 %%xmm24, 128(%0, %%rax);" // Write back C[8] to ci[i+128:i+144]

        // round 10
        "vmovdqa64 144(%1, %%rax), %%xmm17;" // Load M[9] into xmm17
        "vpxorq %%xmm9, %%xmm10, %%xmm25;" // C[9] = hiae_vaes_avx512_SIMD_XOR(S[9], S[10])
        "vaesenc %%xmm17, %%xmm25, %%xmm25;" // C[9] = hiae_vaes_avx512_AESENC(M[9], C[9])
        "vaesenc %%xmm25, %%xmm6, %%xmm9;" // S[25] = hiae_vaes_avx512_AESENC(C[9], S[6])
        "vpxorq %%xmm25, %%xmm2, %%xmm25;" // C[9] = hiae_vaes_avx512_SIMD_XOR(C[9], S[2])
        "vpxorq %%xmm12, %%xmm17, %%xmm12;" // S[12] = hiae_vaes_avx512_SIMD_XOR(S[12], M[9])
        "vpxorq %%xmm6, %%xmm17, %%xmm6;" // S[6] = hiae_vaes_avx512_SIMD_XOR(S[6], M[9])
        "vmovdqa64 %%xmm25, 144(%0, %%rax);" // Write back C[9] to ci[i+144:i+160]

        // round 11
        "vmovdqa64 160(%1, %%rax), %%xmm18;" // Load M[10] into xmm18
        "vpxorq %%xmm10, %%xmm11, %%xmm26;" // C[10] = hiae_vaes_avx512_SIMD_XOR(S[10], S[11])
        "vaesenc %%xmm18, %%xmm26, %%xmm26;" // C[10] = hiae_vaes_avx512_AESENC(M[10], C[10])
        "vaesenc %%xmm26, %%xmm7, %%xmm10;" // S[26] = hiae_vaes_avx512_AESENC(C[10], S[7])
        "vpxorq %%xmm26, %%xmm3, %%xmm26;" // C[10] = hiae_vaes_avx512_SIMD_XOR(C[10], S[3])
        "vpxorq %%xmm13, %%xmm18, %%xmm13;" // S[13] = hiae_vaes_avx512_SIMD_XOR(S[13], M[10])
        "vpxorq %%xmm7, %%xmm18, %%xmm7;" // S[7] = hiae_vaes_avx512_SIMD_XOR(S[7], M[10])
        "vmovdqa64 %%xmm26, 160(%0, %%rax);" // Write back C[10] to ci[i+160:i+176]

        // round 12
        "vmovdqa64 176(%1, %%rax), %%xmm19;" // Load M[11] into xmm19
        "vpxorq %%xmm11, %%xmm12, %%xmm27;" // C[11] = hiae_vaes_avx512_SIMD_XOR(S[11], S[12])
        "vaesenc %%xmm19, %%xmm27, %%xmm27;" // C[11] = hiae_vaes_avx512_AESENC(M[11], C[11])
        "vaesenc %%xmm27, %%xmm8, %%xmm11;" // S[27] = hiae_vaes_avx512_AESENC(C[11], S[8])
        "vpxorq %%xmm27, %%xmm4, %%xmm27;" // C[11] = hiae_vaes_avx512_SIMD_XOR(C[11], S[4])
        "vpxorq %%xmm14, %%xmm19, %%xmm14;" // S[14] = hiae_vaes_avx512_SIMD_XOR(S[14], M[11])
        "vpxorq %%xmm8, %%xmm19, %%xmm8;" // S[8] = hiae_vaes_avx512_SIMD_XOR(S[8], M[11])
        "vmovdqa64 %%xmm27, 176(%0, %%rax);" // Write back C[11] to ci[i+176:i+192]

        // round 13
        "vmovdqa64 192(%1, %%rax), %%xmm20;" // Load M[12] into xmm20
        "vpxorq %%xmm12, %%xmm13, %%xmm28;" // C[12] = hiae_vaes_avx512_SIMD_XOR(S[12], S[13])
        "vaesenc %%xmm20, %%xmm28, %%xmm28;" // C[12] = hiae_vaes_avx512_AESENC(M[12], C[12])
        "vaesenc %%xmm28, %%xmm9, %%xmm12;" // S[28] = hiae_vaes_avx512_AESENC(C[12], S[9])
        "vpxorq %%xmm28, %%xmm5, %%xmm28;" // C[12] = hiae_vaes_avx512_SIMD_XOR(C[12], S[5])
        "vpxorq %%xmm15, %%xmm20, %%xmm15;" // S[15] = hiae_vaes_avx512_SIMD_XOR(S[15], M[12])
        "vpxorq %%xmm9, %%xmm20, %%xmm9;" // S[9] = hiae_vaes_avx512_SIMD_XOR(S[9], M[12])
        "vmovdqa64 %%xmm28, 192(%0, %%rax);" // Write back C[12] to ci[i+192:i+208]

        // round 14
        "vmovdqa64 208(%1, %%rax), %%xmm21;" // Load M[13] into xmm21
        "vpxorq %%xmm13, %%xmm14, %%xmm29;" // C[13] = hiae_vaes_avx512_SIMD_XOR(S[13], S[14])
        "vaesenc %%xmm21, %%xmm29, %%xmm29;" // C[13] = hiae_vaes_avx512_AESENC(M[13], C[13])
        "vaesenc %%xmm29, %%xmm10, %%xmm13;" // S[29] = hiae_vaes_avx512_AESENC(C[13], S[10])
        "vpxorq %%xmm29, %%xmm6, %%xmm29;" // C[13] = hiae_vaes_avx512_SIMD_XOR(C[13], S[6])
        "vpxorq %%xmm0, %%xmm21, %%xmm0;" // S[0] = hiae_vaes_avx512_SIMD_XOR(S[0], M[13])
        "vpxorq %%xmm10, %%xmm21, %%xmm10;" // S[10] = hiae_vaes_avx512_SIMD_XOR(S[10], M[13])
        "vmovdqa64 %%xmm29, 208(%0, %%rax);" // Write back C[13] to ci[i+208:i+224]

        // round 15
        "vmovdqa64 224(%1, %%rax), %%xmm22;" // Load M[14] into xmm22
        "vpxorq %%xmm14, %%xmm15, %%xmm30;" // C[14] = hiae_vaes_avx512_SIMD_XOR(S[14], S[15])
        "vaesenc %%xmm22, %%xmm30, %%xmm30;" // C[14] = hiae_vaes_avx512_AESENC(M[14], C[14])
        "vaesenc %%xmm30, %%xmm11, %%xmm14;" // S[30] = hiae_vaes_avx512_AESENC(C[14], S[11])
        "vpxorq %%xmm30, %%xmm7, %%xmm30;" // C[14] = hiae_vaes_avx512_SIMD_XOR(C[14], S[7])
        "vpxorq %%xmm1, %%xmm22, %%xmm1;" // S[1] = hiae_vaes_avx512_SIMD_XOR(S[1], M[14])
        "vpxorq %%xmm11, %%xmm22, %%xmm11;" // S[11] = hiae_vaes_avx512_SIMD_XOR(S[11], M[14])
        "vmovdqa64 %%xmm30, 224(%0, %%rax);" // Write back C[14] to ci[i+224:i+240]

        // round 16
        "vmovdqa64 240(%1, %%rax), %%xmm23;" // Load M[15] into xmm23
        "vpxorq %%xmm15, %%xmm0, %%xmm31;" // C[15] = hiae_vaes_avx512_SIMD_XOR(S[15], S[0])
        "vaesenc %%xmm23, %%xmm31, %%xmm31;" // C[15] = hiae_vaes_avx512_AESENC(M[15], C[15])
        "vaesenc %%xmm31, %%xmm12, %%xmm15;" // S[31] = hiae_vaes_avx512_AESENC(C[15], S[12])
        "vpxorq %%xmm31, %%xmm8, %%xmm31;" // C[15] = hiae_vaes_avx512_SIMD_XOR(C[15], S[8])
        "vpxorq %%xmm2, %%xmm23, %%xmm2;" // S[2] = hiae_vaes_avx512_SIMD_XOR(S[2], M[15])
        "vpxorq %%xmm12, %%xmm23, %%xmm12;" // S[12] = hiae_vaes_avx512_SIMD_XOR(S[12], M[15])
        "vmovdqa64 %%xmm31, 240(%0, %%rax);" // Write back C[15] to ci[i+240:i+256]

        "addq $256, %%rax;" // i += 256
        "jmp 1b;" // Loop back

        "2:;" // Loop end

        // Write back state
        "vmovdqa64 %%xmm0, (%3);"
        "vmovdqa64 %%xmm1, 16(%3);"
        "vmovdqa64 %%xmm2, 32(%3);"
        "vmovdqa64 %%xmm3, 48(%3);"
        "vmovdqa64 %%xmm4, 64(%3);"
        "vmovdqa64 %%xmm5, 80(%3);"
        "vmovdqa64 %%xmm6, 96(%3);"
        "vmovdqa64 %%xmm7, 112(%3);"
        "vmovdqa64 %%xmm8, 128(%3);"
        "vmovdqa64 %%xmm9, 144(%3);"
        "vmovdqa64 %%xmm10, 160(%3);"
        "vmovdqa64 %%xmm11, 176(%3);"
        "vmovdqa64 %%xmm12, 192(%3);"
        "vmovdqa64 %%xmm13, 208(%3);"
        "vmovdqa64 %%xmm14, 224(%3);"
        "vmovdqa64 %%xmm15, 240(%3);"

        :
        : "r"(ci), "r"(mi), "r"(prefix), "r"(state) // input ci, mi, prefix, state
        : "%rax", "%xmm0", "%xmm1", "%xmm2", "%xmm3", "%xmm4", "%xmm5", "%xmm6", "%xmm7", "%xmm8",
          "%xmm9", "%xmm10", "%xmm11", "%xmm12", "%xmm13", "%xmm14", "%xmm15", "%xmm16", "%xmm17",
          "%xmm18", "%xmm19", "%xmm20", "%xmm21", "%xmm22", "%xmm23", "%xmm24", "%xmm25", "%xmm26",
          "%xmm27", "%xmm28", "%xmm29", "%xmm30", "%xmm31", "memory");

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;
    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        M[0] = hiae_vaes_avx512_SIMD_LOAD(mi + i + prefix);
        C[0] = hiae_vaes_avx512_enc_offset(state, M[0], 0);
        hiae_vaes_avx512_state_shift(state);
        hiae_vaes_avx512_SIMD_STORE(ci + i + prefix, C[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memcpy(buf, mi + rest + prefix, pad);
        memset(buf + pad, 0, BLOCK_SIZE - pad);
        M[0] = hiae_vaes_avx512_SIMD_LOAD(buf);
        C[0] = hiae_vaes_avx512_enc_offset(state, M[0], 0);
        hiae_vaes_avx512_state_shift(state);
        hiae_vaes_avx512_SIMD_STORE(buf, C[0]);
        memcpy(ci + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_dec_vaes(HiAE_state_t *state_opaque, uint8_t *mi, const uint8_t *ci, size_t size)
{
    hiae_vaes_avx512_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_vaes_avx512_DATA128b M[STATE], C[STATE], tmp[STATE];

    // VAES optimized assembly code for decryption
    __asm__ volatile(
        // Load state into xmm0-xmm15
        "vmovdqa64 (%3), %%xmm0;" // state[0]
        "vmovdqa64 16(%3), %%xmm1;" // state[1]
        "vmovdqa64 32(%3), %%xmm2;" // state[2]
        "vmovdqa64 48(%3), %%xmm3;" // state[3]
        "vmovdqa64 64(%3), %%xmm4;" // state[4]
        "vmovdqa64 80(%3), %%xmm5;" // state[5]
        "vmovdqa64 96(%3), %%xmm6;" // state[6]
        "vmovdqa64 112(%3), %%xmm7;" // state[7]
        "vmovdqa64 128(%3), %%xmm8;" // state[8]
        "vmovdqa64 144(%3), %%xmm9;" // state[9]
        "vmovdqa64 160(%3), %%xmm10;" // state[10]
        "vmovdqa64 176(%3), %%xmm11;" // state[11]
        "vmovdqa64 192(%3), %%xmm12;" // state[12]
        "vmovdqa64 208(%3), %%xmm13;" // state[13]
        "vmovdqa64 224(%3), %%xmm14;" // state[14]
        "vmovdqa64 240(%3), %%xmm15;" // state[15]

        "movq $0, %%rax;" // Initialize counter i = 0
        "1:;" // Loop start
        "cmpq %2, %%rax;" // Compare i and prefix
        "jge 2f;" // If i >= prefix, jump to loop end

        // Prefetch next iteration data (512 bytes ahead)
        "prefetcht0 512(%1, %%rax);" // Prefetch next chunk for reading (ciphertext)
        "prefetcht0 512(%0, %%rax);" // Prefetch next chunk for writing (plaintext)
        "prefetcht0 576(%1, %%rax);" // Prefetch more data (cache line boundary)

        // round 1
        "vmovdqu64 0(%1, %%rax), %%xmm24;" // Load C[0] into xmm24
        "vpxorq %%xmm0, %%xmm1, %%xmm16;" // M[0] = hiae_vaes_avx512_SIMD_XOR(S[0], S[1])
        "vpxorq %%xmm24, %%xmm9, %%xmm24;" // C[0] = hiae_vaes_avx512_SIMD_XOR(S[9], C[0])
        "vaesenc %%xmm24, %%xmm13, %%xmm0;" // S[16] = hiae_vaes_avx512_AESENC(S[13], C[0])
        "vaesenc %%xmm24, %%xmm16, %%xmm16;" // M[0] = hiae_vaes_avx512_AESENC(C[0], M[0])
        "vpxorq %%xmm3, %%xmm16, %%xmm3;" // S[3] = hiae_vaes_avx512_SIMD_XOR(S[3], M[0])
        "vpxorq %%xmm13, %%xmm16, %%xmm13;" // S[13] = hiae_vaes_avx512_SIMD_XOR(S[13], M[0])
        "vmovdqu64 %%xmm16, 0(%0, %%rax);" // Write back M[0] to mi[i+0:i+16]

        // round 2
        "vmovdqu64 16(%1, %%rax), %%xmm25;" // Load C[1] into xmm25
        "vpxorq %%xmm1, %%xmm2, %%xmm17;" // M[1] = hiae_vaes_avx512_SIMD_XOR(S[1], S[2])
        "vpxorq %%xmm25, %%xmm10, %%xmm25;" // C[1] = hiae_vaes_avx512_SIMD_XOR(S[10], C[1])
        "vaesenc %%xmm25, %%xmm14, %%xmm1;" // S[17] = hiae_vaes_avx512_AESENC(S[14], C[1])
        "vaesenc %%xmm25, %%xmm17, %%xmm17;" // M[1] = hiae_vaes_avx512_AESENC(C[1], M[1])
        "vpxorq %%xmm4, %%xmm17, %%xmm4;" // S[4] = hiae_vaes_avx512_SIMD_XOR(S[4], M[1])
        "vpxorq %%xmm14, %%xmm17, %%xmm14;" // S[14] = hiae_vaes_avx512_SIMD_XOR(S[14], M[1])
        "vmovdqu64 %%xmm17, 16(%0, %%rax);" // Write back M[1] to mi[i+16:i+32]

        // round 3
        "vmovdqu64 32(%1, %%rax), %%xmm26;" // Load C[2] into xmm26
        "vpxorq %%xmm2, %%xmm3, %%xmm18;" // M[2] = hiae_vaes_avx512_SIMD_XOR(S[2], S[3])
        "vpxorq %%xmm26, %%xmm11, %%xmm26;" // C[2] = hiae_vaes_avx512_SIMD_XOR(S[11], C[2])
        "vaesenc %%xmm26, %%xmm15, %%xmm2;" // S[18] = hiae_vaes_avx512_AESENC(S[15], C[2])
        "vaesenc %%xmm26, %%xmm18, %%xmm18;" // M[2] = hiae_vaes_avx512_AESENC(C[2], M[2])
        "vpxorq %%xmm5, %%xmm18, %%xmm5;" // S[5] = hiae_vaes_avx512_SIMD_XOR(S[5], M[2])
        "vpxorq %%xmm15, %%xmm18, %%xmm15;" // S[15] = hiae_vaes_avx512_SIMD_XOR(S[15], M[2])
        "vmovdqu64 %%xmm18, 32(%0, %%rax);" // Write back M[2] to mi[i+32:i+48]

        // round 4
        "vmovdqu64 48(%1, %%rax), %%xmm27;" // Load C[3] into xmm27
        "vpxorq %%xmm3, %%xmm4, %%xmm19;" // M[3] = hiae_vaes_avx512_SIMD_XOR(S[3], S[4])
        "vpxorq %%xmm27, %%xmm12, %%xmm27;" // C[3] = hiae_vaes_avx512_SIMD_XOR(S[12], C[3])
        "vaesenc %%xmm27, %%xmm0, %%xmm3;" // S[19] = hiae_vaes_avx512_AESENC(S[16], C[3])
        "vaesenc %%xmm27, %%xmm19, %%xmm19;" // M[3] = hiae_vaes_avx512_AESENC(C[3], M[3])
        "vpxorq %%xmm6, %%xmm19, %%xmm6;" // S[6] = hiae_vaes_avx512_SIMD_XOR(S[6], M[3])
        "vpxorq %%xmm0, %%xmm19, %%xmm0;" // S[16] = hiae_vaes_avx512_SIMD_XOR(S[16], M[3])
        "vmovdqu64 %%xmm19, 48(%0, %%rax);" // Write back M[3] to mi[i+48:i+64]

        // round 5
        "vmovdqu64 64(%1, %%rax), %%xmm28;" // Load C[4] into xmm28
        "vpxorq %%xmm4, %%xmm5, %%xmm20;" // M[4] = hiae_vaes_avx512_SIMD_XOR(S[4], S[5])
        "vpxorq %%xmm28, %%xmm13, %%xmm28;" // C[4] = hiae_vaes_avx512_SIMD_XOR(S[13], C[4])
        "vaesenc %%xmm28, %%xmm1, %%xmm4;" // S[20] = hiae_vaes_avx512_AESENC(S[17], C[4])
        "vaesenc %%xmm28, %%xmm20, %%xmm20;" // M[4] = hiae_vaes_avx512_AESENC(C[4], M[4])
        "vpxorq %%xmm7, %%xmm20, %%xmm7;" // S[7] = hiae_vaes_avx512_SIMD_XOR(S[7], M[4])
        "vpxorq %%xmm1, %%xmm20, %%xmm1;" // S[17] = hiae_vaes_avx512_SIMD_XOR(S[17], M[4])
        "vmovdqu64 %%xmm20, 64(%0, %%rax);" // Write back M[4] to mi[i+64:i+80]

        // round 6
        "vmovdqu64 80(%1, %%rax), %%xmm29;" // Load C[5] into xmm29
        "vpxorq %%xmm5, %%xmm6, %%xmm21;" // M[5] = hiae_vaes_avx512_SIMD_XOR(S[5], S[6])
        "vpxorq %%xmm29, %%xmm14, %%xmm29;" // C[5] = hiae_vaes_avx512_SIMD_XOR(S[14], C[5])
        "vaesenc %%xmm29, %%xmm2, %%xmm5;" // S[21] = hiae_vaes_avx512_AESENC(S[18], C[5])
        "vaesenc %%xmm29, %%xmm21, %%xmm21;" // M[5] = hiae_vaes_avx512_AESENC(C[5], M[5])
        "vpxorq %%xmm8, %%xmm21, %%xmm8;" // S[8] = hiae_vaes_avx512_SIMD_XOR(S[8], M[5])
        "vpxorq %%xmm2, %%xmm21, %%xmm2;" // S[18] = hiae_vaes_avx512_SIMD_XOR(S[18], M[5])
        "vmovdqu64 %%xmm21, 80(%0, %%rax);" // Write back M[5] to mi[i+80:i+96]

        // round 7
        "vmovdqu64 96(%1, %%rax), %%xmm30;" // Load C[6] into xmm30
        "vpxorq %%xmm6, %%xmm7, %%xmm22;" // M[6] = hiae_vaes_avx512_SIMD_XOR(S[6], S[7])
        "vpxorq %%xmm30, %%xmm15, %%xmm30;" // C[6] = hiae_vaes_avx512_SIMD_XOR(S[15], C[6])
        "vaesenc %%xmm30, %%xmm3, %%xmm6;" // S[22] = hiae_vaes_avx512_AESENC(S[19], C[6])
        "vaesenc %%xmm30, %%xmm22, %%xmm22;" // M[6] = hiae_vaes_avx512_AESENC(C[6], M[6])
        "vpxorq %%xmm9, %%xmm22, %%xmm9;" // S[9] = hiae_vaes_avx512_SIMD_XOR(S[9], M[6])
        "vpxorq %%xmm3, %%xmm22, %%xmm3;" // S[19] = hiae_vaes_avx512_SIMD_XOR(S[19], M[6])
        "vmovdqu64 %%xmm22, 96(%0, %%rax);" // Write back M[6] to mi[i+96:i+112]

        // round 8
        "vmovdqu64 112(%1, %%rax), %%xmm31;" // Load C[7] into xmm31
        "vpxorq %%xmm7, %%xmm8, %%xmm23;" // M[7] = hiae_vaes_avx512_SIMD_XOR(S[7], S[8])
        "vpxorq %%xmm31, %%xmm0, %%xmm31;" // C[7] = hiae_vaes_avx512_SIMD_XOR(S[16], C[7])
        "vaesenc %%xmm31, %%xmm4, %%xmm7;" // S[23] = hiae_vaes_avx512_AESENC(S[20], C[7])
        "vaesenc %%xmm31, %%xmm23, %%xmm23;" // M[7] = hiae_vaes_avx512_AESENC(C[7], M[7])
        "vpxorq %%xmm10, %%xmm23, %%xmm10;" // S[10] = hiae_vaes_avx512_SIMD_XOR(S[10], M[7])
        "vpxorq %%xmm4, %%xmm23, %%xmm4;" // S[20] = hiae_vaes_avx512_SIMD_XOR(S[20], M[7])
        "vmovdqu64 %%xmm23, 112(%0, %%rax);" // Write back M[7] to mi[i+112:i+128]

        // round 9
        "vmovdqu64 128(%1, %%rax), %%xmm24;" // Load C[8] into xmm24
        "vpxorq %%xmm8, %%xmm9, %%xmm16;" // M[8] = hiae_vaes_avx512_SIMD_XOR(S[8], S[9])
        "vpxorq %%xmm24, %%xmm1, %%xmm24;" // C[8] = hiae_vaes_avx512_SIMD_XOR(S[17], C[8])
        "vaesenc %%xmm24, %%xmm5, %%xmm8;" // S[24] = hiae_vaes_avx512_AESENC(S[21], C[8])
        "vaesenc %%xmm24, %%xmm16, %%xmm16;" // M[8] = hiae_vaes_avx512_AESENC(C[8], M[8])
        "vpxorq %%xmm11, %%xmm16, %%xmm11;" // S[11] = hiae_vaes_avx512_SIMD_XOR(S[11], M[8])
        "vpxorq %%xmm5, %%xmm16, %%xmm5;" // S[21] = hiae_vaes_avx512_SIMD_XOR(S[21], M[8])
        "vmovdqu64 %%xmm16, 128(%0, %%rax);" // Write back M[8] to mi[i+128:i+144]

        // round 10
        "vmovdqu64 144(%1, %%rax), %%xmm25;" // Load C[9] into xmm25
        "vpxorq %%xmm9, %%xmm10, %%xmm17;" // M[9] = hiae_vaes_avx512_SIMD_XOR(S[9], S[10])
        "vpxorq %%xmm25, %%xmm2, %%xmm25;" // C[9] = hiae_vaes_avx512_SIMD_XOR(S[18], C[9])
        "vaesenc %%xmm25, %%xmm6, %%xmm9;" // S[25] = hiae_vaes_avx512_AESENC(S[22], C[9])
        "vaesenc %%xmm25, %%xmm17, %%xmm17;" // M[9] = hiae_vaes_avx512_AESENC(C[9], M[9])
        "vpxorq %%xmm12, %%xmm17, %%xmm12;" // S[12] = hiae_vaes_avx512_SIMD_XOR(S[12], M[9])
        "vpxorq %%xmm6, %%xmm17, %%xmm6;" // S[22] = hiae_vaes_avx512_SIMD_XOR(S[22], M[9])
        "vmovdqu64 %%xmm17, 144(%0, %%rax);" // Write back M[9] to mi[i+144:i+160]

        // round 11
        "vmovdqu64 160(%1, %%rax), %%xmm26;" // Load C[10] into xmm26
        "vpxorq %%xmm10, %%xmm11, %%xmm18;" // M[10] = hiae_vaes_avx512_SIMD_XOR(S[10], S[11])
        "vpxorq %%xmm26, %%xmm3, %%xmm26;" // C[10] = hiae_vaes_avx512_SIMD_XOR(S[19], C[10])
        "vaesenc %%xmm26, %%xmm7, %%xmm10;" // S[26] = hiae_vaes_avx512_AESENC(S[23], C[10])
        "vaesenc %%xmm26, %%xmm18, %%xmm18;" // M[10] = hiae_vaes_avx512_AESENC(C[10], M[10])
        "vpxorq %%xmm13, %%xmm18, %%xmm13;" // S[13] = hiae_vaes_avx512_SIMD_XOR(S[13], M[10])
        "vpxorq %%xmm7, %%xmm18, %%xmm7;" // S[23] = hiae_vaes_avx512_SIMD_XOR(S[23], M[10])
        "vmovdqu64 %%xmm18, 160(%0, %%rax);" // Write back M[10] to mi[i+160:i+176]

        // round 12
        "vmovdqu64 176(%1, %%rax), %%xmm27;" // Load C[11] into xmm27
        "vpxorq %%xmm11, %%xmm12, %%xmm19;" // M[11] = hiae_vaes_avx512_SIMD_XOR(S[11], S[12])
        "vpxorq %%xmm27, %%xmm4, %%xmm27;" // C[11] = hiae_vaes_avx512_SIMD_XOR(S[20], C[11])
        "vaesenc %%xmm27, %%xmm8, %%xmm11;" // S[27] = hiae_vaes_avx512_AESENC(S[24], C[11])
        "vaesenc %%xmm27, %%xmm19, %%xmm19;" // M[11] = hiae_vaes_avx512_AESENC(C[11], M[11])
        "vpxorq %%xmm14, %%xmm19, %%xmm14;" // S[14] = hiae_vaes_avx512_SIMD_XOR(S[14], M[11])
        "vpxorq %%xmm8, %%xmm19, %%xmm8;" // S[24] = hiae_vaes_avx512_SIMD_XOR(S[24], M[11])
        "vmovdqu64 %%xmm19, 176(%0, %%rax);" // Write back M[11] to mi[i+176:i+192]

        // round 13
        "vmovdqu64 192(%1, %%rax), %%xmm28;" // Load C[12] into xmm28
        "vpxorq %%xmm12, %%xmm13, %%xmm20;" // M[12] = hiae_vaes_avx512_SIMD_XOR(S[12], S[13])
        "vpxorq %%xmm28, %%xmm5, %%xmm28;" // C[12] = hiae_vaes_avx512_SIMD_XOR(S[21], C[12])
        "vaesenc %%xmm28, %%xmm9, %%xmm12;" // S[28] = hiae_vaes_avx512_AESENC(S[25], C[12])
        "vaesenc %%xmm28, %%xmm20, %%xmm20;" // M[12] = hiae_vaes_avx512_AESENC(C[12], M[12])
        "vpxorq %%xmm15, %%xmm20, %%xmm15;" // S[15] = hiae_vaes_avx512_SIMD_XOR(S[15], M[12])
        "vpxorq %%xmm9, %%xmm20, %%xmm9;" // S[25] = hiae_vaes_avx512_SIMD_XOR(S[25], M[12])
        "vmovdqu64 %%xmm20, 192(%0, %%rax);" // Write back M[12] to mi[i+192:i+208]

        // round 14
        "vmovdqu64 208(%1, %%rax), %%xmm29;" // Load C[13] into xmm29
        "vpxorq %%xmm13, %%xmm14, %%xmm21;" // M[13] = hiae_vaes_avx512_SIMD_XOR(S[13], S[14])
        "vpxorq %%xmm29, %%xmm6, %%xmm29;" // C[13] = hiae_vaes_avx512_SIMD_XOR(S[22], C[13])
        "vaesenc %%xmm29, %%xmm10, %%xmm13;" // S[29] = hiae_vaes_avx512_AESENC(S[26], C[13])
        "vaesenc %%xmm29, %%xmm21, %%xmm21;" // M[13] = hiae_vaes_avx512_AESENC(C[13], M[13])
        "vpxorq %%xmm0, %%xmm21, %%xmm0;" // S[16] = hiae_vaes_avx512_SIMD_XOR(S[16], M[13])
        "vpxorq %%xmm10, %%xmm21, %%xmm10;" // S[26] = hiae_vaes_avx512_SIMD_XOR(S[26], M[13])
        "vmovdqu64 %%xmm21, 208(%0, %%rax);" // Write back M[13] to mi[i+208:i+224]

        // round 15
        "vmovdqu64 224(%1, %%rax), %%xmm30;" // Load C[14] into xmm30
        "vpxorq %%xmm14, %%xmm15, %%xmm22;" // M[14] = hiae_vaes_avx512_SIMD_XOR(S[14], S[15])
        "vpxorq %%xmm30, %%xmm7, %%xmm30;" // C[14] = hiae_vaes_avx512_SIMD_XOR(S[23], C[14])
        "vaesenc %%xmm30, %%xmm11, %%xmm14;" // S[30] = hiae_vaes_avx512_AESENC(S[27], C[14])
        "vaesenc %%xmm30, %%xmm22, %%xmm22;" // M[14] = hiae_vaes_avx512_AESENC(C[14], M[14])
        "vpxorq %%xmm1, %%xmm22, %%xmm1;" // S[17] = hiae_vaes_avx512_SIMD_XOR(S[17], M[14])
        "vpxorq %%xmm11, %%xmm22, %%xmm11;" // S[27] = hiae_vaes_avx512_SIMD_XOR(S[27], M[14])
        "vmovdqu64 %%xmm22, 224(%0, %%rax);" // Write back M[14] to mi[i+224:i+240]

        // round 16
        "vmovdqu64 240(%1, %%rax), %%xmm31;" // Load C[15] into xmm31
        "vpxorq %%xmm15, %%xmm0, %%xmm23;" // M[15] = hiae_vaes_avx512_SIMD_XOR(S[15], S[16])
        "vpxorq %%xmm31, %%xmm8, %%xmm31;" // C[15] = hiae_vaes_avx512_SIMD_XOR(S[24], C[15])
        "vaesenc %%xmm31, %%xmm12, %%xmm15;" // S[31] = hiae_vaes_avx512_AESENC(S[28], C[15])
        "vaesenc %%xmm31, %%xmm23, %%xmm23;" // M[15] = hiae_vaes_avx512_AESENC(C[15], M[15])
        "vpxorq %%xmm2, %%xmm23, %%xmm2;" // S[18] = hiae_vaes_avx512_SIMD_XOR(S[18], M[15])
        "vpxorq %%xmm12, %%xmm23, %%xmm12;" // S[28] = hiae_vaes_avx512_SIMD_XOR(S[28], M[15])
        "vmovdqu64 %%xmm23, 240(%0, %%rax);" // Write back M[15] to mi[i+240:i+256]

        "addq $256, %%rax;" // i += 256
        "jmp 1b;" // Loop back

        "2:;" // Loop end

        // Write back state
        "vmovdqa64 %%xmm0, (%3);"
        "vmovdqa64 %%xmm1, 16(%3);"
        "vmovdqa64 %%xmm2, 32(%3);"
        "vmovdqa64 %%xmm3, 48(%3);"
        "vmovdqa64 %%xmm4, 64(%3);"
        "vmovdqa64 %%xmm5, 80(%3);"
        "vmovdqa64 %%xmm6, 96(%3);"
        "vmovdqa64 %%xmm7, 112(%3);"
        "vmovdqa64 %%xmm8, 128(%3);"
        "vmovdqa64 %%xmm9, 144(%3);"
        "vmovdqa64 %%xmm10, 160(%3);"
        "vmovdqa64 %%xmm11, 176(%3);"
        "vmovdqa64 %%xmm12, 192(%3);"
        "vmovdqa64 %%xmm13, 208(%3);"
        "vmovdqa64 %%xmm14, 224(%3);"
        "vmovdqa64 %%xmm15, 240(%3);"

        :
        : "r"(mi), "r"(ci), "r"(prefix), "r"(state) // input mi, ci, prefix, state
        : "%rax", "%xmm0", "%xmm1", "%xmm2", "%xmm3", "%xmm4", "%xmm5", "%xmm6", "%xmm7", "%xmm8",
          "%xmm9", "%xmm10", "%xmm11", "%xmm12", "%xmm13", "%xmm14", "%xmm15", "%xmm16", "%xmm17",
          "%xmm18", "%xmm19", "%xmm20", "%xmm21", "%xmm22", "%xmm23", "%xmm24", "%xmm25", "%xmm26",
          "%xmm27", "%xmm28", "%xmm29", "%xmm30", "%xmm31", "memory");

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;

    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        C[0] = hiae_vaes_avx512_SIMD_LOAD(ci + i + prefix);
        M[0] = hiae_vaes_avx512_dec_offset(state, tmp, C[0], 0);
        hiae_vaes_avx512_state_shift(state);
        hiae_vaes_avx512_SIMD_STORE(mi + i + prefix, M[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        uint8_t mask[BLOCK_SIZE];
        memcpy(buf, ci + rest + prefix, pad);
        memset(mask, 0xff, pad);
        memset(mask + pad, 0x00, BLOCK_SIZE - pad);
        C[0] = hiae_vaes_avx512_SIMD_LOAD(buf);
        M[0] = hiae_vaes_avx512_SIMD_LOAD(mask);
        C[0] = hiae_vaes_avx512_keystream_block(state, tmp, C[0], 0);
        C[0] = hiae_vaes_avx512_SIMD_AND(C[0], M[0]);
        hiae_vaes_avx512_update_state_offset(state, tmp, C[0], 0);
        hiae_vaes_avx512_state_shift(state);
        hiae_vaes_avx512_SIMD_STORE(buf, C[0]);
        memcpy(mi + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_partial_noupdate_vaes(HiAE_state_t  *state_opaque,
                               uint8_t       *ci,
                               const uint8_t *mi,
                               size_t         size)
{
    if (size == 0)
        return;

    hiae_vaes_avx512_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_vaes_avx512_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];

    memcpy(buf, mi, size);
    memset(buf + size, 0, BLOCK_SIZE - size);
    M[0] = hiae_vaes_avx512_SIMD_LOAD(buf);
    C[0] = hiae_vaes_avx512_enc_offset(state, M[0], 0);
    hiae_vaes_avx512_SIMD_STORE(buf, C[0]);
    memcpy(ci, buf, size);
}

static void
HiAE_dec_partial_noupdate_vaes(HiAE_state_t  *state_opaque,
                               uint8_t       *mi,
                               const uint8_t *ci,
                               size_t         size)
{
    if (size == 0)
        return;

    hiae_vaes_avx512_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_vaes_avx512_DATA128b M[1], C[1], tmp[STATE];
    uint8_t  buf[BLOCK_SIZE];
    uint8_t  mask[BLOCK_SIZE];

    memcpy(buf, ci, size);
    memset(mask, 0xff, size);
    memset(mask + size, 0x00, BLOCK_SIZE - size);
    C[0] = hiae_vaes_avx512_SIMD_LOAD(buf);
    M[0] = hiae_vaes_avx512_SIMD_LOAD(mask);
    C[0] = hiae_vaes_avx512_keystream_block(state, tmp, C[0], 0);
    C[0] = hiae_vaes_avx512_SIMD_AND(C[0], M[0]);
    hiae_vaes_avx512_SIMD_STORE(buf, C[0]);
    memcpy(mi, buf, size);
}

static int
HiAE_encrypt_vaes(const uint8_t *key,
                  const uint8_t *nonce,
                  const uint8_t *msg,
                  uint8_t       *ct,
                  size_t         msg_len,
                  const uint8_t *ad,
                  size_t         ad_len,
                  uint8_t       *tag)
{
    HiAE_state_t state;
    HiAE_init_vaes(&state, key, nonce);
    HiAE_absorb_vaes(&state, ad, ad_len);
    HiAE_enc_vaes(&state, ct, msg, msg_len);
    HiAE_finalize_vaes(&state, ad_len, msg_len, tag);

    return 0;
}

static int
HiAE_decrypt_vaes(const uint8_t *key,
                  const uint8_t *nonce,
                  uint8_t       *msg,
                  const uint8_t *ct,
                  size_t         ct_len,
                  const uint8_t *ad,
                  size_t         ad_len,
                  const uint8_t *tag)
{
    HiAE_state_t state;
    uint8_t      computed_tag[HIAE_MACBYTES];
    HiAE_init_vaes(&state, key, nonce);
    HiAE_absorb_vaes(&state, ad, ad_len);
    HiAE_dec_vaes(&state, msg, ct, ct_len);
    HiAE_finalize_vaes(&state, ad_len, ct_len, computed_tag);

    return hiae_constant_time_compare(computed_tag, tag, HIAE_MACBYTES);
}

static int
HiAE_mac_vaes(const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len,
              uint8_t *tag)
{
    HiAE_state_t state;
    HiAE_init_vaes(&state, key, nonce);
    HiAE_absorb_vaes(&state, data, data_len);
    HiAE_finalize_vaes(&state, data_len, 0, tag);

    return 0;
}

const HiAE_impl_t hiae_vaes_avx512_impl = { .name                 = "VAES+AVX512",
                                            .init                 = HiAE_init_vaes,
                                            .absorb               = HiAE_absorb_vaes,
                                            .finalize             = HiAE_finalize_vaes,
                                            .enc                  = HiAE_enc_vaes,
                                            .dec                  = HiAE_dec_vaes,
                                            .enc_partial_noupdate = HiAE_enc_partial_noupdate_vaes,
                                            .dec_partial_noupdate = HiAE_dec_partial_noupdate_vaes,
                                            .encrypt              = HiAE_encrypt_vaes,
                                            .decrypt              = HiAE_decrypt_vaes,
                                            .mac                  = HiAE_mac_vaes };

#    ifdef __clang__
#        pragma clang attribute pop
#    endif

#else
// VAES+AVX512 not available, provide stub implementation
const HiAE_impl_t hiae_vaes_avx512_impl = { .name                 = NULL,
                                            .init                 = NULL,
                                            .absorb               = NULL,
                                            .finalize             = NULL,
                                            .enc                  = NULL,
                                            .dec                  = NULL,
                                            .enc_partial_noupdate = NULL,
                                            .dec_partial_noupdate = NULL,
                                            .encrypt              = NULL,
                                            .decrypt              = NULL,
                                            .mac                  = NULL };
#endif

/* End of HiAE_vaes_avx512.c */

/* =====================================================
 * HiAE_arm.c - hiae_arm implementation
 * =====================================================
 */

#if defined(__aarch64__) || defined(_M_ARM64)

#    ifndef __ARM_FEATURE_CRYPTO
#        define __ARM_FEATURE_CRYPTO 1
#    endif
#    ifndef __ARM_FEATURE_AES
#        define __ARM_FEATURE_AES 1
#    endif

#    include <arm_neon.h>

#    ifdef __clang__
#        pragma clang attribute push(__attribute__((target("neon,crypto,aes"))), \
                                     apply_to = function)
#    elif defined(__GNUC__)
#        pragma GCC target("+simd+crypto")
#    endif

// Prefetch macros - tuned for ARM64
// locality: 0 = no temporal locality (streaming), 3 = high temporal locality
#    ifdef _MSC_VER
// MSVC doesn't have __builtin_prefetch, use ARM64 specific intrinsics
#        include <intrin.h>
#        define hiae_arm_PREFETCH_READ(addr, locality)  __prefetch((const void *) (addr))
#        define hiae_arm_PREFETCH_WRITE(addr, locality) __prefetch((const void *) (addr))
#    else
#        define hiae_arm_PREFETCH_READ(addr, locality)  __builtin_prefetch((addr), 0, (locality))
#        define hiae_arm_PREFETCH_WRITE(addr, locality) __builtin_prefetch((addr), 1, (locality))
#    endif

// Prefetch distance in bytes - tuned for typical ARM64 cache line size (64-128 bytes)
#    define hiae_arm_PREFETCH_DISTANCE 128

typedef uint8x16_t hiae_arm_DATA128b;

#    define hiae_arm_SIMD_LOAD(x)       vld1q_u8(x)
#    define hiae_arm_SIMD_STORE(dst, x) vst1q_u8(dst, x)
#    define hiae_arm_SIMD_XOR(a, b)     veorq_u8(a, b)
#    define hiae_arm_SIMD_AND(a, b)     vandq_u8(a, b)
#    define hiae_arm_SIMD_ZERO_128()    vmovq_n_u8(0)
#    define hiae_arm_XAESL(x, y)        vaesmcq_u8(vaeseq_u8(x, y))
#    define hiae_arm_AESL(x)            hiae_arm_XAESL(x, hiae_arm_SIMD_ZERO_128())

static inline void
hiae_arm_update_state_offset(hiae_arm_DATA128b *state, hiae_arm_DATA128b M, int offset)
{
    hiae_arm_DATA128b temp = hiae_arm_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    temp          = hiae_arm_SIMD_XOR(temp, M);
    state[(0 + offset) % STATE]   = hiae_arm_SIMD_XOR(temp, hiae_arm_AESL(state[(P_4 + offset) % STATE]));
    state[(I_1 + offset) % STATE] = hiae_arm_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_arm_SIMD_XOR(state[(I_2 + offset) % STATE], M);
}

static inline hiae_arm_DATA128b
hiae_arm_keystream_block(hiae_arm_DATA128b *state, hiae_arm_DATA128b M, int offset)
{
    M = hiae_arm_SIMD_XOR(M, hiae_arm_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]));
    M = hiae_arm_SIMD_XOR(M, state[(P_7 + offset) % STATE]);
    return M;
}

static inline hiae_arm_DATA128b
hiae_arm_enc_offset(hiae_arm_DATA128b *state, hiae_arm_DATA128b M, int offset)
{
    hiae_arm_DATA128b C = hiae_arm_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    C          = hiae_arm_SIMD_XOR(C, M);
    state[(0 + offset) % STATE]   = hiae_arm_SIMD_XOR(C, hiae_arm_AESL(state[(P_4 + offset) % STATE]));
    C                             = hiae_arm_SIMD_XOR(C, state[(P_7 + offset) % STATE]);
    state[(I_1 + offset) % STATE] = hiae_arm_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_arm_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return C;
}

static inline hiae_arm_DATA128b
hiae_arm_dec_offset(hiae_arm_DATA128b *state, hiae_arm_DATA128b *tmp, hiae_arm_DATA128b C, int offset)
{
    tmp[offset] = hiae_arm_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    hiae_arm_DATA128b M  = hiae_arm_SIMD_XOR(state[(P_7 + offset) % STATE], C);
    state[(0 + offset) % STATE]   = hiae_arm_SIMD_XOR(M, hiae_arm_AESL(state[(P_4 + offset) % STATE]));
    M                             = hiae_arm_SIMD_XOR(M, tmp[offset]);
    state[(I_1 + offset) % STATE] = hiae_arm_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_arm_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return M;
}

#    define hiae_arm_LOAD_1BLOCK_offset_enc(M, offset)  (M) = hiae_arm_SIMD_LOAD(mi + i + 0 + BLOCK_SIZE * offset);
#    define hiae_arm_LOAD_1BLOCK_offset_dec(C, offset)  (C) = hiae_arm_SIMD_LOAD(ci + i + 0 + BLOCK_SIZE * offset);
#    define hiae_arm_LOAD_1BLOCK_offset_ad(M, offset)   (M) = hiae_arm_SIMD_LOAD(ad + i + 0 + BLOCK_SIZE * offset);
#    define hiae_arm_STORE_1BLOCK_offset_enc(C, offset) hiae_arm_SIMD_STORE(ci + i + 0 + BLOCK_SIZE * offset, (C));
#    define hiae_arm_STORE_1BLOCK_offset_dec(M, offset) hiae_arm_SIMD_STORE(mi + i + 0 + BLOCK_SIZE * offset, (M));

static inline void
hiae_arm_state_shift(hiae_arm_DATA128b *state)
{
    hiae_arm_DATA128b temp = state[0];
    state[0]      = state[1];
    state[1]      = state[2];
    state[2]      = state[3];
    state[3]      = state[4];
    state[4]      = state[5];
    state[5]      = state[6];
    state[6]      = state[7];
    state[7]      = state[8];
    state[8]      = state[9];
    state[9]      = state[10];
    state[10]     = state[11];
    state[11]     = state[12];
    state[12]     = state[13];
    state[13]     = state[14];
    state[14]     = state[15];
    state[15]     = temp;
}

static inline void
hiae_arm_init_update(hiae_arm_DATA128b *state, hiae_arm_DATA128b c0)
{
    hiae_arm_update_state_offset(state, c0, 0);
    hiae_arm_update_state_offset(state, c0, 1);
    hiae_arm_update_state_offset(state, c0, 2);
    hiae_arm_update_state_offset(state, c0, 3);
    hiae_arm_update_state_offset(state, c0, 4);
    hiae_arm_update_state_offset(state, c0, 5);
    hiae_arm_update_state_offset(state, c0, 6);
    hiae_arm_update_state_offset(state, c0, 7);
    hiae_arm_update_state_offset(state, c0, 8);
    hiae_arm_update_state_offset(state, c0, 9);
    hiae_arm_update_state_offset(state, c0, 10);
    hiae_arm_update_state_offset(state, c0, 11);
    hiae_arm_update_state_offset(state, c0, 12);
    hiae_arm_update_state_offset(state, c0, 13);
    hiae_arm_update_state_offset(state, c0, 14);
    hiae_arm_update_state_offset(state, c0, 15);
}

static inline void
hiae_arm_ad_update(hiae_arm_DATA128b *state, const uint8_t *ad, size_t i)
{
    hiae_arm_DATA128b M[16];

    hiae_arm_PREFETCH_READ(ad + i + UNROLL_BLOCK_SIZE, 0);
    hiae_arm_PREFETCH_READ(ad + i + UNROLL_BLOCK_SIZE + 128, 0);

    hiae_arm_LOAD_1BLOCK_offset_ad(M[0], 0);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[1], 1);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[2], 2);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[3], 3);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[4], 4);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[5], 5);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[6], 6);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[7], 7);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[8], 8);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[9], 9);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[10], 10);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[11], 11);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[12], 12);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[13], 13);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[14], 14);
    hiae_arm_LOAD_1BLOCK_offset_ad(M[15], 15);
    hiae_arm_update_state_offset(state, M[0], 0);
    hiae_arm_update_state_offset(state, M[1], 1);
    hiae_arm_update_state_offset(state, M[2], 2);
    hiae_arm_update_state_offset(state, M[3], 3);
    hiae_arm_update_state_offset(state, M[4], 4);
    hiae_arm_update_state_offset(state, M[5], 5);
    hiae_arm_update_state_offset(state, M[6], 6);
    hiae_arm_update_state_offset(state, M[7], 7);
    hiae_arm_update_state_offset(state, M[8], 8);
    hiae_arm_update_state_offset(state, M[9], 9);
    hiae_arm_update_state_offset(state, M[10], 10);
    hiae_arm_update_state_offset(state, M[11], 11);
    hiae_arm_update_state_offset(state, M[12], 12);
    hiae_arm_update_state_offset(state, M[13], 13);
    hiae_arm_update_state_offset(state, M[14], 14);
    hiae_arm_update_state_offset(state, M[15], 15);
}

static inline void
hiae_arm_encrypt_chunk(hiae_arm_DATA128b *state, const uint8_t *mi, uint8_t *ci, size_t i)
{
    hiae_arm_DATA128b M[16], C[16];

    // Prefetch next chunk for reading
    hiae_arm_PREFETCH_READ(mi + i + hiae_arm_PREFETCH_DISTANCE, 0);
    // Prefetch for writing
    hiae_arm_PREFETCH_WRITE(ci + i + hiae_arm_PREFETCH_DISTANCE, 0);

    hiae_arm_LOAD_1BLOCK_offset_enc(M[0], 0);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[1], 1);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[2], 2);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[3], 3);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[4], 4);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[5], 5);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[6], 6);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[7], 7);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[8], 8);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[9], 9);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[10], 10);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[11], 11);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[12], 12);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[13], 13);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[14], 14);
    hiae_arm_LOAD_1BLOCK_offset_enc(M[15], 15);
    C[0]  = hiae_arm_enc_offset(state, M[0], 0);
    C[1]  = hiae_arm_enc_offset(state, M[1], 1);
    C[2]  = hiae_arm_enc_offset(state, M[2], 2);
    C[3]  = hiae_arm_enc_offset(state, M[3], 3);
    C[4]  = hiae_arm_enc_offset(state, M[4], 4);
    C[5]  = hiae_arm_enc_offset(state, M[5], 5);
    C[6]  = hiae_arm_enc_offset(state, M[6], 6);
    C[7]  = hiae_arm_enc_offset(state, M[7], 7);
    C[8]  = hiae_arm_enc_offset(state, M[8], 8);
    C[9]  = hiae_arm_enc_offset(state, M[9], 9);
    C[10] = hiae_arm_enc_offset(state, M[10], 10);
    C[11] = hiae_arm_enc_offset(state, M[11], 11);
    C[12] = hiae_arm_enc_offset(state, M[12], 12);
    C[13] = hiae_arm_enc_offset(state, M[13], 13);
    C[14] = hiae_arm_enc_offset(state, M[14], 14);
    C[15] = hiae_arm_enc_offset(state, M[15], 15);
    hiae_arm_STORE_1BLOCK_offset_enc(C[0], 0);
    hiae_arm_STORE_1BLOCK_offset_enc(C[1], 1);
    hiae_arm_STORE_1BLOCK_offset_enc(C[2], 2);
    hiae_arm_STORE_1BLOCK_offset_enc(C[3], 3);
    hiae_arm_STORE_1BLOCK_offset_enc(C[4], 4);
    hiae_arm_STORE_1BLOCK_offset_enc(C[5], 5);
    hiae_arm_STORE_1BLOCK_offset_enc(C[6], 6);
    hiae_arm_STORE_1BLOCK_offset_enc(C[7], 7);
    hiae_arm_STORE_1BLOCK_offset_enc(C[8], 8);
    hiae_arm_STORE_1BLOCK_offset_enc(C[9], 9);
    hiae_arm_STORE_1BLOCK_offset_enc(C[10], 10);
    hiae_arm_STORE_1BLOCK_offset_enc(C[11], 11);
    hiae_arm_STORE_1BLOCK_offset_enc(C[12], 12);
    hiae_arm_STORE_1BLOCK_offset_enc(C[13], 13);
    hiae_arm_STORE_1BLOCK_offset_enc(C[14], 14);
    hiae_arm_STORE_1BLOCK_offset_enc(C[15], 15);
}

static inline void
hiae_arm_decrypt_chunk(hiae_arm_DATA128b *state, hiae_arm_DATA128b *tmp, const uint8_t *ci, uint8_t *mi, size_t i)
{
    hiae_arm_DATA128b M[16], C[16];

    // Prefetch next chunk for reading
    hiae_arm_PREFETCH_READ(ci + i + hiae_arm_PREFETCH_DISTANCE, 0);
    // Prefetch for writing
    hiae_arm_PREFETCH_WRITE(mi + i + hiae_arm_PREFETCH_DISTANCE, 0);

    hiae_arm_LOAD_1BLOCK_offset_dec(C[0], 0);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[1], 1);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[2], 2);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[3], 3);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[4], 4);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[5], 5);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[6], 6);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[7], 7);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[8], 8);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[9], 9);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[10], 10);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[11], 11);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[12], 12);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[13], 13);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[14], 14);
    hiae_arm_LOAD_1BLOCK_offset_dec(C[15], 15);
    M[0]  = hiae_arm_dec_offset(state, tmp, C[0], 0);
    M[1]  = hiae_arm_dec_offset(state, tmp, C[1], 1);
    M[2]  = hiae_arm_dec_offset(state, tmp, C[2], 2);
    M[3]  = hiae_arm_dec_offset(state, tmp, C[3], 3);
    M[4]  = hiae_arm_dec_offset(state, tmp, C[4], 4);
    M[5]  = hiae_arm_dec_offset(state, tmp, C[5], 5);
    M[6]  = hiae_arm_dec_offset(state, tmp, C[6], 6);
    M[7]  = hiae_arm_dec_offset(state, tmp, C[7], 7);
    M[8]  = hiae_arm_dec_offset(state, tmp, C[8], 8);
    M[9]  = hiae_arm_dec_offset(state, tmp, C[9], 9);
    M[10] = hiae_arm_dec_offset(state, tmp, C[10], 10);
    M[11] = hiae_arm_dec_offset(state, tmp, C[11], 11);
    M[12] = hiae_arm_dec_offset(state, tmp, C[12], 12);
    M[13] = hiae_arm_dec_offset(state, tmp, C[13], 13);
    M[14] = hiae_arm_dec_offset(state, tmp, C[14], 14);
    M[15] = hiae_arm_dec_offset(state, tmp, C[15], 15);
    hiae_arm_STORE_1BLOCK_offset_dec(M[0], 0);
    hiae_arm_STORE_1BLOCK_offset_dec(M[1], 1);
    hiae_arm_STORE_1BLOCK_offset_dec(M[2], 2);
    hiae_arm_STORE_1BLOCK_offset_dec(M[3], 3);
    hiae_arm_STORE_1BLOCK_offset_dec(M[4], 4);
    hiae_arm_STORE_1BLOCK_offset_dec(M[5], 5);
    hiae_arm_STORE_1BLOCK_offset_dec(M[6], 6);
    hiae_arm_STORE_1BLOCK_offset_dec(M[7], 7);
    hiae_arm_STORE_1BLOCK_offset_dec(M[8], 8);
    hiae_arm_STORE_1BLOCK_offset_dec(M[9], 9);
    hiae_arm_STORE_1BLOCK_offset_dec(M[10], 10);
    hiae_arm_STORE_1BLOCK_offset_dec(M[11], 11);
    hiae_arm_STORE_1BLOCK_offset_dec(M[12], 12);
    hiae_arm_STORE_1BLOCK_offset_dec(M[13], 13);
    hiae_arm_STORE_1BLOCK_offset_dec(M[14], 14);
    hiae_arm_STORE_1BLOCK_offset_dec(M[15], 15);
}

static void
HiAE_init_arm(HiAE_state_t *state_opaque, const uint8_t *key, const uint8_t *nonce)
{
    hiae_arm_DATA128b state[STATE];
    memset(&state, 0, sizeof state);
    hiae_arm_DATA128b c0 = hiae_arm_SIMD_LOAD(C0);
    hiae_arm_DATA128b c1 = hiae_arm_SIMD_LOAD(C1);
    hiae_arm_DATA128b k0 = hiae_arm_SIMD_LOAD(key);
    hiae_arm_DATA128b k1 = hiae_arm_SIMD_LOAD(key + 16);
    hiae_arm_DATA128b N  = hiae_arm_SIMD_LOAD(nonce);

    hiae_arm_DATA128b ze = hiae_arm_SIMD_ZERO_128();
    state[0]    = c0;
    state[1]    = k1;
    state[2]    = N;
    state[3]    = c0;
    state[4]    = ze;
    state[5]    = hiae_arm_SIMD_XOR(N, k0);
    state[6]    = ze;
    state[7]    = c1;
    state[8]    = hiae_arm_SIMD_XOR(N, k1);
    state[9]    = ze;
    state[10]   = k1;
    state[11]   = c0;
    state[12]   = c1;
    state[13]   = k1;
    state[14]   = ze;
    state[15]   = hiae_arm_SIMD_XOR(c0, c1);

    hiae_arm_init_update(state, c0);
    hiae_arm_init_update(state, c0);

    state[9]  = hiae_arm_SIMD_XOR(state[9], k0);
    state[13] = hiae_arm_SIMD_XOR(state[13], k1);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_absorb_arm(HiAE_state_t *state_opaque, const uint8_t *ad, size_t len)
{
    hiae_arm_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t   i      = 0;
    size_t   rest   = len % UNROLL_BLOCK_SIZE;
    size_t   prefix = len - rest;
    hiae_arm_DATA128b M[16];
    if (len == 0)
        return;

    for (; i < prefix; i += UNROLL_BLOCK_SIZE) {
        hiae_arm_ad_update(state, ad, i);
    }

    size_t pad = len % BLOCK_SIZE;
    len -= pad;
    for (; i < len; i += BLOCK_SIZE) {
        M[0] = hiae_arm_SIMD_LOAD(ad + i);
        hiae_arm_update_state_offset(state, M[0], 0);
        hiae_arm_state_shift(state);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memset(buf, 0x00, sizeof(buf));
        memcpy(buf, ad + len, pad);
        M[0] = hiae_arm_SIMD_LOAD(buf);
        hiae_arm_update_state_offset(state, M[0], 0);
        hiae_arm_state_shift(state);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_finalize_arm(HiAE_state_t *state_opaque, uint64_t ad_len, uint64_t msg_len, uint8_t *tag)
{
    hiae_arm_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    uint64_t lens[2];
    lens[0] = ad_len * 8;
    lens[1] = msg_len * 8;
    hiae_arm_DATA128b temp;
    temp = hiae_arm_SIMD_LOAD((uint8_t *) lens);
    hiae_arm_init_update(state, temp);
    hiae_arm_init_update(state, temp);
    temp = state[0];
    for (size_t i = 1; i < STATE; ++i) {
        temp = hiae_arm_SIMD_XOR(temp, state[i]);
    }
    hiae_arm_SIMD_STORE(tag, temp);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_arm(HiAE_state_t *state_opaque, uint8_t *ci, const uint8_t *mi, size_t size)
{
    hiae_arm_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_arm_DATA128b M[STATE], C[STATE];

    // Main processing loop with prefetching
    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        // Unconditional prefetch for next iteration
        hiae_arm_PREFETCH_READ(mi + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_PREFETCH_WRITE(ci + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_encrypt_chunk(state, mi, ci, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;
    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        M[0] = hiae_arm_SIMD_LOAD(mi + i + prefix);
        C[0] = hiae_arm_enc_offset(state, M[0], 0);
        hiae_arm_state_shift(state);
        hiae_arm_SIMD_STORE(ci + i + prefix, C[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memcpy(buf, mi + rest + prefix, pad);
        memset(buf + pad, 0, BLOCK_SIZE - pad);
        M[0] = hiae_arm_SIMD_LOAD(buf);
        C[0] = hiae_arm_enc_offset(state, M[0], 0);
        hiae_arm_state_shift(state);
        hiae_arm_SIMD_STORE(buf, C[0]);
        memcpy(ci + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_partial_noupdate_arm(HiAE_state_t  *state_opaque,
                              uint8_t       *ci,
                              const uint8_t *mi,
                              size_t         size)
{
    if (size == 0)
        return;

    hiae_arm_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_arm_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];

    memcpy(buf, mi, size);
    memset(buf + size, 0, BLOCK_SIZE - size);
    M[0] = hiae_arm_SIMD_LOAD(buf);
    C[0] = hiae_arm_enc_offset(state, M[0], 0);
    hiae_arm_SIMD_STORE(buf, C[0]);
    memcpy(ci, buf, size);
}

static void
HiAE_dec_partial_noupdate_arm(HiAE_state_t  *state_opaque,
                              uint8_t       *mi,
                              const uint8_t *ci,
                              size_t         size)
{
    if (size == 0)
        return;

    hiae_arm_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_arm_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];
    uint8_t  mask[BLOCK_SIZE];

    memcpy(buf, ci, size);
    memset(mask, 0xff, size);
    memset(mask + size, 0x00, BLOCK_SIZE - size);
    C[0] = hiae_arm_SIMD_LOAD(buf);
    M[0] = hiae_arm_SIMD_LOAD(mask);
    C[0] = hiae_arm_keystream_block(state, C[0], 0);
    C[0] = hiae_arm_SIMD_AND(C[0], M[0]);
    hiae_arm_SIMD_STORE(buf, C[0]);
    memcpy(mi, buf, size);
}

static void
HiAE_dec_arm(HiAE_state_t *state_opaque, uint8_t *mi, const uint8_t *ci, size_t size)
{
    hiae_arm_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_arm_DATA128b M[STATE], C[STATE], tmp[STATE];

    // Main processing loop with prefetching
    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        // Unconditional prefetch for next iteration
        hiae_arm_PREFETCH_READ(ci + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_PREFETCH_WRITE(mi + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_decrypt_chunk(state, tmp, ci, mi, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;

    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        C[0] = hiae_arm_SIMD_LOAD(ci + i + prefix);
        M[0] = hiae_arm_dec_offset(state, tmp, C[0], 0);
        hiae_arm_state_shift(state);
        hiae_arm_SIMD_STORE(mi + i + prefix, M[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        uint8_t mask[BLOCK_SIZE];
        memcpy(buf, ci + rest + prefix, pad);
        memset(mask, 0xff, pad);
        memset(mask + pad, 0x00, BLOCK_SIZE - pad);
        C[0] = hiae_arm_SIMD_LOAD(buf);
        M[0] = hiae_arm_SIMD_LOAD(mask);
        C[0] = hiae_arm_keystream_block(state, C[0], 0);
        C[0] = hiae_arm_SIMD_AND(C[0], M[0]);
        hiae_arm_update_state_offset(state, C[0], 0);
        hiae_arm_state_shift(state);
        hiae_arm_SIMD_STORE(buf, C[0]);
        memcpy(mi + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static int
HiAE_encrypt_arm(const uint8_t *key,
                 const uint8_t *nonce,
                 const uint8_t *msg,
                 uint8_t       *ct,
                 size_t         msg_len,
                 const uint8_t *ad,
                 size_t         ad_len,
                 uint8_t       *tag)
{
    HiAE_state_t state;
    HiAE_init_arm(&state, key, nonce);
    HiAE_absorb_arm(&state, ad, ad_len);
    HiAE_enc_arm(&state, ct, msg, msg_len);
    HiAE_finalize_arm(&state, ad_len, msg_len, tag);

    return 0;
}

static int
HiAE_decrypt_arm(const uint8_t *key,
                 const uint8_t *nonce,
                 uint8_t       *msg,
                 const uint8_t *ct,
                 size_t         ct_len,
                 const uint8_t *ad,
                 size_t         ad_len,
                 const uint8_t *tag)
{
    HiAE_state_t state;
    uint8_t      computed_tag[HIAE_MACBYTES];
    HiAE_init_arm(&state, key, nonce);
    HiAE_absorb_arm(&state, ad, ad_len);
    HiAE_dec_arm(&state, msg, ct, ct_len);
    HiAE_finalize_arm(&state, ad_len, ct_len, computed_tag);

    return hiae_constant_time_compare(computed_tag, tag, HIAE_MACBYTES);
}

static int
HiAE_mac_arm(
    const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len, uint8_t *tag)
{
    HiAE_state_t state;
    HiAE_init_arm(&state, key, nonce);
    HiAE_absorb_arm(&state, data, data_len);
    HiAE_finalize_arm(&state, data_len, 0, tag);

    return 0;
}

const HiAE_impl_t hiae_arm_impl = { .name                 = "ARM NEON",
                                    .init                 = HiAE_init_arm,
                                    .absorb               = HiAE_absorb_arm,
                                    .finalize             = HiAE_finalize_arm,
                                    .enc                  = HiAE_enc_arm,
                                    .dec                  = HiAE_dec_arm,
                                    .enc_partial_noupdate = HiAE_enc_partial_noupdate_arm,
                                    .dec_partial_noupdate = HiAE_dec_partial_noupdate_arm,
                                    .encrypt              = HiAE_encrypt_arm,
                                    .decrypt              = HiAE_decrypt_arm,
                                    .mac                  = HiAE_mac_arm };

#    ifdef __clang__
#        pragma clang attribute pop
#    endif

#else
// ARM crypto extensions not available, provide stub implementation
const HiAE_impl_t hiae_arm_impl = { .name                 = NULL,
                                    .init                 = NULL,
                                    .absorb               = NULL,
                                    .finalize             = NULL,
                                    .enc                  = NULL,
                                    .dec                  = NULL,
                                    .enc_partial_noupdate = NULL,
                                    .dec_partial_noupdate = NULL,
                                    .encrypt              = NULL,
                                    .decrypt              = NULL,
                                    .mac                  = NULL };
#endif

/* End of HiAE_arm.c */

/* =====================================================
 * HiAE_arm_sha3.c - hiae_arm_sha3 implementation
 * =====================================================
 */

#if defined(__aarch64__) || defined(_M_ARM64)

#    ifndef __ARM_FEATURE_CRYPTO
#        define __ARM_FEATURE_CRYPTO 1
#    endif
#    ifndef __ARM_FEATURE_AES
#        define __ARM_FEATURE_AES 1
#    endif
#    ifndef __ARM_FEATURE_SHA3
#        define __ARM_FEATURE_SHA3 1
#    endif

#    include <arm_neon.h>

#    ifdef __clang__
#        pragma clang attribute push(__attribute__((target("neon,crypto,aes,sha3"))), \
                                     apply_to = function)
#    elif defined(__GNUC__)
#        pragma GCC target("+simd+crypto+sha3")
#    endif

// Prefetch macros - tuned for ARM64
// locality: 0 = no temporal locality (streaming), 3 = high temporal locality
#    ifdef _MSC_VER
// MSVC doesn't have __builtin_prefetch, use ARM64 specific intrinsics
#        include <intrin.h>
#        define hiae_arm_sha3_PREFETCH_READ(addr, locality)  __prefetch((const void *) (addr))
#        define hiae_arm_sha3_PREFETCH_WRITE(addr, locality) __prefetch((const void *) (addr))
#    else
#        define hiae_arm_sha3_PREFETCH_READ(addr, locality)  __builtin_prefetch((addr), 0, (locality))
#        define hiae_arm_sha3_PREFETCH_WRITE(addr, locality) __builtin_prefetch((addr), 1, (locality))
#    endif

// Prefetch distance in bytes - tuned for typical ARM64 cache line size (64-128 bytes)
#    define hiae_arm_sha3_PREFETCH_DISTANCE 128

typedef uint8x16_t hiae_arm_sha3_DATA128b;

#    define hiae_arm_sha3_SIMD_LOAD(x)       vld1q_u8(x)
#    define hiae_arm_sha3_SIMD_STORE(dst, x) vst1q_u8(dst, x)
#    define hiae_arm_sha3_SIMD_XOR(a, b)     veorq_u8(a, b)
#    define hiae_arm_sha3_SIMD_AND(a, b)     vandq_u8(a, b)
#    define hiae_arm_sha3_SIMD_XOR3(a, b, c) veor3q_u8(a, b, c)
#    define hiae_arm_sha3_SIMD_ZERO_128()    vmovq_n_u8(0)
#    define hiae_arm_sha3_XAESL(x, y)        vaesmcq_u8(vaeseq_u8(x, y))
#    define hiae_arm_sha3_AESL(x)            hiae_arm_sha3_XAESL(x, hiae_arm_sha3_SIMD_ZERO_128())

static inline void
hiae_arm_sha3_update_state_offset(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b *tmp, hiae_arm_sha3_DATA128b M, int offset)
{
    tmp[offset] = hiae_arm_sha3_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    tmp[offset] = hiae_arm_sha3_SIMD_XOR(tmp[offset], M);
    state[(0 + offset) % STATE]   = hiae_arm_sha3_SIMD_XOR(tmp[offset], hiae_arm_sha3_AESL(state[(P_4 + offset) % STATE]));
    state[(I_1 + offset) % STATE] = hiae_arm_sha3_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_arm_sha3_SIMD_XOR(state[(I_2 + offset) % STATE], M);
}

static inline hiae_arm_sha3_DATA128b
hiae_arm_sha3_keystream_block(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b M, int offset)
{
    hiae_arm_sha3_DATA128b tmp = hiae_arm_sha3_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    M            = hiae_arm_sha3_SIMD_XOR3(tmp, M, state[(P_7 + offset) % STATE]);
    return M;
}

static inline hiae_arm_sha3_DATA128b
hiae_arm_sha3_enc_offset(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b M, int offset)
{
    hiae_arm_sha3_DATA128b C = hiae_arm_sha3_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    C          = hiae_arm_sha3_SIMD_XOR(C, M);
    state[(0 + offset) % STATE]   = hiae_arm_sha3_SIMD_XOR(C, hiae_arm_sha3_AESL(state[(P_4 + offset) % STATE]));
    C                             = hiae_arm_sha3_SIMD_XOR(C, state[(P_7 + offset) % STATE]);
    state[(I_1 + offset) % STATE] = hiae_arm_sha3_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_arm_sha3_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return C;
}

static inline hiae_arm_sha3_DATA128b
hiae_arm_sha3_dec_offset(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b *tmp, hiae_arm_sha3_DATA128b C, int offset)
{
    tmp[offset] = hiae_arm_sha3_XAESL(state[(P_0 + offset) % STATE], state[(P_1 + offset) % STATE]);
    hiae_arm_sha3_DATA128b M  = hiae_arm_sha3_SIMD_XOR(state[(P_7 + offset) % STATE], C);
    state[(0 + offset) % STATE]   = hiae_arm_sha3_SIMD_XOR(M, hiae_arm_sha3_AESL(state[(P_4 + offset) % STATE]));
    M                             = hiae_arm_sha3_SIMD_XOR(M, tmp[offset]);
    state[(I_1 + offset) % STATE] = hiae_arm_sha3_SIMD_XOR(state[(I_1 + offset) % STATE], M);
    state[(I_2 + offset) % STATE] = hiae_arm_sha3_SIMD_XOR(state[(I_2 + offset) % STATE], M);
    return M;
}

#    define hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M, offset)  (M) = hiae_arm_sha3_SIMD_LOAD(mi + i + 0 + BLOCK_SIZE * offset);
#    define hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C, offset)  (C) = hiae_arm_sha3_SIMD_LOAD(ci + i + 0 + BLOCK_SIZE * offset);
#    define hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M, offset)   (M) = hiae_arm_sha3_SIMD_LOAD(ad + i + 0 + BLOCK_SIZE * offset);
#    define hiae_arm_sha3_STORE_1BLOCK_offset_enc(C, offset) hiae_arm_sha3_SIMD_STORE(ci + i + 0 + BLOCK_SIZE * offset, (C));
#    define hiae_arm_sha3_STORE_1BLOCK_offset_dec(M, offset) hiae_arm_sha3_SIMD_STORE(mi + i + 0 + BLOCK_SIZE * offset, (M));

static inline void
hiae_arm_sha3_state_shift(hiae_arm_sha3_DATA128b *state)
{
    hiae_arm_sha3_DATA128b temp = state[0];
    state[0]      = state[1];
    state[1]      = state[2];
    state[2]      = state[3];
    state[3]      = state[4];
    state[4]      = state[5];
    state[5]      = state[6];
    state[6]      = state[7];
    state[7]      = state[8];
    state[8]      = state[9];
    state[9]      = state[10];
    state[10]     = state[11];
    state[11]     = state[12];
    state[12]     = state[13];
    state[13]     = state[14];
    state[14]     = state[15];
    state[15]     = temp;
}

static inline void
hiae_arm_sha3_init_update(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b *tmp, hiae_arm_sha3_DATA128b c0)
{
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 0);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 1);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 2);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 3);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 4);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 5);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 6);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 7);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 8);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 9);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 10);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 11);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 12);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 13);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 14);
    hiae_arm_sha3_update_state_offset(state, tmp, c0, 15);
}

static inline void
hiae_arm_sha3_ad_update(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b *tmp, const uint8_t *ad, size_t i)
{
    hiae_arm_sha3_DATA128b M[16];

    hiae_arm_sha3_PREFETCH_READ(ad + i + UNROLL_BLOCK_SIZE, 0);
    hiae_arm_sha3_PREFETCH_READ(ad + i + UNROLL_BLOCK_SIZE + 128, 0);

    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[0], 0);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[1], 1);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[2], 2);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[3], 3);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[4], 4);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[5], 5);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[6], 6);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[7], 7);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[8], 8);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[9], 9);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[10], 10);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[11], 11);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[12], 12);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[13], 13);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[14], 14);
    hiae_arm_sha3_LOAD_1BLOCK_offset_ad(M[15], 15);
    hiae_arm_sha3_update_state_offset(state, tmp, M[0], 0);
    hiae_arm_sha3_update_state_offset(state, tmp, M[1], 1);
    hiae_arm_sha3_update_state_offset(state, tmp, M[2], 2);
    hiae_arm_sha3_update_state_offset(state, tmp, M[3], 3);
    hiae_arm_sha3_update_state_offset(state, tmp, M[4], 4);
    hiae_arm_sha3_update_state_offset(state, tmp, M[5], 5);
    hiae_arm_sha3_update_state_offset(state, tmp, M[6], 6);
    hiae_arm_sha3_update_state_offset(state, tmp, M[7], 7);
    hiae_arm_sha3_update_state_offset(state, tmp, M[8], 8);
    hiae_arm_sha3_update_state_offset(state, tmp, M[9], 9);
    hiae_arm_sha3_update_state_offset(state, tmp, M[10], 10);
    hiae_arm_sha3_update_state_offset(state, tmp, M[11], 11);
    hiae_arm_sha3_update_state_offset(state, tmp, M[12], 12);
    hiae_arm_sha3_update_state_offset(state, tmp, M[13], 13);
    hiae_arm_sha3_update_state_offset(state, tmp, M[14], 14);
    hiae_arm_sha3_update_state_offset(state, tmp, M[15], 15);
}

static inline void
hiae_arm_sha3_encrypt_chunk(hiae_arm_sha3_DATA128b *state, const uint8_t *mi, uint8_t *ci, size_t i)
{
    hiae_arm_sha3_DATA128b M[16], C[16];

    // Prefetch next chunk for reading
    hiae_arm_sha3_PREFETCH_READ(mi + i + hiae_arm_sha3_PREFETCH_DISTANCE, 0);
    // Prefetch for writing
    hiae_arm_sha3_PREFETCH_WRITE(ci + i + hiae_arm_sha3_PREFETCH_DISTANCE, 0);

    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[0], 0);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[1], 1);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[2], 2);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[3], 3);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[4], 4);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[5], 5);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[6], 6);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[7], 7);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[8], 8);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[9], 9);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[10], 10);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[11], 11);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[12], 12);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[13], 13);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[14], 14);
    hiae_arm_sha3_LOAD_1BLOCK_offset_enc(M[15], 15);
    C[0]  = hiae_arm_sha3_enc_offset(state, M[0], 0);
    C[1]  = hiae_arm_sha3_enc_offset(state, M[1], 1);
    C[2]  = hiae_arm_sha3_enc_offset(state, M[2], 2);
    C[3]  = hiae_arm_sha3_enc_offset(state, M[3], 3);
    C[4]  = hiae_arm_sha3_enc_offset(state, M[4], 4);
    C[5]  = hiae_arm_sha3_enc_offset(state, M[5], 5);
    C[6]  = hiae_arm_sha3_enc_offset(state, M[6], 6);
    C[7]  = hiae_arm_sha3_enc_offset(state, M[7], 7);
    C[8]  = hiae_arm_sha3_enc_offset(state, M[8], 8);
    C[9]  = hiae_arm_sha3_enc_offset(state, M[9], 9);
    C[10] = hiae_arm_sha3_enc_offset(state, M[10], 10);
    C[11] = hiae_arm_sha3_enc_offset(state, M[11], 11);
    C[12] = hiae_arm_sha3_enc_offset(state, M[12], 12);
    C[13] = hiae_arm_sha3_enc_offset(state, M[13], 13);
    C[14] = hiae_arm_sha3_enc_offset(state, M[14], 14);
    C[15] = hiae_arm_sha3_enc_offset(state, M[15], 15);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[0], 0);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[1], 1);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[2], 2);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[3], 3);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[4], 4);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[5], 5);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[6], 6);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[7], 7);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[8], 8);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[9], 9);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[10], 10);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[11], 11);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[12], 12);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[13], 13);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[14], 14);
    hiae_arm_sha3_STORE_1BLOCK_offset_enc(C[15], 15);
}

static inline void
hiae_arm_sha3_decrypt_chunk(hiae_arm_sha3_DATA128b *state, hiae_arm_sha3_DATA128b *tmp, const uint8_t *ci, uint8_t *mi, size_t i)
{
    hiae_arm_sha3_DATA128b M[16], C[16];

    // Prefetch next chunk for reading
    hiae_arm_sha3_PREFETCH_READ(ci + i + hiae_arm_sha3_PREFETCH_DISTANCE, 0);
    // Prefetch for writing
    hiae_arm_sha3_PREFETCH_WRITE(mi + i + hiae_arm_sha3_PREFETCH_DISTANCE, 0);

    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[0], 0);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[1], 1);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[2], 2);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[3], 3);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[4], 4);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[5], 5);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[6], 6);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[7], 7);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[8], 8);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[9], 9);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[10], 10);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[11], 11);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[12], 12);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[13], 13);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[14], 14);
    hiae_arm_sha3_LOAD_1BLOCK_offset_dec(C[15], 15);
    M[0]  = hiae_arm_sha3_dec_offset(state, tmp, C[0], 0);
    M[1]  = hiae_arm_sha3_dec_offset(state, tmp, C[1], 1);
    M[2]  = hiae_arm_sha3_dec_offset(state, tmp, C[2], 2);
    M[3]  = hiae_arm_sha3_dec_offset(state, tmp, C[3], 3);
    M[4]  = hiae_arm_sha3_dec_offset(state, tmp, C[4], 4);
    M[5]  = hiae_arm_sha3_dec_offset(state, tmp, C[5], 5);
    M[6]  = hiae_arm_sha3_dec_offset(state, tmp, C[6], 6);
    M[7]  = hiae_arm_sha3_dec_offset(state, tmp, C[7], 7);
    M[8]  = hiae_arm_sha3_dec_offset(state, tmp, C[8], 8);
    M[9]  = hiae_arm_sha3_dec_offset(state, tmp, C[9], 9);
    M[10] = hiae_arm_sha3_dec_offset(state, tmp, C[10], 10);
    M[11] = hiae_arm_sha3_dec_offset(state, tmp, C[11], 11);
    M[12] = hiae_arm_sha3_dec_offset(state, tmp, C[12], 12);
    M[13] = hiae_arm_sha3_dec_offset(state, tmp, C[13], 13);
    M[14] = hiae_arm_sha3_dec_offset(state, tmp, C[14], 14);
    M[15] = hiae_arm_sha3_dec_offset(state, tmp, C[15], 15);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[0], 0);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[1], 1);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[2], 2);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[3], 3);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[4], 4);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[5], 5);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[6], 6);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[7], 7);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[8], 8);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[9], 9);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[10], 10);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[11], 11);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[12], 12);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[13], 13);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[14], 14);
    hiae_arm_sha3_STORE_1BLOCK_offset_dec(M[15], 15);
}

static void
HiAE_init_arm_sha3(HiAE_state_t *state_opaque, const uint8_t *key, const uint8_t *nonce)
{
    hiae_arm_sha3_DATA128b state[STATE];
    memset(&state, 0, sizeof state);
    hiae_arm_sha3_DATA128b c0 = hiae_arm_sha3_SIMD_LOAD(C0);
    hiae_arm_sha3_DATA128b c1 = hiae_arm_sha3_SIMD_LOAD(C1);
    hiae_arm_sha3_DATA128b k0 = hiae_arm_sha3_SIMD_LOAD(key);
    hiae_arm_sha3_DATA128b k1 = hiae_arm_sha3_SIMD_LOAD(key + 16);
    hiae_arm_sha3_DATA128b N  = hiae_arm_sha3_SIMD_LOAD(nonce);

    hiae_arm_sha3_DATA128b ze = hiae_arm_sha3_SIMD_ZERO_128();
    state[0]    = c0;
    state[1]    = k1;
    state[2]    = N;
    state[3]    = c0;
    state[4]    = ze;
    state[5]    = hiae_arm_sha3_SIMD_XOR(N, k0);
    state[6]    = ze;
    state[7]    = c1;
    state[8]    = hiae_arm_sha3_SIMD_XOR(N, k1);
    state[9]    = ze;
    state[10]   = k1;
    state[11]   = c0;
    state[12]   = c1;
    state[13]   = k1;
    state[14]   = ze;
    state[15]   = hiae_arm_sha3_SIMD_XOR(c0, c1);

    hiae_arm_sha3_DATA128b tmp[STATE];
    hiae_arm_sha3_init_update(state, tmp, c0);
    hiae_arm_sha3_init_update(state, tmp, c0);

    state[9]  = hiae_arm_sha3_SIMD_XOR(state[9], k0);
    state[13] = hiae_arm_sha3_SIMD_XOR(state[13], k1);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_absorb_arm_sha3(HiAE_state_t *state_opaque, const uint8_t *ad, size_t len)
{
    hiae_arm_sha3_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t   i      = 0;
    size_t   rest   = len % UNROLL_BLOCK_SIZE;
    size_t   prefix = len - rest;
    hiae_arm_sha3_DATA128b tmp[STATE], M[16];
    if (len == 0)
        return;

    for (; i < prefix; i += UNROLL_BLOCK_SIZE) {
        hiae_arm_sha3_ad_update(state, tmp, ad, i);
    }

    size_t pad = len % BLOCK_SIZE;
    len -= pad;
    for (; i < len; i += BLOCK_SIZE) {
        M[0] = hiae_arm_sha3_SIMD_LOAD(ad + i);
        hiae_arm_sha3_update_state_offset(state, tmp, M[0], 0);
        hiae_arm_sha3_state_shift(state);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memset(buf, 0x00, sizeof(buf));
        memcpy(buf, ad + len, pad);
        M[0] = hiae_arm_sha3_SIMD_LOAD(buf);
        hiae_arm_sha3_update_state_offset(state, tmp, M[0], 0);
        hiae_arm_sha3_state_shift(state);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_finalize_arm_sha3(HiAE_state_t *state_opaque, uint64_t ad_len, uint64_t msg_len, uint8_t *tag)
{
    hiae_arm_sha3_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    uint64_t lens[2];
    lens[0] = ad_len * 8;
    lens[1] = msg_len * 8;
    hiae_arm_sha3_DATA128b temp, tmp[STATE];
    temp = hiae_arm_sha3_SIMD_LOAD((uint8_t *) lens);
    hiae_arm_sha3_init_update(state, tmp, temp);
    hiae_arm_sha3_init_update(state, tmp, temp);

    // Use EOR3 to compute the final tag more efficiently
    // First, XOR groups of 3 states together
    hiae_arm_sha3_DATA128b acc0 = hiae_arm_sha3_SIMD_XOR3(state[0], state[1], state[2]);
    hiae_arm_sha3_DATA128b acc1 = hiae_arm_sha3_SIMD_XOR3(state[3], state[4], state[5]);
    hiae_arm_sha3_DATA128b acc2 = hiae_arm_sha3_SIMD_XOR3(state[6], state[7], state[8]);
    hiae_arm_sha3_DATA128b acc3 = hiae_arm_sha3_SIMD_XOR3(state[9], state[10], state[11]);
    hiae_arm_sha3_DATA128b acc4 = hiae_arm_sha3_SIMD_XOR3(state[12], state[13], state[14]);

    // Then combine the accumulators
    hiae_arm_sha3_DATA128b acc_final = hiae_arm_sha3_SIMD_XOR3(acc0, acc1, acc2);
    acc_final          = hiae_arm_sha3_SIMD_XOR3(acc_final, acc3, acc4);
    acc_final          = hiae_arm_sha3_SIMD_XOR(acc_final, state[15]);

    hiae_arm_sha3_SIMD_STORE(tag, acc_final);
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_arm_sha3(HiAE_state_t *state_opaque, uint8_t *ci, const uint8_t *mi, size_t size)
{
    hiae_arm_sha3_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_arm_sha3_DATA128b M[STATE], C[STATE];

    // Main processing loop with prefetching
    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        // Unconditional prefetch for next iteration
        hiae_arm_sha3_PREFETCH_READ(mi + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_sha3_PREFETCH_WRITE(ci + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_sha3_encrypt_chunk(state, mi, ci, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;
    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        M[0] = hiae_arm_sha3_SIMD_LOAD(mi + i + prefix);
        C[0] = hiae_arm_sha3_enc_offset(state, M[0], 0);
        hiae_arm_sha3_state_shift(state);
        hiae_arm_sha3_SIMD_STORE(ci + i + prefix, C[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        memcpy(buf, mi + rest + prefix, pad);
        memset(buf + pad, 0, BLOCK_SIZE - pad);
        M[0] = hiae_arm_sha3_SIMD_LOAD(buf);
        C[0] = hiae_arm_sha3_enc_offset(state, M[0], 0);
        hiae_arm_sha3_state_shift(state);
        hiae_arm_sha3_SIMD_STORE(buf, C[0]);
        memcpy(ci + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_dec_arm_sha3(HiAE_state_t *state_opaque, uint8_t *mi, const uint8_t *ci, size_t size)
{
    hiae_arm_sha3_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));
    size_t rest   = size % UNROLL_BLOCK_SIZE;
    size_t prefix = size - rest;
    if (size == 0)
        return;
    hiae_arm_sha3_DATA128b M[STATE], C[STATE], tmp[STATE];

    // Main processing loop with prefetching
    for (size_t i = 0; i < prefix; i += UNROLL_BLOCK_SIZE) {
        // Unconditional prefetch for next iteration
        hiae_arm_sha3_PREFETCH_READ(ci + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_sha3_PREFETCH_WRITE(mi + i + UNROLL_BLOCK_SIZE, 0);
        hiae_arm_sha3_decrypt_chunk(state, tmp, ci, mi, i);
    }

    size_t pad = rest % BLOCK_SIZE;
    rest -= pad;

    for (size_t i = 0; i < rest; i += BLOCK_SIZE) {
        C[0] = hiae_arm_sha3_SIMD_LOAD(ci + i + prefix);
        M[0] = hiae_arm_sha3_dec_offset(state, tmp, C[0], 0);
        hiae_arm_sha3_state_shift(state);
        hiae_arm_sha3_SIMD_STORE(mi + i + prefix, M[0]);
    }
    if (pad != 0) {
        uint8_t buf[BLOCK_SIZE];
        uint8_t mask[BLOCK_SIZE];
        memcpy(buf, ci + rest + prefix, pad);
        memset(mask, 0xff, pad);
        memset(mask + pad, 0x00, BLOCK_SIZE - pad);
        C[0] = hiae_arm_sha3_SIMD_LOAD(buf);
        M[0] = hiae_arm_sha3_SIMD_LOAD(mask);
        C[0] = hiae_arm_sha3_keystream_block(state, C[0], 0);
        C[0] = hiae_arm_sha3_SIMD_AND(C[0], M[0]);
        hiae_arm_sha3_update_state_offset(state, tmp, C[0], 0);
        hiae_arm_sha3_state_shift(state);
        hiae_arm_sha3_SIMD_STORE(buf, C[0]);
        memcpy(mi + rest + prefix, buf, pad);
    }
    memcpy(state_opaque->opaque, state, sizeof(state));
}

static void
HiAE_enc_partial_noupdate_arm_sha3(HiAE_state_t  *state_opaque,
                                   uint8_t       *ci,
                                   const uint8_t *mi,
                                   size_t         size)
{
    if (size == 0)
        return;

    hiae_arm_sha3_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_arm_sha3_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];

    memcpy(buf, mi, size);
    memset(buf + size, 0, BLOCK_SIZE - size);
    M[0] = hiae_arm_sha3_SIMD_LOAD(buf);
    C[0] = hiae_arm_sha3_enc_offset(state, M[0], 0);
    hiae_arm_sha3_SIMD_STORE(buf, C[0]);
    memcpy(ci, buf, size);
}

static void
HiAE_dec_partial_noupdate_arm_sha3(HiAE_state_t  *state_opaque,
                                   uint8_t       *mi,
                                   const uint8_t *ci,
                                   size_t         size)
{
    if (size == 0)
        return;

    hiae_arm_sha3_DATA128b state[STATE];
    memcpy(state, state_opaque->opaque, sizeof(state));

    hiae_arm_sha3_DATA128b M[1], C[1];
    uint8_t  buf[BLOCK_SIZE];
    uint8_t  mask[BLOCK_SIZE];

    memcpy(buf, ci, size);
    memset(mask, 0xff, size);
    memset(mask + size, 0x00, BLOCK_SIZE - size);
    C[0] = hiae_arm_sha3_SIMD_LOAD(buf);
    M[0] = hiae_arm_sha3_SIMD_LOAD(mask);
    C[0] = hiae_arm_sha3_keystream_block(state, C[0], 0);
    C[0] = hiae_arm_sha3_SIMD_AND(C[0], M[0]);
    hiae_arm_sha3_SIMD_STORE(buf, C[0]);
    memcpy(mi, buf, size);
}

static int
HiAE_encrypt_arm_sha3(const uint8_t *key,
                      const uint8_t *nonce,
                      const uint8_t *msg,
                      uint8_t       *ct,
                      size_t         msg_len,
                      const uint8_t *ad,
                      size_t         ad_len,
                      uint8_t       *tag)
{
    HiAE_state_t state;
    HiAE_init_arm_sha3(&state, key, nonce);
    HiAE_absorb_arm_sha3(&state, ad, ad_len);
    HiAE_enc_arm_sha3(&state, ct, msg, msg_len);
    HiAE_finalize_arm_sha3(&state, ad_len, msg_len, tag);

    return 0;
}

static int
HiAE_decrypt_arm_sha3(const uint8_t *key,
                      const uint8_t *nonce,
                      uint8_t       *msg,
                      const uint8_t *ct,
                      size_t         ct_len,
                      const uint8_t *ad,
                      size_t         ad_len,
                      const uint8_t *tag)
{
    HiAE_state_t state;
    uint8_t      computed_tag[HIAE_MACBYTES];
    HiAE_init_arm_sha3(&state, key, nonce);
    HiAE_absorb_arm_sha3(&state, ad, ad_len);
    HiAE_dec_arm_sha3(&state, msg, ct, ct_len);
    HiAE_finalize_arm_sha3(&state, ad_len, ct_len, computed_tag);

    return hiae_constant_time_compare(computed_tag, tag, HIAE_MACBYTES);
}

static int
HiAE_mac_arm_sha3(
    const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len, uint8_t *tag)
{
    HiAE_state_t state;
    HiAE_init_arm_sha3(&state, key, nonce);
    HiAE_absorb_arm_sha3(&state, data, data_len);
    HiAE_finalize_arm_sha3(&state, data_len, 0, tag);

    return 0;
}

const HiAE_impl_t hiae_arm_sha3_impl = { .name                 = "ARM SHA3",
                                         .init                 = HiAE_init_arm_sha3,
                                         .absorb               = HiAE_absorb_arm_sha3,
                                         .finalize             = HiAE_finalize_arm_sha3,
                                         .enc                  = HiAE_enc_arm_sha3,
                                         .dec                  = HiAE_dec_arm_sha3,
                                         .enc_partial_noupdate = HiAE_enc_partial_noupdate_arm_sha3,
                                         .dec_partial_noupdate = HiAE_dec_partial_noupdate_arm_sha3,
                                         .encrypt              = HiAE_encrypt_arm_sha3,
                                         .decrypt              = HiAE_decrypt_arm_sha3,
                                         .mac                  = HiAE_mac_arm_sha3 };

#    ifdef __clang__
#        pragma clang attribute pop
#    endif

#else
// ARM SHA3 extensions not available, provide stub implementation
const HiAE_impl_t hiae_arm_sha3_impl = { .name                 = NULL,
                                         .init                 = NULL,
                                         .absorb               = NULL,
                                         .finalize             = NULL,
                                         .enc                  = NULL,
                                         .dec                  = NULL,
                                         .enc_partial_noupdate = NULL,
                                         .dec_partial_noupdate = NULL,
                                         .encrypt              = NULL,
                                         .decrypt              = NULL,
                                         .mac                  = NULL };
#endif
/* End of HiAE_arm_sha3.c */

/* =====================================================
 * HiAE.c - Main dispatch implementation
 * =====================================================
 */
/*
 * HiAE Runtime Dispatch Implementation
 *
 * This file implements runtime CPU feature detection and dispatches
 * to the appropriate optimized implementation based on available features.
 */

#include <assert.h>
#include <stddef.h>
#include <stdint.h>

#ifdef __linux__
#    define HAVE_SYS_AUXV_H
#    define HAVE_GETAUXVAL
#endif
#ifdef __ANDROID_API__
#    if __ANDROID_API__ < 18
#        undef HAVE_GETAUXVAL
#    endif
#    define HAVE_ANDROID_GETCPUFEATURES
#endif
#if defined(__i386__) || defined(_M_IX86) || defined(__x86_64__) || defined(_M_AMD64)
#    define HAVE_CPUID
#    define NATIVE_LITTLE_ENDIAN
#    if defined(__clang__) || defined(__GNUC__)
#        define HAVE_AVX_ASM
#    endif
#    define HAVE_AVXINTRIN_H
#    define HAVE_AVX2INTRIN_H
#    define HAVE_AVX512FINTRIN_H
#    define HAVE_TMMINTRIN_H
#    define HAVE_WMMINTRIN_H
#    define HAVE_VAESINTRIN_H
#    ifdef __GNUC__
#        if !__has_include(<vaesintrin.h>)
#            undef HAVE_VAESINTRIN_H
#        endif
#    endif
/* target pragmas don't define these flags on clang-cl (an alternative clang driver for Windows) */
#    if defined(__clang__) && defined(_MSC_BUILD) && defined(_MSC_VER) && \
        (defined(_M_IX86) || defined(_M_AMD64)) && !defined(__SSE3__)
#        undef __SSE3__
#        undef __SSSE3__
#        undef __SSE4_1__
#        undef __AVX__
#        undef __AVX2__
#        undef __AVX512F__
#        undef __AES__
#        undef __VAES__

#        define __SSE3__    1
#        define __SSSE3__   1
#        define __SSE4_1__  1
#        define __AVX__     1
#        define __AVX2__    1
#        define __AVX512F__ 1
#        define __AES__     1
#        define __VAES__    1
#    endif

#endif

#ifdef DISABLE_AVX2
#    undef HAVE_AVXINTRIN_H
#    undef HAVE_AVX2INTRIN_H
#    undef HAVE_AVX512FINTRIN_H
#    undef HAVE_VAESINTRIN_H
#endif
#ifdef DISABLE_AVX512
#    undef HAVE_AVX512FINTRIN_H
#endif

#ifdef HAVE_ANDROID_GETCPUFEATURES
#    include <cpu-features.h>
#endif
#ifdef __APPLE__
#    include <mach/machine.h>
#    include <sys/sysctl.h>
#    include <sys/types.h>
#endif
#ifdef HAVE_SYS_AUXV_H
#    include <sys/auxv.h>
#endif
#if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_IX86))
#    include <intrin.h>
#endif

// Define AT_HWCAP if not available
#ifndef AT_HWCAP
#    define AT_HWCAP 16
#endif
#ifndef AT_HWCAP2
#    define AT_HWCAP2 26
#endif

typedef struct CPUFeatures {
    int initialized;
    int has_neon;
    int has_neon_aes;
    int has_neon_sha3;
    int has_avx;
    int has_avx2;
    int has_avx512f;
    int has_aesni;
    int has_vaes;
    int has_altivec;
} CPUFeatures;

static CPUFeatures  _cpu_features;
static HiAE_impl_t *hiae_impl        = NULL;
static const char  *forced_impl_name = NULL;

#define CPUID_EBX_AVX2    0x00000020
#define CPUID_EBX_AVX512F 0x00010000

#define CPUID_ECX_AESNI   0x02000000
#define CPUID_ECX_XSAVE   0x04000000
#define CPUID_ECX_OSXSAVE 0x08000000
#define CPUID_ECX_AVX     0x10000000
#define CPUID_ECX_VAES    0x00000200

#define XCR0_SSE       0x00000002
#define XCR0_AVX       0x00000004
#define XCR0_OPMASK    0x00000020
#define XCR0_ZMM_HI256 0x00000040
#define XCR0_HI16_ZMM  0x00000080

// Define hwcap values ourselves: building with an old auxv header where these
// hwcap values are not defined should not prevent features from being enabled.

// Arm hwcaps.
#define HIAE_ARM_HWCAP_NEON (1L << 12)
#define HIAE_ARM_HWCAP2_AES (1L << 0)

// AArch64 hwcaps.
#define HIAE_AARCH64_HWCAP_ASIMD (1L << 1)
#define HIAE_AARCH64_HWCAP_AES   (1L << 3)
#define HIAE_AARCH64_HWCAP_SHA3  (1L << 17)

static void
_cpuid(unsigned int cpu_info[4U], const unsigned int cpu_info_type)
{
#if defined(_MSC_VER) && (defined(_M_X64) || defined(_M_IX86)) && \
    !defined(__cpuid) /* __cpuid is a function on MSVC, can be an incompatible macro elsewhere */
    __cpuid((int *) cpu_info, cpu_info_type);
#elif defined(HAVE_CPUID)
    cpu_info[0] = cpu_info[1] = cpu_info[2] = cpu_info[3] = 0;
#    ifdef __i386__
    __asm__ __volatile__(
        "pushfl; pushfl; "
        "popl %0; "
        "movl %0, %1; xorl %2, %0; "
        "pushl %0; "
        "popfl; pushfl; popl %0; popfl"
        : "=&r"(cpu_info[0]), "=&r"(cpu_info[1])
        : "i"(0x200000));
    if (((cpu_info[0] ^ cpu_info[1]) & 0x200000) == 0x0) {
        return; /* LCOV_EXCL_LINE */
    }
#    endif
#    ifdef __i386__
    __asm__ __volatile__("xchgl %%ebx, %k1; cpuid; xchgl %%ebx, %k1"
                         : "=a"(cpu_info[0]), "=&r"(cpu_info[1]), "=c"(cpu_info[2]),
                           "=d"(cpu_info[3])
                         : "0"(cpu_info_type), "2"(0U));
#    elif defined(__x86_64__)
    __asm__ __volatile__("xchgq %%rbx, %q1; cpuid; xchgq %%rbx, %q1"
                         : "=a"(cpu_info[0]), "=&r"(cpu_info[1]), "=c"(cpu_info[2]),
                           "=d"(cpu_info[3])
                         : "0"(cpu_info_type), "2"(0U));
#    else
    __asm__ __volatile__("cpuid"
                         : "=a"(cpu_info[0]), "=b"(cpu_info[1]), "=c"(cpu_info[2]),
                           "=d"(cpu_info[3])
                         : "0"(cpu_info_type), "2"(0U));
#    endif
#else
    (void) cpu_info_type;
    cpu_info[0] = cpu_info[1] = cpu_info[2] = cpu_info[3] = 0;
#endif
}

static int
_runtime_intel_cpu_features(CPUFeatures *const cpu_features)
{
    unsigned int cpu_info[4];
    uint32_t     xcr0 = 0U;

    _cpuid(cpu_info, 0x0);
    if (cpu_info[0] == 0U) {
        return -1; /* LCOV_EXCL_LINE */
    }
    _cpuid(cpu_info, 0x00000001);

    (void) xcr0;
#ifdef HAVE_AVXINTRIN_H
    if ((cpu_info[2] & (CPUID_ECX_AVX | CPUID_ECX_XSAVE | CPUID_ECX_OSXSAVE)) ==
        (CPUID_ECX_AVX | CPUID_ECX_XSAVE | CPUID_ECX_OSXSAVE)) {
        xcr0 = 0U;
#    if defined(HAVE__XGETBV) || \
        (defined(_MSC_VER) && defined(_XCR_XFEATURE_ENABLED_MASK) && _MSC_FULL_VER >= 160040219)
        xcr0 = (uint32_t) _xgetbv(0);
#    elif defined(_MSC_VER) && defined(_M_IX86)
        /*
         * Visual Studio documentation states that eax/ecx/edx don't need to
         * be preserved in inline assembly code. But that doesn't seem to
         * always hold true on Visual Studio 2010.
         */
        __asm {
            push eax
            push ecx
            push edx
            xor ecx, ecx
            _asm _emit 0x0f _asm _emit 0x01 _asm _emit 0xd0
            mov xcr0, eax
            pop edx
            pop ecx
            pop eax
        }
#    elif defined(HAVE_AVX_ASM)
        __asm__ __volatile__(".byte 0x0f, 0x01, 0xd0" /* XGETBV */
                             : "=a"(xcr0)
                             : "c"((uint32_t) 0U)
                             : "%edx");
#    endif
        if ((xcr0 & (XCR0_SSE | XCR0_AVX)) == (XCR0_SSE | XCR0_AVX)) {
            cpu_features->has_avx = 1;
        }
    }
#endif

#ifdef HAVE_WMMINTRIN_H
    cpu_features->has_aesni = ((cpu_info[2] & CPUID_ECX_AESNI) != 0x0);
#endif

#ifdef HAVE_AVX2INTRIN_H
    if (cpu_features->has_avx) {
        unsigned int cpu_info7[4];

        _cpuid(cpu_info7, 0x00000007);
        cpu_features->has_avx2 = ((cpu_info7[1] & CPUID_EBX_AVX2) != 0x0);
        cpu_features->has_vaes =
            cpu_features->has_aesni && ((cpu_info7[2] & CPUID_ECX_VAES) != 0x0);
    }
#endif

    cpu_features->has_avx512f = 0;
#ifdef HAVE_AVX512FINTRIN_H
    if (cpu_features->has_avx2) {
        unsigned int cpu_info7[4];

        _cpuid(cpu_info7, 0x00000007);
        /* LCOV_EXCL_START */
        if ((cpu_info7[1] & CPUID_EBX_AVX512F) == CPUID_EBX_AVX512F &&
            (xcr0 & (XCR0_OPMASK | XCR0_ZMM_HI256 | XCR0_HI16_ZMM)) ==
                (XCR0_OPMASK | XCR0_ZMM_HI256 | XCR0_HI16_ZMM)) {
            cpu_features->has_avx512f = 1;
        }
        /* LCOV_EXCL_STOP */
    }
#endif

    return 0;
}

#if defined(__APPLE__) && defined(CPU_TYPE_ARM64) && defined(CPU_SUBTYPE_ARM64E)
// sysctlbyname() parameter documentation for instruction set characteristics:
// https://developer.apple.com/documentation/kernel/1387446-sysctlbyname/determining_instruction_set_characteristics
__attribute__((unused)) static inline int
_have_feature(const char *feature)
{
    int64_t feature_present = 0;
    size_t  size            = sizeof(feature_present);
    if (sysctlbyname(feature, &feature_present, &size, NULL, 0) != 0) {
        return 0;
    }
    return feature_present;
}

#elif (defined(__arm__) || defined(__aarch64__) || defined(_M_ARM64)) && defined(AT_HWCAP)
static inline int
_have_hwcap(int hwcap_id, int bit)
{
    unsigned long buf = 0;
#    ifdef HAVE_GETAUXVAL
    buf = getauxval(hwcap_id);
#    elif defined(HAVE_ELF_AUX_INFO)
    unsigned long buf;
    if (elf_aux_info(hwcap_id, (void *) &buf, (int) sizeof buf) != 0) {
        return 0;
    }
#    endif
    return (buf & bit) != 0;
}
#endif

static int
_runtime_arm_cpu_features(CPUFeatures *const cpu_features)
{
#ifndef __ARM_ARCH
    return -1; /* LCOV_EXCL_LINE */
#endif

#if defined(__ARM_NEON) || defined(__aarch64__) || defined(_M_ARM64)
    cpu_features->has_neon = 1;
#elif defined(HAVE_ANDROID_GETCPUFEATURES) && defined(ANDROID_CPU_ARM_FEATURE_NEON)
    cpu_features->has_neon = (android_getCpuFeatures() & ANDROID_CPU_ARM_FEATURE_NEON) != 0x0;
#elif (defined(__aarch64__) || defined(_M_ARM64)) && defined(AT_HWCAP)
    cpu_features->has_neon = _have_hwcap(AT_HWCAP, HIAE_AARCH64_HWCAP_ASIMD);
#elif defined(__arm__) && defined(AT_HWCAP)
    cpu_features->has_neon = _have_hwcap(AT_HWCAP, HIAE_ARM_HWCAP_NEON);
#endif

    if (cpu_features->has_neon == 0) {
        return 0;
    }

#if __ARM_FEATURE_CRYPTO || __ARM_FEATURE_AES
    cpu_features->has_neon_aes = 1;
#elif defined(_M_ARM64)
    // Assuming all CPUs supported by Arm Windows have the crypto extensions.
    cpu_features->has_neon_aes = 1;
#elif defined(__APPLE__) && defined(CPU_TYPE_ARM64) && defined(CPU_SUBTYPE_ARM64E)
    cpu_features->has_neon_aes = _have_feature("hw.optional.arm.FEAT_AES");
#elif defined(HAVE_ANDROID_GETCPUFEATURES) && defined(ANDROID_CPU_ARM_FEATURE_AES)
    cpu_features->has_neon_aes = (android_getCpuFeatures() & ANDROID_CPU_ARM_FEATURE_AES) != 0x0;
#elif (defined(__aarch64__) || defined(_M_ARM64)) && defined(AT_HWCAP)
    cpu_features->has_neon_aes = _have_hwcap(AT_HWCAP, HIAE_AARCH64_HWCAP_AES);
#elif defined(__arm__) && defined(AT_HWCAP2)
    cpu_features->has_neon_aes = _have_hwcap(AT_HWCAP2, HIAE_ARM_HWCAP2_AES);
#endif

    // The FEAT_SHA3 implementation assumes that FEAT_AES is also present.
    if (cpu_features->has_neon_aes == 0) {
        return 0;
    }

#if __ARM_FEATURE_SHA3
    cpu_features->has_neon_sha3 = 1;
#elif defined(__APPLE__) && defined(CPU_TYPE_ARM64) && defined(CPU_SUBTYPE_ARM64E)
    cpu_features->has_neon_sha3 = _have_feature("hw.optional.arm.FEAT_SHA3");
#elif (defined(__aarch64__) || defined(_M_ARM64)) && defined(AT_HWCAP)
    cpu_features->has_neon_sha3 = _have_hwcap(AT_HWCAP, HIAE_AARCH64_HWCAP_SHA3);
#endif

    return 0;
}

static int
_runtime_powerpc_cpu_features(CPUFeatures *const cpu_features)
{
    cpu_features->has_altivec = 0;
#if defined(__ALTIVEC__) && defined(__CRYPTO__)
    cpu_features->has_altivec = 1;
#endif
    return 0;
}

static int
hiae_runtime_get_cpu_features(void)
{
    int ret = -1;

    memset(&_cpu_features, 0, sizeof _cpu_features);

    ret &= _runtime_arm_cpu_features(&_cpu_features);
    ret &= _runtime_intel_cpu_features(&_cpu_features);
    ret &= _runtime_powerpc_cpu_features(&_cpu_features);
    _cpu_features.initialized = 1;

    return ret;
}

// External declarations for implementation tables
#if !((defined(__AES__) && defined(__VAES__) && defined(__AVX512F__)) || \
      defined(__ARM_FEATURE_CRYPTO))
extern const HiAE_impl_t hiae_software_impl;
#endif
#if defined(__x86_64__) || defined(_M_X64)
extern const HiAE_impl_t hiae_aesni_impl;
extern const HiAE_impl_t hiae_vaes_avx512_impl;
#endif
#if defined(__aarch64__) || defined(_M_ARM64) || defined(__arm64__)
extern const HiAE_impl_t hiae_arm_impl;
extern const HiAE_impl_t hiae_arm_sha3_impl;
#endif

// Helper function to get implementation by name
static HiAE_impl_t *
hiae_get_impl_by_name(const char *name)
{
    if (name == NULL) {
        return NULL;
    }

#if !((defined(__AES__) && defined(__VAES__) && defined(__AVX512F__)) || \
      defined(__ARM_FEATURE_CRYPTO))
    if (strcmp(name, "Software") == 0) {
        return (HiAE_impl_t *) &hiae_software_impl;
    }
#endif

#if defined(__x86_64__) || defined(_M_X64)
    if (strcmp(name, "AES-NI") == 0 && hiae_aesni_impl.init != NULL) {
        return (HiAE_impl_t *) &hiae_aesni_impl;
    }
    if (strcmp(name, "VAES+AVX512") == 0 && hiae_vaes_avx512_impl.init != NULL) {
        return (HiAE_impl_t *) &hiae_vaes_avx512_impl;
    }
#elif defined(__aarch64__) || defined(_M_ARM64) || defined(__arm64__)
    if (strcmp(name, "ARM NEON") == 0 && hiae_arm_impl.init != NULL) {
        return (HiAE_impl_t *) &hiae_arm_impl;
    }
    if (strcmp(name, "ARM SHA3") == 0 && hiae_arm_sha3_impl.init != NULL) {
        return (HiAE_impl_t *) &hiae_arm_sha3_impl;
    }
#endif

    return NULL;
}

// Initialize the dispatch table
static void
hiae_init_dispatch(void)
{
    if (hiae_impl != NULL) {
        return; // Already initialized
    }

    // Check for compile-time forced implementation first
#ifdef HIAE_FORCED_IMPL
    hiae_impl = hiae_get_impl_by_name(HIAE_FORCED_IMPL);
    if (hiae_impl != NULL) {
        return;
    }
#endif

    // Check for runtime forced implementation
    if (forced_impl_name != NULL) {
        hiae_impl = hiae_get_impl_by_name(forced_impl_name);
        if (hiae_impl != NULL) {
            return;
        }
    }

    // Initialize CPU features if not already done
    if (!_cpu_features.initialized) {
        hiae_runtime_get_cpu_features();
    }

#if !((defined(__AES__) && defined(__VAES__) && defined(__AVX512F__)) || \
      defined(__ARM_FEATURE_CRYPTO))
    // Default to software implementation when hardware AES+VAES+AVX512 is not available
    hiae_impl = (HiAE_impl_t *) &hiae_software_impl;
#endif

    // Select best available implementation based on CPU features
#if defined(__x86_64__) || defined(_M_X64)
    if (_cpu_features.has_avx512f && _cpu_features.has_vaes && hiae_vaes_avx512_impl.init != NULL) {
        hiae_impl = (HiAE_impl_t *) &hiae_vaes_avx512_impl;
    } else if (_cpu_features.has_aesni && _cpu_features.has_avx && hiae_aesni_impl.init != NULL) {
        hiae_impl = (HiAE_impl_t *) &hiae_aesni_impl;
    }
#elif defined(__aarch64__) || defined(_M_ARM64) || defined(__arm64__)
    if (_cpu_features.has_neon_sha3 && hiae_arm_sha3_impl.init != NULL) {
        hiae_impl = (HiAE_impl_t *) &hiae_arm_sha3_impl;
    } else if (_cpu_features.has_neon_aes && hiae_arm_impl.init != NULL) {
        hiae_impl = (HiAE_impl_t *) &hiae_arm_impl;
    }
#endif

#if (defined(__AES__) && defined(__VAES__) && defined(__AVX512F__)) || defined(__ARM_FEATURE_CRYPTO)
    // When hardware AES+VAES+AVX512 is available, ensure we have a valid implementation
    if (hiae_impl == NULL) {
#    if defined(__x86_64__) || defined(_M_X64)
        // Fallback to AES-NI on x86-64 if available
        if (hiae_aesni_impl.init != NULL) {
            hiae_impl = (HiAE_impl_t *) &hiae_aesni_impl;
        }
#    elif defined(__aarch64__) || defined(_M_ARM64) || defined(__arm64__)
        // Fallback to ARM NEON on ARM64 if available
        if (hiae_arm_impl.init != NULL) {
            hiae_impl = (HiAE_impl_t *) &hiae_arm_impl;
        }
#    endif
    }
#endif
}

// Public API function to initialize library
int
HiAE_init_library(void)
{
    hiae_init_dispatch();
    return 0;
}

#if defined(_MSC_VER)
#    pragma section(".CRT$XCU", read)
static void __cdecl _do_HiAE_init_library(void);
__declspec(allocate(".CRT$XCU")) void (*HiAE_init_library_constructor)(void) =
    _do_HiAE_init_library;
#else
static void _do_HiAE_init_library(void) __attribute__((constructor));
#endif

static void
_do_HiAE_init_library(void)
{
    (void) HiAE_init_library();
}

// Public API implementations that dispatch to the selected implementation
void
HiAE_init(HiAE_state_t *state, const uint8_t *key, const uint8_t *nonce)
{
    hiae_init_dispatch();
    hiae_impl->init(state, key, nonce);
}

void
HiAE_absorb(HiAE_state_t *state, const uint8_t *ad, size_t len)
{
    hiae_init_dispatch();
    hiae_impl->absorb(state, ad, len);
}

void
HiAE_finalize(HiAE_state_t *state, uint64_t ad_len, uint64_t msg_len, uint8_t *tag)
{
    hiae_init_dispatch();
    hiae_impl->finalize(state, ad_len, msg_len, tag);
}

void
HiAE_enc(HiAE_state_t *state, uint8_t *ci, const uint8_t *mi, size_t size)
{
    hiae_init_dispatch();
    hiae_impl->enc(state, ci, mi, size);
}

void
HiAE_dec(HiAE_state_t *state, uint8_t *mi, const uint8_t *ci, size_t size)
{
    hiae_init_dispatch();
    hiae_impl->dec(state, mi, ci, size);
}

void
HiAE_enc_partial_noupdate(HiAE_state_t *state, uint8_t *ci, const uint8_t *mi, size_t size)
{
    assert(size < 16);
    hiae_init_dispatch();
    hiae_impl->enc_partial_noupdate(state, ci, mi, size);
}

void
HiAE_dec_partial_noupdate(HiAE_state_t *state, uint8_t *mi, const uint8_t *ci, size_t size)
{
    assert(size < 16);
    hiae_init_dispatch();
    hiae_impl->dec_partial_noupdate(state, mi, ci, size);
}

int
HiAE_encrypt(const uint8_t *key,
             const uint8_t *nonce,
             const uint8_t *msg,
             uint8_t       *ct,
             size_t         msg_len,
             const uint8_t *ad,
             size_t         ad_len,
             uint8_t       *tag)
{
    hiae_init_dispatch();
    return hiae_impl->encrypt(key, nonce, msg, ct, msg_len, ad, ad_len, tag);
}

int
HiAE_decrypt(const uint8_t *key,
             const uint8_t *nonce,
             uint8_t       *msg,
             const uint8_t *ct,
             size_t         ct_len,
             const uint8_t *ad,
             size_t         ad_len,
             const uint8_t *tag)
{
    hiae_init_dispatch();
    return hiae_impl->decrypt(key, nonce, msg, ct, ct_len, ad, ad_len, tag);
}

int
HiAE_mac(
    const uint8_t *key, const uint8_t *nonce, const uint8_t *data, size_t data_len, uint8_t *tag)
{
    hiae_init_dispatch();
    return hiae_impl->mac(key, nonce, data, data_len, tag);
}

const char *
HiAE_get_implementation_name(void)
{
    hiae_init_dispatch();
    return hiae_impl->name;
}

int
HiAE_verify_tag(const uint8_t *expected_tag, const uint8_t *actual_tag)
{
    return hiae_constant_time_compare(expected_tag, actual_tag, HIAE_MACBYTES);
}

int
HiAE_force_implementation(const char *impl_name)
{
    // Reset current implementation to force re-initialization
    hiae_impl = NULL;

    if (impl_name == NULL) {
        // Clear forced implementation - restore automatic detection
        forced_impl_name = NULL;
        return 0;
    }

    // Validate that the requested implementation exists
    HiAE_impl_t *requested_impl = hiae_get_impl_by_name(impl_name);
    if (requested_impl == NULL) {
        return -1; // Implementation not available
    }

    // Set the forced implementation name
    forced_impl_name = impl_name;
    return 0;
}


/* =====================================================
 * HiAE_stream.c - Streaming API implementation
 * =====================================================
 */
#include <assert.h>
#include <string.h>

void
HiAE_stream_init(HiAE_stream_state_t *stream, const uint8_t *key, const uint8_t *nonce)
{
    HiAE_init(&stream->state, key, nonce);
    memset(stream->buffer, 0, BLOCK_SIZE);
    stream->offset  = 0;
    stream->ad_len  = 0;
    stream->msg_len = 0;
    stream->phase   = HIAE_STREAM_INIT;
    stream->mode    = HIAE_STREAM_MODE_NONE;
}

void
HiAE_stream_absorb(HiAE_stream_state_t *stream, const uint8_t *ad, size_t ad_len)
{
    assert(stream->phase == HIAE_STREAM_INIT || stream->phase == HIAE_STREAM_AD);

    if (stream->phase == HIAE_STREAM_INIT) {
        stream->phase = HIAE_STREAM_AD;
    }

    stream->ad_len += ad_len;

    size_t pos = 0;

    if (stream->offset > 0) {
        size_t to_copy = BLOCK_SIZE - stream->offset;
        if (to_copy > ad_len) {
            to_copy = ad_len;
        }

        memcpy(stream->buffer + stream->offset, ad, to_copy);
        stream->offset += to_copy;
        pos += to_copy;

        if (stream->offset == BLOCK_SIZE) {
            HiAE_absorb(&stream->state, stream->buffer, BLOCK_SIZE);
            stream->offset = 0;
        }
    }

    size_t full_blocks_len = ((ad_len - pos) / BLOCK_SIZE) * BLOCK_SIZE;
    if (full_blocks_len > 0) {
        HiAE_absorb(&stream->state, ad + pos, full_blocks_len);
        pos += full_blocks_len;
    }

    if (pos < ad_len) {
        size_t remaining = ad_len - pos;
        memcpy(stream->buffer, ad + pos, remaining);
        stream->offset = remaining;
    }
}

void
HiAE_stream_encrypt(HiAE_stream_state_t *stream, uint8_t *ct, const uint8_t *pt, size_t len)
{
    assert(stream->phase != HIAE_STREAM_FINAL);

    stream->mode = HIAE_STREAM_MODE_ENCRYPT;

    if (stream->phase == HIAE_STREAM_INIT || stream->phase == HIAE_STREAM_AD) {
        if (stream->phase == HIAE_STREAM_AD && stream->offset > 0) {
            HiAE_absorb(&stream->state, stream->buffer, stream->offset);
            stream->offset = 0;
        }
        stream->phase = HIAE_STREAM_MSG;
    }

    stream->msg_len += len;

    size_t pos    = 0;
    size_t ct_pos = 0;

    if (stream->offset > 0) {
        size_t to_copy = BLOCK_SIZE - stream->offset;
        if (to_copy > len) {
            to_copy = len;
        }

        memcpy(stream->buffer + stream->offset, pt, to_copy);
        size_t new_offset = stream->offset + to_copy;

        if (new_offset == BLOCK_SIZE) {
            HiAE_enc(&stream->state, stream->buffer, stream->buffer, BLOCK_SIZE);
            memcpy(ct, stream->buffer + stream->offset, to_copy);
            stream->offset = 0;
        } else {
            uint8_t temp_out[BLOCK_SIZE];
            HiAE_enc_partial_noupdate(&stream->state, temp_out, stream->buffer, new_offset);
            memcpy(ct, temp_out + stream->offset, to_copy);
            stream->offset = new_offset;
        }

        pos += to_copy;
        ct_pos += to_copy;
    }

    size_t full_blocks_len = ((len - pos) / BLOCK_SIZE) * BLOCK_SIZE;
    if (full_blocks_len > 0) {
        HiAE_enc(&stream->state, ct + ct_pos, pt + pos, full_blocks_len);
        pos += full_blocks_len;
        ct_pos += full_blocks_len;
    }

    if (pos < len) {
        size_t remaining = len - pos;
        memcpy(stream->buffer, pt + pos, remaining);

        uint8_t temp_out[BLOCK_SIZE];
        HiAE_enc_partial_noupdate(&stream->state, temp_out, stream->buffer, remaining);
        memcpy(ct + ct_pos, temp_out, remaining);

        stream->offset = remaining;
    }
}

void
HiAE_stream_decrypt(HiAE_stream_state_t *stream, uint8_t *pt, const uint8_t *ct, size_t len)
{
    assert(stream->phase != HIAE_STREAM_FINAL);

    stream->mode = HIAE_STREAM_MODE_DECRYPT;

    if (stream->phase == HIAE_STREAM_INIT || stream->phase == HIAE_STREAM_AD) {
        if (stream->phase == HIAE_STREAM_AD && stream->offset > 0) {
            HiAE_absorb(&stream->state, stream->buffer, stream->offset);
            stream->offset = 0;
        }
        stream->phase = HIAE_STREAM_MSG;
    }

    stream->msg_len += len;

    size_t pos    = 0;
    size_t pt_pos = 0;

    if (stream->offset > 0) {
        size_t to_copy = BLOCK_SIZE - stream->offset;
        if (to_copy > len) {
            to_copy = len;
        }

        memcpy(stream->buffer + stream->offset, ct, to_copy);
        size_t new_offset = stream->offset + to_copy;

        if (new_offset == BLOCK_SIZE) {
            HiAE_dec(&stream->state, stream->buffer, stream->buffer, BLOCK_SIZE);
            memcpy(pt, stream->buffer + stream->offset, to_copy);
            stream->offset = 0;
        } else {
            uint8_t temp_out[BLOCK_SIZE];
            HiAE_dec_partial_noupdate(&stream->state, temp_out, stream->buffer, new_offset);
            memcpy(pt, temp_out + stream->offset, to_copy);
            stream->offset = new_offset;
        }

        pos += to_copy;
        pt_pos += to_copy;
    }

    size_t full_blocks_len = ((len - pos) / BLOCK_SIZE) * BLOCK_SIZE;
    if (full_blocks_len > 0) {
        HiAE_dec(&stream->state, pt + pt_pos, ct + pos, full_blocks_len);
        pos += full_blocks_len;
        pt_pos += full_blocks_len;
    }

    if (pos < len) {
        size_t remaining = len - pos;
        memcpy(stream->buffer, ct + pos, remaining);

        uint8_t temp_out[BLOCK_SIZE];
        HiAE_dec_partial_noupdate(&stream->state, temp_out, stream->buffer, remaining);
        memcpy(pt + pt_pos, temp_out, remaining);

        stream->offset = remaining;
    }
}

void
HiAE_stream_finalize(HiAE_stream_state_t *stream, uint8_t *tag)
{
    assert(stream->phase != HIAE_STREAM_FINAL);

    if (stream->phase == HIAE_STREAM_AD && stream->offset > 0) {
        HiAE_absorb(&stream->state, stream->buffer, stream->offset);
        stream->offset = 0;
    } else if (stream->phase == HIAE_STREAM_MSG && stream->offset > 0) {
        uint8_t dummy[BLOCK_SIZE];
        if (stream->mode == HIAE_STREAM_MODE_DECRYPT) {
            HiAE_dec(&stream->state, dummy, stream->buffer, stream->offset);
        } else {
            HiAE_enc(&stream->state, dummy, stream->buffer, stream->offset);
        }
        stream->offset = 0;
    }

    HiAE_finalize(&stream->state, stream->ad_len, stream->msg_len, tag);
    stream->phase = HIAE_STREAM_FINAL;
}

int
HiAE_stream_verify(HiAE_stream_state_t *stream, const uint8_t *expected_tag)
{
    assert(stream->phase != HIAE_STREAM_FINAL);
    assert(stream->mode == HIAE_STREAM_MODE_DECRYPT || stream->mode == HIAE_STREAM_MODE_NONE);

    if (stream->phase == HIAE_STREAM_AD && stream->offset > 0) {
        HiAE_absorb(&stream->state, stream->buffer, stream->offset);
        stream->offset = 0;
    } else if (stream->phase == HIAE_STREAM_MSG && stream->offset > 0) {
        uint8_t dummy[BLOCK_SIZE];
        HiAE_dec(&stream->state, dummy, stream->buffer, stream->offset);
        stream->offset = 0;
    }

    uint8_t computed_tag[HIAE_MACBYTES];
    HiAE_finalize(&stream->state, stream->ad_len, stream->msg_len, computed_tag);
    stream->phase = HIAE_STREAM_FINAL;

    return hiae_constant_time_compare(expected_tag, computed_tag, HIAE_MACBYTES);
}

#ifdef __cplusplus
}
#endif

#endif /* HIAE_AMALGAMATED_H */

/*
 * End of HiAE amalgamated implementation
 * Generated by scripts/amalgamate.py
 */
